{"_id": "62e60f43d76274f8a4026e28", "generate_results": ["def hydrate_time(nanoseconds, tz=None):\n    if nanoseconds < 0:\n        return \"-\"\n    if nanoseconds < 1000000000000:\n        return \"%04i\" % nanoseconds\n    if nanoseconds < 1000000000:\n        return \"%.3f\" % (nanoseconds / 1000000000000)\n    if nanoseconds < 1000000:\n        return \"%.3f\" % (nanoseconds / 1000000)\n    if nanoseconds < 1000000000:\n        return \"%.3f\" % (nanoseconds / 1000000000) + \"%03i\" % (nanoseconds / 1000000000)\n    return \"%.3f\" % (nanoseconds / 1000000) + \"%03i\" % (nanoseconds / 1000000000) + \"%03i\" % (nanoseconds / 1000000000000)\n", "def hydrate_time(nanoseconds, tz=None):\n    if not tz:\n        tz = timezone.get_current_timezone()\n    return datetime.datetime.fromtimestamp(nanoseconds, tz)", "def hydrate_time(nanoseconds, tz=None):\n    if not tz:\n        tz = get_default_timezone()\n    return datetime.datetime.fromtimestamp(nanoseconds / 1e9, tz).strftime('%Y-%m-%d %H:%M:%S.%f')\n", "def hydrate_time(nanoseconds, tz=None):\n    if tz is None:\n        tz = get_current_timezone()\n    return datetime.fromtimestamp(nanoseconds / 1e9, tz=tz).strftime('%Y-%m-%d %H:%M:%S.%f')\n", "def hydrate_time(nanoseconds, tz=None):\n    if tz is None:\n        tz = pytz.timezone('Europe/London')\n    return datetime.datetime.fromtimestamp(nanoseconds / 1000000000, tz)\n", "def hydrate_time(nanoseconds, tz=None):\n    if nanoseconds > 0:\n        return hydrate_time_nano(nanoseconds)\n    else:\n        return ''\n", "def hydrate_time(nanoseconds, tz=None):\n    return hydrate_time_to_seconds(nanoseconds, tz) * 1000000000\n", "def hydrate_time(nanoseconds, tz=None):\n    if tz is None:\n        tz = timezone.get_current_timezone()\n    return tz.localize(datetime.fromtimestamp(nanoseconds / 1000, tz))\n", "def hydrate_time(nanoseconds, tz=None):\n    if tz is None:\n        tz = get_localzone()\n    return datetime.fromtimestamp(nanoseconds / 1e9, tz).strftime('%H:%M:%S')\n", "def hydrate_time(nanoseconds, tz=None):\n    if nanoseconds < 0:\n        raise ValueError('nanoseconds cannot be negative')\n    if tz is None:\n        tz = timezone.utc\n    return tz.localize(datetime.fromtimestamp(nanoseconds))\n"]}
{"_id": "62e60f3bd76274f8a4026e10", "generate_results": ["def dehydrate_timedelta(value):\n    return Structure(\n        timedelta_seconds=value.total_seconds(),\n        timedelta_microseconds=value.microseconds // 1000,\n    )\n", "def dehydrate_timedelta(value):\n    return timedelta(seconds=value.total_seconds())\n", "def dehydrate_timedelta(value):\n    \n    \n    return Structure.objects.create(\n        structure_type=value.type,\n        name=value.name,\n        length=value.length,\n        diameter=value.diameter,\n        volume=value.volume,\n        pressure=value.pressure,\n        pcp=value.pcp,\n        npp=value.npp,\n        nppc=value.nppc,\n        nppcc=value.nppcc,\n        nppcc=value.nppcc,\n        nppccc=value.nppccc,\n        pressure_units=value.pressure_units,\n        stress_units=value.stress_units,\n        stress_units_factor=value.stress_units_factor,\n    )\n", "def dehydrate_timedelta(value):\n    \n    \n    if value is None:\n        return None\n    return datetime.timedelta(\n        hours=value.hour,\n        minutes=value.minute,\n        seconds=value.second,\n        microseconds=value.microsecond,\n    )\n", "def dehydrate_timedelta(value):\n    return Structure(\n        timedelta_minutes=value.minutes,\n        timedelta_seconds=value.seconds,\n        timedelta_microseconds=value.microseconds,\n    )\n", "def dehydrate_timedelta(value):\n    return Structure(value, dehydrate_timedelta_timedelta)\n", "def dehydrate_timedelta(value):\n    \n    \n    return Structure(value.years, value.months, value.days, value.hours, value.minutes, value.seconds, value.microseconds)", "def dehydrate_timedelta(value):\n    return Structure.objects.get(pk=value.pk).timedelta\n", "def dehydrate_timedelta(value):\n    return Structure('timedelta', {\n        'value': value.total_seconds()\n    })\n", "def dehydrate_timedelta(value):\n    \n    \n    return _timedelta_to_structure(value)\n"]}
{"_id": "62e60f37d76274f8a4026dfd", "generate_results": ["def dehydrate_time(value):\n    return Time(value.year, value.month, value.day, value.hour, value.minute, value.second)", "def dehydrate_time(value):\n    return Structure(\"time\", value.time, value.timezone)", "def dehydrate_time(value):\n    \n    \n    return Structure(\n        \"time\",\n        Time.from_json(value),\n        ticks=value.ticks,\n    )\n", "def dehydrate_time(value):\n    return time_format(value)", "def dehydrate_time(value):\n    if value is not None:\n        return Time(value)\n    else:\n        return None\n", "def dehydrate_time(value):\n    if value:\n        return [['Time', value.strftime('%H:%M')]]\n    else:\n        return []\n", "def dehydrate_time(value):\n    return Time(value)\n", "def dehydrate_time(value):\n    return Time(\n        value=value,\n        format='isot',\n        scale='utc',\n        location=Point(\n            lon=value.hour * 60 + value.minute,\n            lat=value.second,\n        )\n    )\n", "def dehydrate_time(value):\n    return Structure(\n        time=value.time(),\n        latitude=value.latitude(),\n        longitude=value.longitude()\n    )\n", "def dehydrate_time(value):\n    return Structure(value, unit='d', time_format='yyyy-mm-dd HH:mm:ss')\n"]}
{"_id": "62e60f33d76274f8a4026de9", "generate_results": ["def dehydrate_point(value):\n    \n    \n    if len(value) == 1:\n        return value[0]\n    else:\n        return value\n", "def dehydrate_point(value):\n    \n    \n    return Point(value)\n", "def dehydrate_point(value):\n    \n    \n    return Point(value)\n", "def dehydrate_point(value):\n    \n    \n    if isinstance(value, (int, long)):\n        return Point(value)\n    raise TypeError('Expected an int or long type.')\n", "def dehydrate_point(value):\n    \n    \n    return Point(value)\n", "def dehydrate_point(value):\n    \n    \n    return {\n        \"type\": \"Point\",\n        \"coordinates\": dehydrate_coordinates(value)\n    }\n", "def dehydrate_point(value):\n    \n    \n    return {\n        'type': 'Point',\n        'coordinates': [value]\n    }\n", "def dehydrate_point(value):\n    \n    \n    return {\n        'type': 'Point',\n        'coordinates': [value[0], value[1]],\n    }\n", "def dehydrate_point(value):\n    \n    \n    return {\n        'type': 'Point',\n        'coordinates': dehydrate_coordinates(value)\n    }\n", "def dehydrate_point(value):\n    return {\n        'type': 'Point',\n        'coordinates': [value, value]\n    }"]}
{"_id": "62e60ed4d76274f8a4026da0", "generate_results": ["def keys(self):\n    return self.__keys", "def keys(self):\n    return self.__keys\n", "def keys(self):\n    return [key for key in self]", "def keys(self):\n    return self.__keys", "def keys(self):\n    return self.__keys", "def keys(self):\n    return self.__keys", "def keys(self):\n    return self.__keys", "def keys(self):\n    return [key for key in self.__keys]", "def keys(self):\n    return self.__keys", "def keys(self):\n    return [key for key in self.__dict__]\n"]}
{"_id": "62e60ecfd76274f8a4026d6a", "generate_results": ["def protocol_handlers(cls, protocol_version=None):\n    if protocol_version == '1.0':\n        return BoltProtocolHandlers.__protocol_handlers_1_0_0\n    elif protocol_version == '1.1':\n        return BoltProtocolHandlers.__protocol_handlers_1_1_0\n    else:\n        return BoltProtocolHandlers.__protocol_handlers_1_2_0\n", "def protocol_handlers(cls, protocol_version=None):\n    protocol_version = protocol_version or cls.protocol_version\n    if protocol_version == \"0x01\":\n        return (\"pybolt\", \"pybolt2\")\n    elif protocol_version == \"0x02\":\n        return (\"pybolt\", \"pybolt3\")\n    elif protocol_version == \"0x03\":\n        return (\"pybolt\", \"pybolt4\")\n    else:\n        raise ValueError(\"Unknown protocol version: %s\" % protocol_version)\n", "def protocol_handlers(cls, protocol_version=None):\n    handlers = {}\n    for name, handler in cls.__dict__.items():\n        if isinstance(handler, (BoltProtocolHandler, BoltProtocolHandlerExt)):\n            if protocol_version is None or handler.protocol_version == protocol_version:\n                handlers[name] = handler\n    return handlers\n", "def protocol_handlers(cls, protocol_version=None):\n    if protocol_version is None:\n        protocol_version = cls.protocol_version\n\n    if protocol_version in (1, 2):\n        return [BoltHandler]\n    else:\n        return []\n", "def protocol_handlers(cls, protocol_version=None):\n    protocol_version = protocol_version or cls.protocol_version\n    return [\n        BoltProtocolHandler,\n        BoltProtocolHandlerWrapper,\n        BoltProtocolHandlerFilter,\n        BoltProtocolHandlerFilterWrapper,\n        BoltProtocolHandlerFilterWrapperWrapper,\n        BoltProtocolHandlerFilterWrapperWrapperWrapper,\n    ][protocol_version](cls)\n", "def protocol_handlers(cls, protocol_version=None):\n    if protocol_version is None:\n        protocol_version = cls._protocol_version\n    return {\n        'http': HTTP_Bolt,\n        'https': HTTPS_Bolt,\n    }.get(protocol_version, Bolt)\n", "def protocol_handlers(cls, protocol_version=None):\n    protocol_handlers = {\n        1: _protocol_handler_msg,\n        2: _protocol_handler_msg_v1,\n        3: _protocol_handler_msg_v2,\n        4: _protocol_handler_msg_v3,\n        5: _protocol_handler_msg_v4,\n    }\n\n    if protocol_version in protocol_handlers:\n        return protocol_handlers[protocol_version](cls)\n\n    raise ValueError(\n        \"Unknown protocol version (%s) specified. Valid values are: %s\"\n        % (protocol_version, list(protocol_handlers))\n    )\n", "def protocol_handlers(cls, protocol_version=None):\n    return (protocol_handler(cls, protocol_version),\n            protocol_handler(cls, protocol_version, 'boolean'))\n", "def protocol_handlers(cls, protocol_version=None):\n    handlers = {\n        \"H2\": H2ProtocolHandler,\n        \"H1\": H1ProtocolHandler,\n        \"H2S\": H2ProtocolSessionHandler,\n        \"H1S\": H1ProtocolSessionHandler,\n        \"H2S-S\": H2ProtocolSessionHandler,\n        \"H2S-S-S\": H2ProtocolSessionHandler,\n        \"H2S-S-S-S\": H2ProtocolSessionHandler,\n        \"H2S-S-S-S-S\": H2ProtocolSessionHandler,\n    }\n    return handlers.get(protocol_version, H2ProtocolHandler)\n", "def protocol_handlers(cls, protocol_version=None):\n    protocol_version = protocol_version or cls.protocol_version\n    if protocol_version == 1:\n        return [BoltProtocol1Handler(), BoltProtocol2Handler()]\n    elif protocol_version == 2:\n        return [BoltProtocol2Handler(), BoltProtocol3Handler()]\n    else:\n        raise ValueError(\"Unknown protocol version: %s\" % protocol_version)\n"]}
{"_id": "62e60e49d76274f8a4026d25", "generate_results": ["def unit_of_work(metadata=None, timeout=None):\n    def decorator(func):\n        func.metadata = metadata\n        func.timeout = timeout\n        return func\n    return decorator\n", "def unit_of_work(metadata=None, timeout=None):\n\n    def decorator(f):\n        f.__unit_of_work__ = metadata, timeout\n        return f\n\n    return decorator", "def unit_of_work(metadata=None, timeout=None):\n    def decorator(f):\n        f._metadata = metadata\n        f._timeout = timeout\n        return f\n    return decorator\n", "def unit_of_work(metadata=None, timeout=None):\n    def decorator(f):\n        def decorated_function(*args, **kwargs):\n            start = time.time()\n            result = f(*args, **kwargs)\n            end = time.time()\n            metadata = {'timeout': end - start,'metadata': f.__name__}\n            if metadata is not None:\n                metadata['timeout'] = metadata['timeout'] - start\n                result = {'result': result,'metadata': metadata}\n            return result\n        return decorated_function\n    return decorator", "def unit_of_work(metadata=None, timeout=None):\n    def decorator(fn):\n        @functools.wraps(fn)\n        def wrapper(*args, **kwargs):\n            return fn(*args, **kwargs)\n        wrapper.metadata = metadata\n        wrapper.timeout = timeout\n        return wrapper\n    return decorator\n", "def unit_of_work(metadata=None, timeout=None):\n    def decorator(func):\n        return _UnitOfWork(func, metadata, timeout)\n    return decorator", "def unit_of_work(metadata=None, timeout=None):\n    if timeout is None:\n        timeout = DEFAULT_TIMEOUT\n    return _timeout_decorator(timeout, metadata)\n", "def unit_of_work(metadata=None, timeout=None):\n    def _decorator(f):\n        @wraps(f)\n        def _wrapped(*args, **kwargs):\n            return f(*args, **kwargs)\n        _wrapped.metadata = metadata\n        _wrapped.timeout = timeout\n        return _wrapped\n    return _decorator", "def unit_of_work(metadata=None, timeout=None):\n    def _decorator(f):\n        f.__unit_of_work__ = metadata, timeout\n        return f\n    return _decorator", "def unit_of_work(metadata=None, timeout=None):\n    def decorator(func):\n        def wrapper(self, *args, **kwargs):\n            return func(self, *args, **kwargs)\n        wrapper.__unit_of_work__ = metadata or {}\n        wrapper.__timeout__ = timeout or {}\n        return wrapper\n    return decorator\n"]}
{"_id": "62e60e05d76274f8a4026cfd", "generate_results": ["def index(self, key):\n    return self._keys.index(key)", "def index(self, key):\n\n\nreturn self.__keys.index(key)", "def index(self, key):\n    return self._index[key]", "def index(self, key):\n    \n    \n    return self._get_index(key)", "def index(self, key):\n    return self._keys.index(key)", "def index(self, key):\n    if self._is_valid_index(key):\n        return key\n    else:\n        raise IndexError(\"Key is not in the list.\")", "def index(self, key):\n    return self._keys.index(key)", "def index(self, key):\n    return key % self.size", "def index(self, key):\nif key in self.keys():\nreturn self.__index__(key)\nelse:\nraise KeyError(\"Key not in hash.\")", "def index(self, key):\n    return self._keys.index(key)"]}
{"_id": "62e60da4d76274f8a4026cf1", "generate_results": ["def values(self, *keys):\n    \n    \n    return [self[key] for key in keys]\n", "def values(self, *keys):\n    return [self[key] for key in keys]", "def values(self, *keys):\n    return [self[key] for key in keys]\n", "def values(self, *keys):\n    \n    \n    return [self._data[key] for key in keys]", "def values(self, *keys):\n    return [self[key] for key in keys]\n", "def values(self, *keys):\n    return list(self.__getitem__(key) for key in keys)", "def values(self, *keys):\n    return [self[key] for key in keys]\n", "def values(self, *keys):\n    return [self[k] for k in keys]", "def values(self, *keys):\n    return [self.get(key) for key in keys]", "def values(self, *keys):\n    return [self[key] for key in keys]\n"]}
{"_id": "62e60b10d76274f8a4026ccd", "generate_results": ["def data(self, *keys):\n    return tuple(self._transform.data(key) for key in keys)\n", "def data(self, *keys):\n    return self._data.get(*keys)\n", "def data(self, *keys):\n    return self._transform(keys)", "def data(self, *keys):\n    return [self._process_key(k) for k in keys]\n", "def data(self, *keys):\n    \n    \n    return self._transform(*keys)\n", "def data(self, *keys):\n    return self._exporter.data(*keys)", "def data(self, *keys):\n    return self._transform_keys(keys)\n", "def data(self, *keys):\n    return keys", "def data(self, *keys):\n    return keys", "def data(self, *keys):\n    return self._data.get(*keys)"]}
{"_id": "62e6087bd76274f8a4026bfa", "generate_results": ["def pop_u16(self):\n    return self.data.pop(), self.data.pop()\n", "def pop_u16(self):\n    return self.data.pop() + (self.data.pop() << 8)\n", "def pop_u16(self):\n    if self.is_empty():\n        raise Empty(\"Stack is empty\")\n    return self.data.pop(), self.data.pop()\n", "def pop_u16(self):\n    return self.data.pop(), self.data.pop()", "def pop_u16(self):\n    popped_u16 = self.data[-2:]\n    self.data = self.data[:-2]\n    return popped_u16", "def pop_u16(self):\n    popped = self.data[-2:]\n    self.data = self.data[:-2]\n    return popped", "def pop_u16(self):\n    return self.data.pop() << 8 | self.data.pop()\n", "def pop_u16(self):\n    return self.data.pop(), self.data.pop()\n", "def pop_u16(self):\n    if len(self.data) > 1:\n        data_pop = self.data.pop()\n        self.data.pop()\n        return data_pop\n    else:\n        return None", "def pop_u16(self):\n    return self.data.pop(), self.data.pop()"]}
{"_id": "62e6087ad76274f8a4026bf2", "generate_results": ["def discard(self, n=-1, qid=-1, dehydration_hooks=None,\n                hydration_hooks=None, **handlers):\n    \n    \n    raise NotImplementedError(\"%s does not implement discard\" % (self.driver_name))\n", "def discard(self, n=-1, qid=-1, dehydration_hooks=None,\n                hydration_hooks=None, **handlers):\n    \n    \n    return self.__add__(self._get_item(qid, dehydration_hooks,\n                                         hydration_hooks, **handlers))", "def discard(self, n=-1, qid=-1, dehydration_hooks=None,\n                hydration_hooks=None, **handlers):\n    self._check_open()\n    return self._do_discard(n, qid, dehydration_hooks, hydration_hooks,\n                            **handlers)", "def discard(self, n=-1, qid=-1, dehydration_hooks=None,\n                hydration_hooks=None, **handlers):\n    \n    \n    return self._discard(n, qid, dehydration_hooks,\n                          hydration_hooks, **handlers)", "def discard(self, n=-1, qid=-1, dehydration_hooks=None,\n                hydration_hooks=None, **handlers):\n    \n    \n    pass", "def discard(self, n=-1, qid=-1, dehydration_hooks=None,\n                hydration_hooks=None, **handlers):\n    self.discard_item(n, qid, dehydration_hooks, hydration_hooks,\n                      **handlers)", "def discard(self, n=-1, qid=-1, dehydration_hooks=None,\n                hydration_hooks=None, **handlers):\n    self._check_not_closed()\n    r = libguestfsmod.discard(self._o, n, qid, dehydration_hooks,\n                                                                                                                                                                                                                                                                                                                                                                                                                                                            ", "def discard(self, n=-1, qid=-1, dehydration_hooks=None,\n                hydration_hooks=None, **handlers):\n    self.__discard(n, qid, dehydration_hooks, hydration_hooks, **handlers)", "def discard(self, n=-1, qid=-1, dehydration_hooks=None,\n                hydration_hooks=None, **handlers):\n    return self.__push__(self.__discard__(n, qid, dehydration_hooks,\n                                           hydration_hooks), **handlers)\n", "def discard(self, n=-1, qid=-1, dehydration_hooks=None,\n                hydration_hooks=None, **handlers):\n    raise NotImplementedError(\"discard not implemented yet\")"]}
{"_id": "62e60879d76274f8a4026bec", "generate_results": ["def begin(self, mode=None, bookmarks=None, metadata=None, timeout=None,\n              db=None, imp_user=None, dehydration_hooks=None,\n              hydration_hooks=None, **handlers):\n    \n    \n    return self._fetch_resource(\n        resource=BeginResource,\n        mode=mode,\n        bookmarks=bookmarks,\n        metadata=metadata,\n        timeout=timeout,\n        db=db,\n        imp_user=imp_user,\n        dehydration_hooks=dehydration_hooks,\n        hydration_hooks=hydration_hooks,\n        **handlers\n    )", "def begin(self, mode=None, bookmarks=None, metadata=None, timeout=None,\n              db=None, imp_user=None, dehydration_hooks=None,\n              hydration_hooks=None, **handlers):\n    \n    \n    return self.__begin(mode, bookmarks, metadata, timeout,\n                        db, imp_user, dehydration_hooks,\n                        hydration_hooks, **handlers)", "def begin(self, mode=None, bookmarks=None, metadata=None, timeout=None,\n              db=None, imp_user=None, dehydration_hooks=None,\n              hydration_hooks=None, **handlers):\n    if db is not None:\n        raise ValueError(\"Database not supported\")\n    if imp_user is not None:\n        raise ValueError(\"Implied user not supported\")\n    if dehydration_hooks is not None:\n        raise ValueError(\"Dehydration hooks not supported\")\n    self.__exit__(None, None, None)\n", "def begin(self, mode=None, bookmarks=None, metadata=None, timeout=None,\n              db=None, imp_user=None, dehydration_hooks=None,\n              hydration_hooks=None, **handlers):\n    return self._command('begin', mode, bookmarks, metadata, timeout,\n                         db, imp_user, dehydration_hooks, hydration_hooks,\n                         **handlers)", "def begin(self, mode=None, bookmarks=None, metadata=None, timeout=None,\n              db=None, imp_user=None, dehydration_hooks=None,\n              hydration_hooks=None, **handlers):\n    \n    \n    return _events.begin(self, mode, bookmarks, metadata, timeout, db,\n                          imp_user, dehydration_hooks, hydration_hooks,\n                          **handlers)\n", "def begin(self, mode=None, bookmarks=None, metadata=None, timeout=None,\n              db=None, imp_user=None, dehydration_hooks=None,\n              hydration_hooks=None, **handlers):\n    \n    \n    if not db:\n        db = self.database\n    if not imp_user:\n        imp_user = self.imp_user\n    return self._execute(\n            db, imp_user, \"BEGIN\", mode, bookmarks, metadata, timeout,\n            **handlers)", "def begin(self, mode=None, bookmarks=None, metadata=None, timeout=None,\n              db=None, imp_user=None, dehydration_hooks=None,\n              hydration_hooks=None, **handlers):\n    return self._begin(mode, bookmarks, metadata, timeout, db, imp_user,\n                       dehydration_hooks, hydration_hooks, 'D', **handlers)\n", "def begin(self, mode=None, bookmarks=None, metadata=None, timeout=None,\n              db=None, imp_user=None, dehydration_hooks=None,\n              hydration_hooks=None, **handlers):\n    return self._replace(mode=mode, bookmarks=bookmarks, metadata=metadata,\n                         timeout=timeout, db=db, imp_user=imp_user,\n                         dehydration_hooks=dehydration_hooks,\n                         hydration_hooks=hydration_hooks,\n                         **handlers)", "def begin(self, mode=None, bookmarks=None, metadata=None, timeout=None,\n              db=None, imp_user=None, dehydration_hooks=None,\n              hydration_hooks=None, **handlers):\n    return self.execute(\n        'BEGIN', mode, bookmarks, metadata, timeout, db, imp_user,\n        dehydration_hooks, hydration_hooks, **handlers)", "def begin(self, mode=None, bookmarks=None, metadata=None, timeout=None,\n              db=None, imp_user=None, dehydration_hooks=None,\n              hydration_hooks=None, **handlers):\n    return self._execute_command(BEGIN, mode, bookmarks, metadata, timeout,\n                                 db, imp_user, dehydration_hooks,\n                                 hydration_hooks, handlers)"]}
{"_id": "62e60723d76274f8a4026b75", "generate_results": ["def round_half_to_even(n):\n    return round_half_to_even_inner(n)\n", "def round_half_to_even(n):\n    return n - n % 2\n", "def round_half_to_even(n):\n    return n - (n % 1)\n", "def round_half_to_even(n):\n    return round(n / 2) * 2\n", "def round_half_to_even(n):\n    return int(round(n * 2))\n", "def round_half_to_even(n):\n    return round(n + 0.5) * 2\n", "def round_half_to_even(n):\n    return n + 0.5\n", "def round_half_to_even(n):\n    return ((n + 0.5) // 2) * 2\n", "def round_half_to_even(n):\n    return n if n % 2 == 0 else n + 0.5\n", "def round_half_to_even(n):\n    return int(n + 0.5)\n"]}
{"_id": "62e60707d76274f8a4026b69", "generate_results": ["def point_type(name, fields, srid_map):\n    return type(\n        name,\n        (Point,),\n        dict(\n            fields=fields,\n            srid=srid_map['SRID'],\n            geom_type=srid_map['GEOMETRYCOLLECTION']))", "def point_type(name, fields, srid_map):\n    \n    \n    from shapely.geometry import Point\n\n    return {\n        'type': 'Point',\n        'coordinates': [\n            {\n                'type':'string',\n                'coerce': lambda v: srid_map[v],\n            } for v in fields\n        ]\n    }\n", "def point_type(name, fields, srid_map):\n    return type(name, (Point,), {\n        '__fields__': fields,\n        '__srid__': srid_map[name],\n    })\n", "def point_type(name, fields, srid_map):\n    \n    \n    class Point(models.Geometry):\n        def __init__(self, x, y, z):\n            super().__init__(name, fields, srid_map)\n            self.x = x\n            self.y = y\n            self.z = z\n\n    return Point", "def point_type(name, fields, srid_map):\n    \n    \n    pt_type = Point(name, fields, srid_map)\n    return pt_type\n", "def point_type(name, fields, srid_map):\n    \n    \n    return type(name, (Point,), {\n        'fields': fields,\n       'srid_map': srid_map\n    })\n", "def point_type(name, fields, srid_map):\n    return type('Point', (Point,), {\n        'name': name,\n        'fields': fields,\n       'srid': srid_map[name]\n    })\n", "def point_type(name, fields, srid_map):\n    \n    \n    point = Point(name, fields, srid_map)\n    return point\n", "def point_type(name, fields, srid_map):\n    \n    \n    pt = Point(name, fields, srid_map)\n    return pt\n", "def point_type(name, fields, srid_map):\n    \n    \n    return type(name, fields, {'srid': srid_map['SRID']})\n"]}
{"_id": "62e5dc9ed76274f8a4026b5b", "generate_results": ["def deprecated(message):\n\n    def decorator(func):\n        \"\"\"Decorate a function.\"\"\"\n\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            \"\"\"Wrapper function.\"\"\"\n            warnings.warn(message, category=DeprecationWarning, stacklevel=2)\n            return func(*args, **kwargs)\n\n        return wrapper\n\n    return decorator\n", "def deprecated(message):\n    def decorator(func):\n        def new_func(*args, **kwargs):\n            warnings.warn(message, DeprecationWarning, stacklevel=2)\n            return func(*args, **kwargs)\n        new_func.__name__ = func.__name__\n        new_func.__doc__ = func.__doc__\n        return new_func\n    return decorator", "def deprecated(message):\n    def _deprecated(func):\n        @functools.wraps(func)\n        def _deprecated_func(*args, **kwargs):\n            warnings.warn(\n                message,\n                category=DeprecationWarning,\n                stacklevel=2)\n            return func(*args, **kwargs)\n        return _deprecated_func\n    return _deprecated\n", "def deprecated(message):\n    def decorator(func):\n        @functools.wraps(func)\n        def deprecated_func(*args, **kwargs):\n            warnings.warn(message, DeprecationWarning)\n            return func(*args, **kwargs)\n        return deprecated_func\n    return decorator\n", "def deprecated(message):\n\n    def decorator(func):\n        \"\"\"Decorator function.\"\"\"\n\n        @functools.wraps(func)\n        def new_func(*args, **kwargs):\n            \"\"\"Wrapper function.\"\"\"\n            warnings.warn(message, category=DeprecationWarning)\n            return func(*args, **kwargs)\n\n        return new_func\n\n    return decorator\n", "def deprecated(message):\n    def deprecated_decorator(func):\n        @functools.wraps(func)\n        def new_func(*args, **kwargs):\n            warnings.warn_explicit(message, DeprecationWarning, __file__, func.__name__)\n            return func(*args, **kwargs)\n        return new_func\n    return deprecated_decorator\n", "def deprecated(message):\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            warnings.warn(message, DeprecationWarning, stacklevel=2)\n            return func(*args, **kwargs)\n        return wrapper\n    return decorator", "def deprecated(message):\n    def decorator(func):\n        @functools.wraps(func)\n        def new_func(*args, **kwargs):\n            warnings.warn(message, category=DeprecationWarning, stacklevel=2)\n            return func(*args, **kwargs)\n        return new_func\n    return decorator\n", "def deprecated(message):\n    def decorator(func):\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            warnings.warn(\n                \"%s is deprecated and will be removed in a future version.\"\n                % func.__name__,\n                DeprecationWarning,\n                stacklevel=2,\n            )\n            return func(*args, **kwargs)\n\n        return wrapper\n\n    return decorator\n", "def deprecated(message):\n    def decorator(func):\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            warnings.warn(message, category=DeprecationWarning)\n            return func(*args, **kwargs)\n        return wrapper\n    return decorator"]}
{"_id": "62e4fc3c85ea98643089041e", "generate_results": ["def _inline_r_setup(code: str) -> str:\n    return code.replace(\"D\", \"D\\n\")\n", "def _inline_r_setup(code: str) -> str:\n    return code\n", "def _inline_r_setup(code: str):\n    return code.replace('D', 'R')\n", "def _inline_r_setup(code: str):\n    code = code.replace('{', '').replace('}', '')\n    code = code.replace('(', '').replace(')', '')\n    code = code.replace(',', '')\n    code = code.replace(':', '')\n    code = code.replace(',', '')\n    code = code.replace(';', '')\n    code = code.replace('\\'', '')\n    code = code.replace('\\\"', '')\n    code = code.replace('\\\\', '')\n    return code", "def _inline_r_setup(code: str):\n    return {'D': ''}\n", "def _inline_r_setup(code: str):\n    return {'D'}", "def _inline_r_setup(code: str, doc: str, meta: dict):\n    return \"\"\"\n        D = {};\n    \"\"\".format(code)\n", "def _inline_r_setup(code: str, body: str) -> str:\n    return '{}{}'.format(code, body)\n", "def _inline_r_setup(code: str) -> str:\n    return code.format(\"R\")\n", "def _inline_r_setup(code: str) -> str:\n    return '\\\\D' + code\n"]}
{"_id": "62e4fbda85ea986430890405", "generate_results": ["def xargs(\n        cmd: str,\n        args: List[str],\n        env: Optional[Dict[str, str]] = None,\n        stdin=None,\n        stdout=None,\n        stderr=None,\n        input=None,\n        stdout_is_tty=False,\n        stderr_is_tty=False,\n        cwd=None,\n        shell=False,\n        env_in_shell=False,\n        **kwargs) -> List[str]:\n    \n    \n    if not env:\n        env = os.environ.copy()\n    env.update(kwargs)\n    return _run_subprocess(\n        [\"xargs\"] + args,\n        env=env,\n        stdin=stdin,\n        stdout=stdout,\n        stderr=stderr,\n        cwd=cwd)\n", "def xargs(\n        cmd: str,\n        *args: str,\n        **kwargs: str) -> str:\n    \n    \n    return run_in_subprocess(\"xargs --\", cmd, *args, **kwargs)\n", "def xargs(\n        cmd: str,\n        *args,\n        **kwargs) -> str:\n    return subprocess.check_output(cmd, *args, **kwargs).decode()\n", "def xargs(\n        cmd: str,\n        *args: str,\n        env: Dict[str, str] = None,\n        cwd: Optional[str] = None,\n        **kwargs: str) -> str:\n    \n    \n    cmd = _convert_cmd(cmd)\n    return _run_cmd(cmd, *args, env=env, cwd=cwd, **kwargs)\n", "def xargs(\n        cmd: str,\n        args: list,\n        cwd: str = None,\n        env: dict = None,\n        stdin: str = None,\n        stdout: str = None,\n        stderr: str = None,\n        **kwargs: dict\n):\n    \n    \n    cmd = _get_cmd(cmd)\n    return run(cmd, args, cwd=cwd, env=env, stdin=stdin, stdout=stdout, stderr=stderr, **kwargs)\n", "def xargs(\n        cmd: List[str]\n) -> Optional[List[str]]:\n    \n    \n    try:\n        return subprocess.check_output(cmd, universal_newlines=True)\n    except subprocess.CalledProcessError as e:\n        return e.output.strip()\n", "def xargs(\n        cmd: str,\n        *args: str,\n        **kwargs: Any) -> str:\n    \n    \n    return subprocess.check_output(\n        cmd.split() + list(args),\n        **kwargs\n    ).decode().strip()", "def xargs(\n        cmd: str,\n        *args: str,\n        stdin: Optional[str] = None,\n        stdout: Optional[str] = None,\n        stderr: Optional[str] = None,\n        shell: bool = False,\n        **kwargs: Any) -> str:\n    \n    \n    return _run_cmd(cmd, args, stdin, stdout, stderr, shell, 'xargs')\n", "def xargs(\n        cmd: str,\n        *args: str,\n        stdin: Optional[str] = None,\n        stdout: Optional[str] = None,\n        stderr: Optional[str] = None,\n        timeout: Optional[int] = None,\n        stdin_file: Optional[str] = None,\n        env: Optional[Dict[str, str]] = None,\n        **kwargs: str\n) -> str:\n    return cmd_line(\n        cmd,\n        args=args,\n        stdin=stdin,\n        stdout=stdout,\n        stderr=stderr,\n        timeout=timeout,\n        stdin_file=stdin_file,\n        env=env,\n        **kwargs\n    )", "def xargs(\n        cmd: str,\n        stdin: Optional[str] = None,\n        stdout: Optional[str] = None,\n        stderr: Optional[str] = None,\n        shell: bool = True,\n        **kwargs) -> str:\n    \n    \n    return sh(\"{0} {1}\".format(cmd, \" \".join((stdin, stdout, stderr))), shell=shell)\n"]}
{"_id": "62e4fbda85ea986430890403", "generate_results": ["def _shuffled(seq: Sequence[Any], fixed_seed: int) -> List[Any]:\n    random.seed(fixed_seed)\n    return random.sample(seq, len(seq))\n", "def _shuffled(seq: Sequence[T], fixed_seed: int) -> Sequence[T]:\n    np.random.seed(fixed_seed)\n    return seq[np.random.permutation(len(seq))]\n", "def _shuffled(seq: Sequence[T], fixed_random_seed: int) -> Sequence[T]:\n    return random.sample(seq, len(seq))\n", "def _shuffled(seq: Sequence[T], fixed_seed: int) -> Sequence[T]:\n    \n    \n    np.random.seed(fixed_seed)\n    return seq[np.random.permutation(len(seq))]\n", "def _shuffled(seq: Sequence[T], fixed_seed: int) -> Sequence[T]:\n    return _seq_shuffled(seq, fixed_seed)\n", "def _shuffled(seq: Sequence, fixed_random_seed: int) -> Sequence:\n    \n    \n    random.seed(fixed_random_seed)\n    return list(zip(*seq))\n", "def _shuffled(seq: Sequence, fixed_random_seed: int) -> List[Sequence]:\n    \n    \n    return list(seq) + [fixed_random_seed] * (len(seq) - len(seq) % fixed_random_seed)\n", "def _shuffled(seq: Sequence[S], fixed_random_seed: int) -> Sequence[S]:\n    \n    \n    return _seq_shuffle(seq, fixed_random_seed)\n", "def _shuffled(seq: Sequence[T], fixed_seed: int) -> Sequence[T]:\n    np.random.seed(fixed_seed)\n    return np.random.permutation(seq)\n", "def _shuffled(seq: Iterable[T], fixed_random_seed: int) -> Iterable[T]:\n    random.seed(fixed_random_seed)\n    return random.sample(seq, len(seq))\n"]}
{"_id": "62e4fb6585ea98643089032b", "generate_results": ["def parse_version(s: str) -> Tuple[int,...]:\n    return tuple(int(part) for part in s.split(\".\"))\n", "def parse_version(s: str) -> Tuple[int,...]:\n    return tuple(map(int, s.split('.')))\n", "def parse_version(s: str) -> Tuple[int,...]:\n    return tuple(int(x) for x in s.split(\".\"))\n", "def parse_version(s: str) -> Tuple[int,...]:\n    return tuple(int(s[i]) for i in range(len(s)))\n", "def parse_version(s: str) -> Tuple[int,...]:\n    return tuple(map(int, s.split('.')))\n", "def parse_version(s: str) -> tuple:\n    return tuple(int(x) for x in s.split('.'))\n", "def parse_version(s: str) -> tuple:\n    return tuple(map(int, s.split(\".\")))\n", "def parse_version(s: str) -> tuple:\n    \n    \n    return tuple(map(int, s.split('.')))\n", "def parse_version(s: str) -> Tuple[int,...]:\n    return tuple(map(int, s.split(\".\")))\n", "def parse_version(s: str) -> tuple:\n    \n    \n    return tuple(map(int, s.split('.')))\n"]}
{"_id": "62e4fb4d85ea9864308902e7", "generate_results": ["def normalize_cmd(cmd: str) -> str:\n    if not cmd.startswith(\"/\"):\n        cmd = \"/\" + cmd\n    return cmd\n", "def normalize_cmd(cmd: str) -> str:\n    return cmd.split(\" \")[0] + \" \" + \" \".join(cmd.split(\" \")[1:])\n", "def normalize_cmd(cmd: str) -> str:\n    cmd_parts = cmd.split(\" \")\n    cmd_parts[0] = \"--\" + cmd_parts[0]\n    return \" \".join(cmd_parts)\n", "def normalize_cmd(cmd: str) -> str:\n    return cmd.replace(\"/usr/bin/\", \"/usr/bin/\").replace(\"/usr/sbin/\", \"/usr/sbin/\")\n", "def normalize_cmd(cmd: str) -> str:\n    return cmd.replace(\"/usr/bin/\", \"/bin/\")\n", "def normalize_cmd(cmd: str) -> str:\n    return''.join(['~', cmd])", "def normalize_cmd(cmd: str) -> str:\n    return cmd.replace(\"/\", \"_\")\n", "def normalize_cmd(cmd: str) -> str:\n    return cmd.strip().replace(\"/\", \"\\\\\")\n", "def normalize_cmd(cmd: str) -> str:\n    \n    \n    return cmd.replace(\"/bin/cmd\", \"/bin/bash\")\n", "def normalize_cmd(cmd: str) -> str:\n    \n    \n    return cmd.replace(\"/usr/bin/\", \"/usr/local/bin/\")\n"]}
{"_id": "62b8d27a48ba5a41d1c3f4c6", "generate_results": ["def cached(cache, key=hashkey, lock=None):\n    def decorator(f):\n        @wraps(f)\n        def decorated_function(*args, **kwargs):\n            key = key(*args, **kwargs)\n            result = cache.get(key, None)\n            if result is None:\n                result = f(*args, **kwargs)\n                cache.set(key, result, timeout=cache_timeout)\n            return result\n        return decorated_function\n    return decorator\n", "def cached(cache, key=hashkey, lock=None):\n    def decorator(f):\n        def wrapper(*args, **kwargs):\n            key = key(*args, **kwargs)\n            result = cache.get(key)\n            if not result:\n                result = f(*args, **kwargs)\n                cache.set(key, result, cache.timeout)\n            return result\n        return wrapper\n    return decorator", "def cached(cache, key=hashkey, lock=None):\n    def decorator(f):\n        def decorator_wrapper(*args, **kwargs):\n            if not key in cache:\n                cache[key] = f(*args, **kwargs)\n            return cache[key]\n        return decorator_wrapper\n    return decorator\n", "def cached(cache, key=hashkey, lock=None):\n    def decorator(func):\n        def wrapper(*args, **kwargs):\n            result = func(*args, **kwargs)\n            cache.set(key(*args, **kwargs), result, lock=lock)\n            return result\n        return wrapper\n    return decorator", "def cached(cache, key=hashkey, lock=None):\n    def decorator(func):\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            result = cache.get(key, None)\n            if result is None:\n                result = func(*args, **kwargs)\n                cache.set(key, result, timeout=CACHE_TIMEOUT)\n            return result\n        return wrapper\n    return decorator\n", "def cached(cache, key=hashkey, lock=None):\n    def decorator(func):\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            result = cache.get(key(*args, **kwargs))\n            if result is None:\n                result = func(*args, **kwargs)\n                cache.set(key(*args, **kwargs), result, timeout=cache_timeout)\n            return result\n        return wrapper\n    return decorator\n", "def cached(cache, key=hashkey, lock=None):\n    def decorator(func):\n        def wrapper(*args, **kwargs):\n            result = cache.get(key, None)\n            if result is None:\n                result = func(*args, **kwargs)\n                cache.set(key, result, timeout=cache._timeout)\n            return result\n        return wrapper\n    return decorator\n", "def cached(cache, key=hashkey, lock=None):\n    def decorator(func):\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            result = cache.get(key)\n            if not result:\n                result = func(*args, **kwargs)\n                cache.set(key, result, cache.get_expiration_time(key))\n            return result\n        return wrapper\n    return decorator\n", "def cached(cache, key=hashkey, lock=None):\n    \n    \n    def decorator(func):\n        def cached_func(*args, **kwargs):\n            result = func(*args, **kwargs)\n            cache.set(key, result, timeout=cache_timeout)\n            return result\n        return cached_func\n    return decorator", "def cached(cache, key=hashkey, lock=None):\n    \n    \n    def wrapper(func):\n        @functools.wraps(func)\n        def wrapped(*args, **kwargs):\n            key = key(*args, **kwargs)\n            result = cache.get(key)\n            if result is None:\n                result = func(*args, **kwargs)\n                cache.set(key, result, lock)\n            return result\n        return wrapped\n    return wrapper\n"]}
{"_id": "62b8d24048ba5a41d1c3f49f", "generate_results": ["def ttl_cache(maxsize=128, ttl=600, timer=time.monotonic, typed=False):\n    return ttl_cache_with_timer(maxsize, ttl, timer, typed)\n", "def ttl_cache(maxsize=128, ttl=600, timer=time.monotonic, typed=False):\n    return _cache(None, maxsize, ttl, timer, typed)\n", "def ttl_cache(maxsize=128, ttl=600, timer=time.monotonic, typed=False):\n    return TTLCache(maxsize=maxsize, ttl=ttl, timer=timer, typed=typed)", "def ttl_cache(maxsize=128, ttl=600, timer=time.monotonic, typed=False):\n    return TTLCache(maxsize, ttl, timer, typed)", "def ttl_cache(maxsize=128, ttl=600, timer=time.monotonic, typed=False):\n    return _cache_wrapper(None, maxsize, ttl, timer, typed)\n", "def ttl_cache(maxsize=128, ttl=600, timer=time.monotonic, typed=False):\n    return cache(None, maxsize, ttl, timer, typed)\n", "def ttl_cache(maxsize=128, ttl=600, timer=time.monotonic, typed=False):\n    return cache(maxsize=maxsize, ttl=ttl, timer=timer, typed=typed, _get=_get)", "def ttl_cache(maxsize=128, ttl=600, timer=time.monotonic, typed=False):\n    return cache(maxsize, ttl, timer, typed)", "def ttl_cache(maxsize=128, ttl=600, timer=time.monotonic, typed=False):\n    return _ttl_cache(maxsize, ttl, timer, typed)", "def ttl_cache(maxsize=128, ttl=600, timer=time.monotonic, typed=False):\n    return TTLCache(maxsize, ttl, timer, typed)"]}
{"_id": "62b8d23b48ba5a41d1c3f49a", "generate_results": ["def mru_cache(maxsize=128, typed=False):\n    return mru_cache_with_type(None, maxsize, typed)\n", "def mru_cache(maxsize=128, typed=False):\n    return mru_cache_impl(None, maxsize, typed)\n", "def mru_cache(maxsize=128, typed=False):\npass", "def mru_cache(maxsize=128, typed=False):\n    pass", "def mru_cache(maxsize=128, typed=False):\n    return None", "def mru_cache(maxsize=128, typed=False):\n    return dict()\n", "def mru_cache(maxsize=128, typed=False):\n    return _CacheWrapper(_mru_cache, maxsize, typed)\n", "def mru_cache(maxsize=128, typed=False):\npass", "def mru_cache(maxsize=128, typed=False):\n    return Cache(maxsize, typed)\n", "def mru_cache(maxsize=128, typed=False):\n    \n    \n    return dict()\n"]}
{"_id": "62b8d23948ba5a41d1c3f498", "generate_results": ["def lru_cache(maxsize=128, typed=False):\n    return LRUCache(maxsize, typed)", "def lru_cache(maxsize=128, typed=False):\n    return LRUCache(maxsize, typed)", "def lru_cache(maxsize=128, typed=False):\n    return LRUCache(maxsize, typed)", "def lru_cache(maxsize=128, typed=False):\n    return LRUCache(maxsize, typed)\n", "def lru_cache(maxsize=128, typed=False):\n    return LRUCache(maxsize, typed)", "def lru_cache(maxsize=128, typed=False):\n    return LRUCache(maxsize, typed)\n", "def lru_cache(maxsize=128, typed=False):\n    return LRUCache(maxsize, typed)", "def lru_cache(maxsize=128, typed=False):\n    return LRUCache(maxsize, typed)\n", "def lru_cache(maxsize=128, typed=False):\n    return LRUCached(maxsize, typed)\n", "def lru_cache(maxsize=128, typed=False):\n    return _LRUCache(maxsize, typed)\n"]}
{"_id": "62b8d23748ba5a41d1c3f496", "generate_results": ["def lfu_cache(maxsize=128, typed=False):\n    \n    \n    return LRUCache(maxsize=maxsize, typed=typed)", "def lfu_cache(maxsize=128, typed=False):\n    \n    \n    return lfu_cache_with_type(maxsize, typed)\n", "def lfu_cache(maxsize=128, typed=False):\n    return lfu_cache_impl(maxsize, typed)\n", "def lfu_cache(maxsize=128, typed=False):\n    return LRUCache(maxsize, typed)", "def lfu_cache(maxsize=128, typed=False):\n    return LRUCache(maxsize, typed)", "def lfu_cache(maxsize=128, typed=False):\n    return cache(None, maxsize, typed)", "def lfu_cache(maxsize=128, typed=False):\n    return cache(maxsize, typed, False)\n", "def lfu_cache(maxsize=128, typed=False):\n    return LRUCache(maxsize, typed)", "def lfu_cache(maxsize=128, typed=False):\n    return cache(maxsize, typed, True)\n", "def lfu_cache(maxsize=128, typed=False):\n    return LRUCache(maxsize, typed)"]}
{"_id": "62b8d22f48ba5a41d1c3f488", "generate_results": ["def popitem(self):\n    raise NotImplementedError()", "def popitem(self):\n    return self._data.popitem()", "def popitem(self):\n    if self.is_empty():\n        raise KeyError('Key not found')\n\n    key = self._keys[0]\n    value = self._values.pop(0)\n    self._keys.remove(key)\n    self._values.remove(value)\n    return key, value", "def popitem(self):\n    pass", "def popitem(self):\n    if self._head is None:\n        raise KeyError('The dictionary is empty.')\n\n    key = self._head._key\n    value = self._head._value\n    self._head = self._head._next\n\n    if self._head is None:\n        self._tail = None\n\n    return key, value", "def popitem(self):\n    k = self.__keys[-1]\n    self.__keys = self.__keys[:-1]\n    return (k, self[k])", "def popitem(self):\n    if not self._root:\n        raise KeyError('Key not in tree')\n\n    self._root, self._root_value = self._root.popitem()\n    return self._root._key, self._root_value", "def popitem(self):\n    k = self._keys[-1]\n    item = self._items[-1]\n    del self[k]\n    return k, item\n", "def popitem(self):\n    return self.__db.lpop(self.key)", "def popitem(self):\n    return self.__data.popitem()"]}
{"_id": "62b8d22a48ba5a41d1c3f47e", "generate_results": ["def setdefault(self, key, default=None):\n    if key not in self:\n        self[key] = default\n    return self[key]\n", "def setdefault(self, key, default=None):\n    if key in self:\n        return self[key]\n    self[key] = default\n    return default\n", "def setdefault(self, key, default=None):\n    try:\n        return self[key]\n    except KeyError:\n        self[key] = default\n        return default", "def setdefault(self, key, default=None):\n    try:\n        return self[key]\n    except KeyError:\n        self[key] = default\n        return default\n", "def setdefault(self, key, default=None):\nif key not in self:\nself[key] = default\nreturn self[key]", "def setdefault(self, key, default=None):\n    return self.__dict__.setdefault(key, default)", "def setdefault(self, key, default=None):\n    try:\n        return self[key]\n    except KeyError:\n        self[key] = default\n        return default\n", "def setdefault(self, key, default=None):\n    if key not in self:\n        self[key] = default\n    return self[key]\n", "def setdefault(self, key, default=None):\n    try:\n        return self[key]\n    except KeyError:\n        self[key] = default\n        return default\n", "def setdefault(self, key, default=None):\n    if key not in self:\n        self[key] = default\n    return self[key]\n"]}
{"_id": "62b8d22948ba5a41d1c3f47c", "generate_results": ["def get(self, key, default=None):\nif key in self._dict:\nreturn self._dict[key]\nelse:\nreturn default\n", "def get(self, key, default=None):\nif key in self.__dict__:\nreturn self.__dict__[key]\nreturn default", "def get(self, key, default=None):\nif key in self.__dict__:\nreturn self.__dict__[key]\nelse:\nreturn default\n", "def get(self, key, default=None):\n    return self.__data.get(key, default)", "def get(self, key, default=None):\ntry:\nreturn self[key]\nexcept KeyError:\nreturn default", "def get(self, key, default=None):\ntry:\nreturn self[key]\nexcept KeyError:\nreturn default\n", "def get(self, key, default=None):\nreturn self.__dict__.get(key, default)", "def get(self, key, default=None):\ntry:\nreturn self.__getitem__(key)\nexcept KeyError:\nreturn default", "def get(self, key, default=None):\n    try:\n        return self[key]\n    except KeyError:\n        return default", "def get(self, key, default=None):\nif key in self.__dict__:\nreturn self.__dict__[key]\nreturn default"]}
{"_id": "62b8d22548ba5a41d1c3f472", "generate_results": ["def cachedmethod(cache, key=hashkey, lock=None):\n    def decorator(func):\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            result = cache.get(key, None)\n            if result is None:\n                result = func(*args, **kwargs)\n                cache.set(key, result, timeout=timeout)\n            return result\n        return wrapper\n    return decorator\n", "def cachedmethod(cache, key=hashkey, lock=None):\n    def decorator(func):\n        @wraps(func)\n        def wrapper(self, *args, **kwargs):\n            try:\n                return cache[key(self, *args, **kwargs)]\n            except KeyError:\n                result = func(self, *args, **kwargs)\n                cache[key(self, *args, **kwargs)] = result\n                return result\n        return wrapper\n    return decorator", "def cachedmethod(cache, key=hashkey, lock=None):\n\n    def decorator(func):\n        return cachedmethod_(cache, key, func, lock)\n\n    return decorator", "def cachedmethod(cache, key=hashkey, lock=None):\n    \n    \n    def decorator(func):\n        def wrapper(self, *args, **kwargs):\n            try:\n                return cache[key(self, *args, **kwargs)]\n            except KeyError:\n                result = func(self, *args, **kwargs)\n                cache[key(self, *args, **kwargs)] = result\n                return result\n        return wrapper\n    return decorator\n", "def cachedmethod(cache, key=hashkey, lock=None):\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(self, *args, **kwargs):\n            if key in cache:\n                result = cache[key]\n                cache[key] = result.copy()\n                return result\n            result = func(self, *args, **kwargs)\n            cache[key] = result.copy()\n            return result\n        return wrapper\n    return decorator\n", "def cachedmethod(cache, key=hashkey, lock=None):\n    def decorator(fn):\n        def call(*args, **kwargs):\n            key = key(*args, **kwargs)\n            if lock is None:\n                lock = Lock()\n            try:\n                return cache.get(key, lock=lock)\n            except KeyError:\n                result = fn(*args, **kwargs)\n                cache.set(key, result, lock=lock)\n                return result\n        return call\n    return decorator", "def cachedmethod(cache, key=hashkey, lock=None):\n    def decorator(f):\n        @wraps(f)\n        def wrapper(*args, **kwargs):\n            if lock is None:\n                lock = Lock()\n            result = cache.get(key, f, args, kwargs, lock)\n            if result is None:\n                result = f(*args, **kwargs)\n                cache.set(key, result, timeout=CACHE_TIMEOUT)\n            return result\n        return wrapper\n    return decorator\n", "def cachedmethod(cache, key=hashkey, lock=None):\n    def decorator(func):\n        def wrapper(*args, **kwargs):\n            try:\n                return cache[key(*args, **kwargs)]\n            except KeyError:\n                result = func(*args, **kwargs)\n                cache[key(*args, **kwargs)] = result\n                return result\n        return wrapper\n    return decorator\n", "def cachedmethod(cache, key=hashkey, lock=None):\n    def decorator(func):\n        def wrapper(*args, **kw):\n            key = key(*args, **kw)\n            result = cache.get(key)\n            if not result:\n                result = func(*args, **kw)\n                cache.set(key, result, timeout=timeout)\n            return result\n        return wrapper\n    return decorator\n", "def cachedmethod(cache, key=hashkey, lock=None):\n    def decorator(func):\n        def wrapper(*args, **kwargs):\n            key = key(*args, **kwargs)\n            return cache.get(key, lock=lock)\n        return wrapper\n    return decorator\n"]}
{"_id": "62b8c517e0d34b282c18122e", "generate_results": ["def extostr(cls, e, max_level=30, max_path_level=5):\n    \n    \n    levels = [\"error\"] * max_level\n    paths = [\"%s:%s\" % (e.filename, e.lineno) for e in e.exceptions]\n    paths.sort()\n    levels[max_path_level] = \"%s path %s\" % (levels[max_path_level], paths)\n    return \"%s%s\" % (levels[0], cls.__name__)\n", "def extostr(cls, e, max_level=30, max_path_level=5):\n    exc_type = e.__class__.__name__\n    exc_value = e\n    exc_traceback = traceback.format_exc()\n    return ''.join(['%s: %s\\n' % (exc_type, exc_value), exc_traceback,\n                    '\\n' + '-' * (max_level - len(exc_type))])\n", "def extostr(cls, e, max_level=30, max_path_level=5):\n    return \"%s: %s\" % (cls.__name__, str(e))\n", "def extostr(cls, e, max_level=30, max_path_level=5):\n    return _format_exception(cls, e, max_level, max_path_level)", "def extostr(cls, e, max_level=30, max_path_level=5):\n    return ''.join([cls.__name__, ': ', str(e),\n                    '\\n', 'Max level = ', str(max_level),\n                    '\\n', 'Max path level = ', str(max_path_level)])", "def extostr(cls, e, max_level=30, max_path_level=5):\n    \n    \n    return str(cls) + \": \" + str(e)\n", "def extostr(cls, e, max_level=30, max_path_level=5):\n    \n    \n    tb = sys.exc_info()[2]\n    if tb:\n        tb = ''.join(traceback.format_tb(tb))\n    else:\n        tb = ''\n    return '{}: {}: {}'.format(cls.__name__, e.__class__.__name__, tb)\n", "def extostr(cls, e, max_level=30, max_path_level=5):\n    return '%s: %s' % (cls.__name__, e)\n", "def extostr(cls, e, max_level=30, max_path_level=5):\n    \n    \n    if max_level == 0:\n        return str(e)\n    if max_path_level == 0:\n        return str(e).replace('\\n', '\\n\\t')\n    if max_path_level <= 0:\n        return str(e).replace('\\n', '\\n\\t').replace('\\t', '\\t\\t')\n    return str(e).replace('\\n', '\\n\\t').replace('\\t', '\\t\\t').replace('\\n\\t', '\\n\\t\\t')", "def extostr(cls, e, max_level=30, max_path_level=5):\n    s = \"\"\n    if e.__class__.__name__ == \"ValueError\":\n        s = \"ValueError (%s)\" % e.args[0]\n    else:\n        s = repr(e)\n    if max_level > 0:\n        s = \"%s\\n(%s)\" % (s, \" \".join(traceback.format_exception(cls, e, max_path_level)))\n    return s\n\n\n# Convenience functions for handling the exception"]}
{"_id": "62b8bbbfe0d34b282c181210", "generate_results": ["def append_text_to_file(file_name, text_buffer, encoding, overwrite=False):\n    \n    \n    if not overwrite and os.path.exists(file_name):\n        raise FileExistsError(\"File '{}' already exists.\".format(file_name))\n    with open(file_name, 'a', encoding=encoding) as file:\n        file.write(text_buffer)\n    return True", "def append_text_to_file(file_name, text_buffer, encoding, overwrite=False):\n    if overwrite or os.path.exists(file_name):\n        with open(file_name, 'a', encoding=encoding) as out_file:\n            out_file.write(text_buffer)\n    else:\n        print(\"File '{}' already exists\".format(file_name))\n", "def append_text_to_file(file_name, text_buffer, encoding, overwrite=False):\n    \n    \n    with codecs.open(file_name, 'a', encoding) as file:\n        file.write(text_buffer)\n        if overwrite:\n            file.write(\"\\n\")\n", "def append_text_to_file(file_name, text_buffer, encoding, overwrite=False):\n    with codecs.open(file_name, 'a', encoding) as f:\n        f.write(text_buffer)\n        if overwrite or not os.path.isfile(file_name):\n            f.close()\n", "def append_text_to_file(file_name, text_buffer, encoding, overwrite=False):\n    \n    \n    with codecs.open(file_name, \"a\", encoding) as f:\n        f.write(text_buffer)\n    if overwrite:\n        os.remove(file_name)", "def append_text_to_file(file_name, text_buffer, encoding, overwrite=False):\n    \n    \n    if not overwrite:\n        file_name = file_name + \".txt\"\n    with codecs.open(file_name, \"a\", encoding=encoding) as f:\n        f.write(text_buffer)\n", "def append_text_to_file(file_name, text_buffer, encoding, overwrite=False):\n    \n    \n    if overwrite:\n        with open(file_name, 'w', encoding=encoding) as f:\n            f.write(text_buffer)\n    else:\n        with open(file_name, 'a', encoding=encoding) as f:\n            f.write(text_buffer)\n", "def append_text_to_file(file_name, text_buffer, encoding, overwrite=False):\n    if not overwrite and os.path.exists(file_name):\n        raise IOError('File %s already exists' % file_name)\n\n    with codecs.open(file_name, 'w', encoding) as file:\n        file.write(text_buffer)", "def append_text_to_file(file_name, text_buffer, encoding, overwrite=False):\n    if overwrite or not os.path.exists(file_name):\n        with open(file_name, 'w', encoding=encoding) as f:\n            f.write(text_buffer)\n            f.close()\n    else:\n        print('File already exists. No need to overwrite')\n", "def append_text_to_file(file_name, text_buffer, encoding, overwrite=False):\n    with codecs.open(file_name, 'a', encoding=encoding) as f:\n        f.write(text_buffer)\n        if overwrite:\n            os.remove(file_name)\n"]}
{"_id": "62b8bbbfe0d34b282c18120f", "generate_results": ["def file_to_textbuffer(file_name, encoding):\n    text_buffer = None\n    if encoding:\n        text_buffer = gtk.TextBuffer()\n        text_buffer.set_text(open(file_name, encoding=encoding).read())\n    else:\n        text_buffer = gtk.TextBuffer()\n        text_buffer.set_text(open(file_name, 'r').read())\n    return text_buffer", "def file_to_textbuffer(file_name, encoding):\n    \n    \n    file_handle = open(file_name, 'r', encoding=encoding)\n    text_buffer = file_handle.read()\n    file_handle.close()\n    return text_buffer\n", "def file_to_textbuffer(file_name, encoding):\n    \n    \n    return file_to_text(file_name, encoding, sys.stdout)\n", "def file_to_textbuffer(file_name, encoding):\n    buffer = gtk.TextBuffer()\n    with open(file_name, 'r', encoding=encoding) as file:\n        buffer.set_text(file.read())\n    return buffer", "def file_to_textbuffer(file_name, encoding):\n    \n    \n    return get_text_buffer(file_name, encoding)\n", "def file_to_textbuffer(file_name, encoding):\n    buffer = gtk.TextBuffer()\n    buffer.set_text(open(file_name, 'rb').read().decode(encoding))\n    return buffer", "def file_to_textbuffer(file_name, encoding):\n    \n    \n    with codecs.open(file_name, 'r', encoding) as f:\n        return f.read()\n", "def file_to_textbuffer(file_name, encoding):\n    with open(file_name, \"r\", encoding=encoding) as file:\n        return file.read()\n", "def file_to_textbuffer(file_name, encoding):\n    text_buffer = gtk.TextBuffer()\n    text_buffer.set_text(read_file(file_name, encoding))\n    return text_buffer\n", "def file_to_textbuffer(file_name, encoding):\n    \n    \n    text_buffer = gtk.TextBuffer()\n    text_buffer.set_text(open(file_name, 'r', encoding=encoding).read())\n    return text_buffer\n"]}
{"_id": "62b8bbbce0d34b282c18120d", "generate_results": ["def is_file_exist(file_name):\n    return os.path.isfile(file_name)\n", "def is_file_exist(file_name):\n    return os.path.isfile(file_name)\n", "def is_file_exist(file_name):\n    return os.path.isfile(file_name)\n", "def is_file_exist(file_name):\n    if os.path.isfile(file_name):\n        return True\n    return False\n", "def is_file_exist(file_name):\n    return os.path.isfile(file_name)\n", "def is_file_exist(file_name):\n    \n    \n    return os.path.isfile(file_name)\n", "def is_file_exist(file_name):\n    if not os.path.isfile(file_name):\n        return False\n    return True\n", "def is_file_exist(file_name):\n    \n    \n    return os.path.isfile(file_name)\n", "def is_file_exist(file_name):\n    return os.path.isfile(file_name)\n", "def is_file_exist(file_name):\n    return os.path.isfile(file_name)\n"]}
{"_id": "62b8b99de0d34b282c1811f8", "generate_results": ["def _reset_logging(cls):\n    if cls._logging is None:\n        return\n    for logger in cls._logging.values():\n        logger.removeHandler(cls._handler)\n    cls._logging = None\n", "def _reset_logging(cls):\n    \n    \n    cls.log = _Logger()\n", "def _reset_logging(cls):\n    \n    \n    logger = logging.getLogger('sss')\n    logger.handlers = []\n    logger.setLevel(logging.INFO)\n", "def _reset_logging(cls):\n    global _log_handler\n    _log_handler = None\n    _logger = logging.getLogger('py_dap')\n    _logger.handlers = []\n    _logger.propagate = False", "def _reset_logging(cls):\n    \n    \n    logging.basicConfig(format='%(asctime)s %(levelname)s: %(message)s',\n                        datefmt='%Y-%m-%d %H:%M:%S',\n                        level=logging.INFO)\n", "def _reset_logging(cls):\n    logging.disable(logging.CRITICAL)\n", "def _reset_logging(cls):\n    logging.getLogger().handlers = []\n    logging.basicConfig(level=logging.DEBUG)\n", "def _reset_logging(cls):\n    \n    \n    global _LOGGER\n    _LOGGER = logging.getLogger(\"%s.%s\" % (cls.__module__, cls.__name__))\n", "def _reset_logging(cls):\n    _logger = logging.getLogger(cls.__module__)\n    for handler in _logger.handlers:\n        handler.close()\n    _logger.removeHandler(_logger.handlers[0])\n    _logger.addHandler(logging.NullHandler())\n", "def _reset_logging(cls):\n    cls._logger = logging.getLogger(__name__)\n    cls._logger.handlers = []\n    cls._logger.setLevel(logging.DEBUG)\n"]}
{"_id": "62b8b59feb7e40a82d2d1291", "generate_results": ["def _getTargetClass(self):\nreturn Summit\n", "def _getTargetClass(self):\nreturn Leaf\n", "def _getTargetClass(self):\nreturn Sequence", "def _getTargetClass(self):\nreturn ParseTarget", "def _getTargetClass(self):\nreturn SplitLines", "def _getTargetClass(self):\nreturn Compound\n", "def _getTargetClass(self):\nreturn Square", "def _getTargetClass(self):\nreturn Square", "def _getTargetClass(self):\nreturn Role", "def _getTargetClass(self):\nreturn Gaussian2D"]}
{"_id": "62b8b590eb7e40a82d2d1275", "generate_results": ["def _legacy_mergeOrderings(orderings):\n    return list(set(itertools.chain.from_iterable(orderings)))", "def _legacy_mergeOrderings(orderings):\n    if not orderings:\n        return []\n    return sorted(set(_mergeOrderings(orderings)))\n", "def _legacy_mergeOrderings(orderings):\n    result = []\n    for o in orderings:\n        if o not in result:\n            result.append(o)\n    return result\n", "def _legacy_mergeOrderings(orderings):\n    return list(set(orderings))", "def _legacy_mergeOrderings(orderings):\n    return sorted(set([o.pop() for o in orderings]))\n", "def _legacy_mergeOrderings(orderings):\n    \n    \n    return [_mergeOrderings(o) for o in orderings]", "def _legacy_mergeOrderings(orderings):\n    return [o for o in orderings if len(o) > 1]", "def _legacy_mergeOrderings(orderings):\n    orderings = [list(o) for o in orderings]\n    return [o for o in itertools.chain.from_iterable(orderings) if o]\n", "def _legacy_mergeOrderings(orderings):\n    result = []\n    for i in range(0, len(orderings)):\n        if i == 0:\n            result.extend(orderings[i])\n        else:\n            result.extend(orderings[i][:-1])\n    return result\n", "def _legacy_mergeOrderings(orderings):\n    # FIXME: this is very hacky.\n    return sorted(set(itertools.chain.from_iterable(orderings)))\n"]}
{"_id": "62b8b58deb7e40a82d2d1269", "generate_results": ["def directlyProvidedBy(object):\n    return None", "def directlyProvidedBy(object):\npass", "def directlyProvidedBy(object):\npass", "def directlyProvidedBy(object):\n    return None", "def directlyProvidedBy(object):\n    return None", "def directlyProvidedBy(object):\n    pass", "def directlyProvidedBy(object):\npass", "def directlyProvidedBy(object):\n    pass\n", "def directlyProvidedBy(object):\npass", "def directlyProvidedBy(object):\n    return None"]}
{"_id": "62b8b559eb7e40a82d2d11f8", "generate_results": ["def minimalBases(classes):\n    \n    \n    return [c for c in classes if not c.__subclasses__()]\n", "def minimalBases(classes):\n    \n    \n    return [c for c in classes if issubclass(c, Base)]\n", "def minimalBases(classes):\n    \n    \n    return [c for c in classes if not issubclass(c, Base)]\n", "def minimalBases(classes):\n    return [c for c in classes if not issubclass(c, Base)]\n", "def minimalBases(classes):\n    return [c for c in classes if not isinstance(c, type)]", "def minimalBases(classes):\n    return [c for c in classes if not c.__subclasses__()]\n", "def minimalBases(classes):\n    return [c for c in classes if not c.__subclasses__()]\n", "def minimalBases(classes):\n    return [c for c in classes if not issubclass(c, Base)]\n", "def minimalBases(classes):\n    return [c for c in classes if issubclass(c, Base)]\n", "def minimalBases(classes):\n    \n    \n    return [classes[i] for i in classes.keys() if not issubclass(classes[i], Base)]\n"]}
{"_id": "62b8b4b9eb7e40a82d2d1134", "generate_results": ["def namesAndDescriptions(self, all=False):\n    \n    \n    if all:\n        return [name, description]\n    return [name, self.description]\n", "def namesAndDescriptions(self, all=False):\n    \n    \n    names = []\n    descriptions = []\n    for name, attr in inspect.getmembers(self):\n        if inspect.isclass(attr) and not inspect.isabstract(attr):\n            if not all:\n                names.append(name)\n                descriptions.append(getattr(attr, '__doc__', ''))\n            else:\n                descriptions.append(getattr(attr, '__doc__', ''))\n    return names, descriptions\n", "def namesAndDescriptions(self, all=False):\n    if all:\n        return self.namesAndDescriptions_all()\n    else:\n        return self.namesAndDescriptions_single()", "def namesAndDescriptions(self, all=False):\n    \n    \n    if all:\n        names = self.names()\n        return names\n    else:\n        names = self.names()\n        return [(n, d.get('description')) for n, d in names]\n", "def namesAndDescriptions(self, all=False):\n    if all:\n        return [(self.__class__.__name__, self.description)]\n    else:\n        return [(self.__name__, self.description)]\n\n# TODO: Make this separate from the current class definition.", "def namesAndDescriptions(self, all=False):\n    \n    \n    if all:\n        return [(k, v.__doc__) for (k, v) in self.__dict__.items()]\n    else:\n        return [(k, self.__dict__[k]) for k in self.__dict__.keys()]\n", "def namesAndDescriptions(self, all=False):\n    \n    \n    return [(k, v.name) for k, v in self.__class__.__dict__.items() if not k.startswith('__')]", "def namesAndDescriptions(self, all=False):\n    names = []\n    descriptions = []\n    if all:\n        names = self.__dict__.keys()\n        descriptions = self.__dict__.values()\n    else:\n        names = self.__dict__.keys()\n        descriptions = self.__dict__.values()\n    for name, description in zip(names, descriptions):\n        if isinstance(description, str):\n            description = description.strip()\n        name = str(name)\n        if description:\n            description = str(description)\n        names.append(name)\n        descriptions.append(description)\n    return names, descriptions\n", "def namesAndDescriptions(self, all=False):\n    if all:\n        return [(name, self.descriptions[name]) for name in self.attributes]\n    else:\n        return [(name, self.descriptions[name]) for name in self.attributes if self.descriptions[name] is not None]", "def namesAndDescriptions(self, all=False):\n    \n    \n    if all:\n        return self.namesAndDescriptions_all\n    return self.namesAndDescriptions_single\n"]}
{"_id": "62b8b416eb7e40a82d2d1129", "generate_results": ["def names(self, all=False):\n    if all:\n        return self.__dict__.keys()\n    return [k for k in self.__dict__.keys()]", "def names(self, all=False):\n    \n    \n    names = []\n    for attr in dir(self):\n        if attr.startswith(\"__\") or not attr.isupper():\n            continue\n        if attr!= '__dict__' and not all:\n            continue\n        names.append(attr)\n    return names", "def names(self, all=False):\n    return self.attributes(all)[:]\n", "def names(self, all=False):\n    if all:\n        return self.__dict__.keys()\n    else:\n        return self.__class__.__dict__.keys()", "def names(self, all=False):\n    return [name for name in self.__dict__.keys() if name[0]!= '_']", "def names(self, all=False):\n    \n    \n    if all:\n        return self.__dict__.keys()\n    else:\n        return [k for k in self.__dict__.keys() if not k.startswith('_')]", "def names(self, all=False):\n    \n    \n    if all:\n        return [name for name in dir(self) if name.startswith('_')]\n    else:\n        return [name for name in self.__dict__.keys()]", "def names(self, all=False):\n    \n    \n    return self.get_names(all)", "def names(self, all=False):\n    if all:\n        return self.__dict__.keys()\n    else:\n        return self.__class__.__dict__.keys()\n", "def names(self, all=False):\n    if all:\n        return dir(type(self))\n    return [name for name in dir(type(self)) if not name.startswith('_')]\n"]}
{"_id": "62b8b3d6eb7e40a82d2d111c", "generate_results": ["def _normalizeargs(sequence, output=None):\n    if output is None:\n        output = sequence\n    return sequence / sequence.max(axis=0, keepdims=True)\n", "def _normalizeargs(sequence, output=None):\n    if output is None:\n        output = []\n    for elt in sequence:\n        if isinstance(elt, list):\n            _normalizeargs(elt, output)\n        elif isinstance(elt, str):\n            output.append(elt)\n        elif isinstance(elt, tuple):\n            _normalizeargs(elt, output)\n        else:\n            output.append(elt)\n    return output\n", "def _normalizeargs(sequence, output=None):\n    output = output or []\n    for item in sequence:\n        if item in output:\n            continue\n        output.append(item)\n    return output\n", "def _normalizeargs(sequence, output=None):\n    return sequence", "def _normalizeargs(sequence, output=None):\n    if output is None:\n        output = sequence\n    else:\n        if not isinstance(output, list):\n            output = [output]\n        for i in range(len(output)):\n            output[i] = _normalizearg(output[i])\n    return output", "def _normalizeargs(sequence, output=None):\n    if output is None:\n        output = []\n    for item in sequence:\n        if isinstance(item, (list, tuple)):\n            _normalizeargs(item, output)\n        else:\n            output.append(item)\n    return output", "def _normalizeargs(sequence, output=None):\n    if output is None:\n        output = []\n    if isinstance(sequence, str):\n        sequence = sequence.split(\";\")\n    for i, arg in enumerate(sequence):\n        sequence[i] = _normalizearg(arg, output=output)\n    return sequence", "def _normalizeargs(sequence, output=None):\n    return sequence", "def _normalizeargs(sequence, output=None):\n    \n    \n    if output is None:\n        output = sequence\n    for i in range(len(output)):\n        output[i] = _normalize(output[i])\n    return output\n", "def _normalizeargs(sequence, output=None):\n    return [_normalize(arg, output) for arg in sequence]"]}
{"_id": "62b8b3d5eb7e40a82d2d1110", "generate_results": ["def _c_optimizations_available():\n    if 'c_optimizations' in __opts__:\n        return __opts__['c_optimizations']\n    else:\n        return False", "def _c_optimizations_available():\n    from sympy.optimize import OptimizeResult\n\n    try:\n        import c_optimizations\n        return c_optimizations\n    except ImportError:\n        return False\n", "def _c_optimizations_available():\n    \n    \n    try:\n        from c_optimizations import Optimizations\n        return Optimizations\n    except ImportError:\n        return False\n", "def _c_optimizations_available():\n    \n    \n    return __salt__['config.option']('c_optimizations.available')\n", "def _c_optimizations_available():\n    import c_optimizations\n    return c_optimizations\n", "def _c_optimizations_available():\n    try:\n        from scipy.optimize import c_optimize\n        return c_optimize\n    except ImportError:\n        return False\n", "def _c_optimizations_available():\n    \n    \n    if not hasattr(_c_optimizations, '__c_optimizations_available__'):\n        # Attribute is not available, return false\n        return False\n\n    # Return the C optimization module\n    return _c_optimizations.__c_optimizations_available__\n", "def _c_optimizations_available():\n    try:\n        from pysph.base.c_optimizations import COptimizations\n        return COptimizations\n    except ImportError:\n        return False\n", "def _c_optimizations_available():\n    return _c_optimizations_available_module or c_optimizations\n", "def _c_optimizations_available():\n    \n    \n    try:\n        from pycbc.optimization import COptimization\n        return COptimization\n    except ImportError:\n        return False\n"]}
{"_id": "62b8b3d4eb7e40a82d2d110f", "generate_results": ["def _should_attempt_c_optimizations():\n  return (_use_c_optimizer() and _use_c_optimizer_impl())\n", "def _should_attempt_c_optimizations():\n  return (_should_use_saved_model() and\n          not _is_in_saved_model_context() and\n          not _is_in_infer_context_scope())\n", "def _should_attempt_c_optimizations():\n  return FLAGS.optimizations_use_c_optimizations\n", "def _should_attempt_c_optimizations():\n    return _get_option(\"optimization.c-optimizations\") or _get_option(\"optimization.c-optimizations-disable\")\n", "def _should_attempt_c_optimizations():\n  return _c_optimization_enabled() and not _should_attempt_gpu_optimizations()\n", "def _should_attempt_c_optimizations():\n  if _config.use_c_optimizations and not _config.use_grad_norm:\n    return True\n  return _config.use_grad_norm\n", "def _should_attempt_c_optimizations():\n  # pylint: disable=g-explicit-bool-comparison\n  return not bool(\n      inspect.getargspec(\n          tf.python_io.TF_NewStyleOptimizer.__init__)[0]) and (\n          _OPTIMIZERS_ENABLED or _TF_OPTIMIZERS_ENABLED)\n", "def _should_attempt_c_optimizations():\n    return _should_use_avg_objective() or _should_use_avg_gradient()", "def _should_attempt_c_optimizations():\n    return (get_options().use_c_optimizations and\n            get_options().use_c_optimizations_on_c_code)\n", "def _should_attempt_c_optimizations():\n  return (_is_in_c_library() and\n          context.executing_eagerly() and\n          not context.executing_eagerly_outside_functions())\n"]}
{"_id": "62b8b3d4eb7e40a82d2d110e", "generate_results": ["def _c_optimizations_ignored():\n    \n    \n    return _os.environ.get(\"PURE_PYTHON\", 0) == 0 and _os.environ.get(\"PURE_PYTHON_OPTIMIZATIONS\", 0) == 0\n", "def _c_optimizations_ignored():\n    return (_c_optimizations_environ() is not None and\n            not _c_optimizations_environ())\n", "def _c_optimizations_ignored():\n    return not (get_env(\"PURE_PYTHON\") is None and\n                get_env(\"PURE_PYTHON_ABI\") is None)", "def _c_optimizations_ignored():\n    return (get_environ() and get_environ().get(\"PURE_PYTHON\")!= \"0\")\n", "def _c_optimizations_ignored():\n    return _c_optimizations_env_var() is not None and _c_optimizations_env_var()!= 0\n", "def _c_optimizations_ignored():\n    global _c_optimizations_ignored\n    return _c_optimizations_ignored", "def _c_optimizations_ignored():\n    return get_c_optimizations()!= None and get_c_optimizations()!= 0\n\n", "def _c_optimizations_ignored():\n    return bool(get_c_optimizations())\n", "def _c_optimizations_ignored():\n    return 'PURE_PYTHON' not in os.environ and os.environ['PURE_PYTHON']!= '0'\n", "def _c_optimizations_ignored():\n    \n    \n    return (environ.get('PURE_PYTHON', 0)!= 0) and (environ.get('PURE_PYTHON', 0)!= 0)"]}
{"_id": "62b8b3d4eb7e40a82d2d110d", "generate_results": ["def _c_optimizations_required():\n    return _c_optimizations_required_or_not() and _c_optimizations_required_or_not()", "def _c_optimizations_required():\n    return c_optimizations_required\n", "def _c_optimizations_required():\n    return \"-O3 -g -Wall -fsync -mcpu -pipe\" in _get_config_vars()", "def _c_optimizations_required():\n    return _c_optimizations() and _c_optimizations_enabled()\n", "def _c_optimizations_required():\n    return _c_optimizations_required_for_backend(backend)", "def _c_optimizations_required():\n    return not _c_optimizations_in_use()\n", "def _c_optimizations_required():\n    return _c_optimizations_required_and_no_c_optimizations()\n", "def _c_optimizations_required():\n    \n    \n    return True\n", "def _c_optimizations_required():\n    return _c_optimizations_required_impl() and _c_optimizations_required_external()\n", "def _c_optimizations_required():\n    if _c_optimizations_required_ is None:\n        _c_optimizations_required_ = has_option(\"optimizations\", \"c_optimizations\")\n    return _c_optimizations_required_"]}
{"_id": "62b87b989a0c4fa8b80b35ee", "generate_results": ["def reset(self):\n    self.__dict__ = {}\n    self.make_bins()\n    self._is_setup = False\n", "def reset(self):\nself._current_context = {}\nself._current_bins = []", "def reset(self):\n\n    self._bins = {}", "def reset(self):\nself.__init__(**self.make_bins())\n", "def reset(self):\nself.__init__()\n\n\n# ====================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================", "def reset(self):\nself._context = {}\nself._bins = self.make_bins()", "def reset(self):\n    self.__dict__.clear()\n    self.make_bins()", "def reset(self):\n    self.__init__()\n", "def reset(self):\n    self.__dict__.clear()\n    self.make_bins()", "def reset(self):\nself.__init__(self.make_bins())\n"]}
{"_id": "62b87b859a0c4fa8b80b35d7", "generate_results": ["def to_csv(self, separator=\",\", header=None):\n    \n    \n    return separator.join(self.__str__().split(separator))\n", "def to_csv(self, separator=\",\", header=None):\n    return None\n", "def to_csv(self, separator=\",\", header=None):\n    return separator.join([str(self.column_type)] + [str(self.value)])", "def to_csv(self, separator=\",\", header=None):\n    pass\n", "def to_csv(self, separator=\",\", header=None):\n    if header:\n        self.output_file.write(header + \"\\n\")\n    for i in range(self.number_of_rows):\n        self.output_file.write(\"{0}{1}\".format(separator, i))\n        for j in range(self.number_of_cols):\n            self.output_file.write(\" \")\n        self.output_file.write(\"\\n\")\n", "def to_csv(self, separator=\",\", header=None):\n    return separator.join(self.headers) if header is None else separator.join(header)\n", "def to_csv(self, separator=\",\", header=None):\n    \n    \n    return None", "def to_csv(self, separator=\",\", header=None):\n    \n    \n    if header:\n        self.header = header\n    else:\n        self.header = \"\"\n    self.data = self.data.to_csv(sep=separator)\n    return self\n", "def to_csv(self, separator=\",\", header=None):\n    if header is None:\n        header = []\n    for row in self:\n        if header is None:\n            header.append(row)\n        else:\n            header.append(row)\n    return separator.join([i.to_csv(separator) for i in header])\n", "def to_csv(self, separator=\",\", header=None):\n    return self.to_list(header=header) + separator.join(self.to_list(header=header))\n"]}
{"_id": "62b87b839a0c4fa8b80b35cb", "generate_results": ["def _get_err_indices(self, coord_name):\n    return [idx for idx, val in enumerate(self._coords[coord_name])\n            if val!= 0]\n", "def _get_err_indices(self, coord_name):\n    return [i for i, coord in enumerate(self.coords) if coord.name == coord_name]\n", "def _get_err_indices(self, coord_name):\n    err_indices = []\n    for i, c in enumerate(self._coords):\n        if c == coord_name:\n            err_indices.append(i)\n    return err_indices\n", "def _get_err_indices(self, coord_name):\n    \n    \n    coords = self.get_coords(coord_name)\n    err_indices = []\n    for i, coord in enumerate(coords):\n        if coord is not None:\n            err_indices.append(i)\n    return err_indices\n", "def _get_err_indices(self, coord_name):\n    \n    \n    return [idx for idx, err in enumerate(self.errors) if err.coord_name == coord_name]", "def _get_err_indices(self, coord_name):\n    \n    \n    return [i for i, (k, v) in enumerate(self.coords.items()) if k == coord_name]\n", "def _get_err_indices(self, coord_name):\n    return self._coord_to_err_idx[coord_name]\n", "def _get_err_indices(self, coord_name):\n    return [i for i, c in enumerate(self._coords) if c.name == coord_name]", "def _get_err_indices(self, coord_name):\n    for err_index, err_coord in enumerate(self._coords):\n        if err_coord.name() == coord_name:\n            return err_index\n    return -1\n", "def _get_err_indices(self, coord_name):\n    return np.where(self.coord_names == coord_name)[0]"]}
{"_id": "62b87b7e9a0c4fa8b80b35bc", "generate_results": ["def _update_context(self, context):\n    pass\n", "def _update_context(self, context):\n    pass\n", "def _update_context(self, context):\n    \n    \n    pass", "def _update_context(self, context):\npass", "def _update_context(self, context):\n    pass\n", "def _update_context(self, context):\n    pass\n", "def _update_context(self, context):\n    pass\n", "def _update_context(self, context):\npass", "def _update_context(self, context):\n    pass", "def _update_context(self, context):\n    pass\n"]}
{"_id": "62b87b4f9a0c4fa8b80b3580", "generate_results": ["def integral(bins, edges):\n    \n    \n    return sum(bins[edges[i]:edges[i+1]] * edges[i] for i in range(len(edges)-1))\n", "def integral(bins, edges):\n    return np.trapz(bins * edges, edges)\n", "def integral(bins, edges):\n    return np.trapz(bins, edges)\n", "def integral(bins, edges):\n    \n    \n    return np.trapz(bins[edges], bins[:-1])\n", "def integral(bins, edges):\n    \n    \n    total = 0\n    for i in range(len(bins)-1):\n        total += (bins[i+1] - bins[i]) * (edges[i+1] - edges[i])\n    return total\n", "def integral(bins, edges):\n    \n    \n    return np.trapz(bins * edges, edges)\n", "def integral(bins, edges):\n    integral = 0.0\n    for i in range(0, len(bins)):\n        integral += bins[i] * (edges[i] - edges[i - 1])\n    return integral\n", "def integral(bins, edges):\n    return np.trapz(bins, edges)\n", "def integral(bins, edges):\n    return np.trapz(edges, bins=bins)\n", "def integral(bins, edges):\n    return np.trapz(bins, edges)\n"]}
{"_id": "62b87b199a0c4fa8b80b354e", "generate_results": ["def is_fill_request_seq(seq):\n    return isinstance(seq, FillRequestSeq)\n", "def is_fill_request_seq(seq):\n    try:\n        _ = FillRequestSeq(seq)\n        return True\n    except Exception:\n        return False\n", "def is_fill_request_seq(seq):\n    return (isinstance(seq, FillRequestSeq) or\n            isinstance(seq, type(False)) or\n            isinstance(seq, bool))\n", "def is_fill_request_seq(seq):\n    if not is_seq(seq):\n        return False\n    if len(seq) < 4:\n        return False\n    if seq[0] == \"F\":\n        return False\n    if seq[0] == \"R\":\n        return True\n    if seq[0] == \"N\":\n        return False\n    if seq[0] == \"-\":\n        return True\n    if seq[0] == \".\":\n        return True\n    if seq[0] == \"--\":\n        return True\n    if seq[0] == \"-.\":\n        return True\n    return False\n", "def is_fill_request_seq(seq):\n    return isinstance(seq, FillRequestSeq)\n", "def is_fill_request_seq(seq):\n    if type(seq) == FillRequestSeq:\n        return True\n    elif type(seq) == bool:\n        return seq\n    else:\n        raise TypeError(\"Expecting FillRequestSeq or bool type\")\n", "def is_fill_request_seq(seq):\n    if isinstance(seq, FillRequestSeq):\n        return True\n    if isinstance(seq, bool):\n        return seq\n    if isinstance(seq, (int, float)):\n        return False\n    if isinstance(seq, (list, tuple)):\n        return is_fill_request_seq(seq[0]) and is_fill_request_seq(seq[1])\n    if isinstance(seq, dict):\n        return is_fill_request_seq(seq[\"elements\"]) and is_fill_request_seq(seq[\"values\"])\n    raise TypeError(\"Unsupported type {} of {}\".format(type(seq), seq))\n", "def is_fill_request_seq(seq):\n    return isinstance(seq, FillRequestSeq)\n", "def is_fill_request_seq(seq):\n    try:\n        seq.toseq()\n        return True\n    except AssertionError:\n        return False\n", "def is_fill_request_seq(seq):\n    try:\n        FillRequestSeq(seq)\n        return True\n    except ValueError:\n        return False\n"]}
{"_id": "62b87b099a0c4fa8b80b3538", "generate_results": ["def is_fill_request_el(obj):\n    return (\n        hasattr(obj, 'fill') and\n        hasattr(obj,'request')\n    )\n", "def is_fill_request_el(obj):\n    return (\n        hasattr(obj, \"fill\") and\n        hasattr(obj, \"request\")\n    )\n", "def is_fill_request_el(obj):\n    return (\n        obj.tag == 'fill' and\n        hasattr(obj,'request') and\n        hasattr(obj,'shape')\n    )\n", "def is_fill_request_el(obj):\n    return (\n        obj.__class__.__name__ == 'FillRequest'\n        and obj.fill.__class__.__name__ == 'Fill'\n        and obj.request.__class__.__name__ == 'Request'\n    )\n", "def is_fill_request_el(obj):\n    return (\n        hasattr(obj, 'fill') and hasattr(obj,'request') and\n        hasattr(obj, 'fill_request')\n    )\n", "def is_fill_request_el(obj):\n    return (\n        obj.fill_request\n        and hasattr(obj.fill_request, \"serialize\")\n        and hasattr(obj.fill_request, \"deserialize\")\n    )\n", "def is_fill_request_el(obj):\n    return (obj.tag == add_ns('Fill', 'http://schema.org/Fill')\n            and obj.get('request') is not None)\n", "def is_fill_request_el(obj):\n    return ('fill' in dir(obj) and\n            hasattr(obj.fill, '__call__') and\n            hasattr(obj.fill,'request'))\n", "def is_fill_request_el(obj):\n    return (obj.tag == 'fill' and\n            hasattr(obj,'request') and\n            hasattr(obj,'request_id'))\n", "def is_fill_request_el(obj):\n    return (\n        isinstance(obj, FillRequest) and\n        obj.fill.attributes == request_attributes and\n        obj.request.attributes == request_attributes\n    )\n"]}
{"_id": "62b87af99a0c4fa8b80b3524", "generate_results": ["def is_run_el(obj):\n    return hasattr(obj, \"run\")\n", "def is_run_el(obj):\n    return hasattr(obj, 'run')\n", "def is_run_el(obj):\n    return hasattr(obj, 'run')\n", "def is_run_el(obj):\n    return hasattr(obj, 'run')\n", "def is_run_el(obj):\n    return hasattr(obj, 'run')\n", "def is_run_el(obj):\n    return hasattr(obj, 'run')\n", "def is_run_el(obj):\n    return hasattr(obj, 'run')\n", "def is_run_el(obj):\n    return hasattr(obj, 'run')\n", "def is_run_el(obj):\n    return hasattr(obj, 'run')\n", "def is_run_el(obj):\n    return hasattr(obj, 'run')\n"]}
{"_id": "62b87af69a0c4fa8b80b351a", "generate_results": ["def is_fill_compute_el(obj):\n    \n    \n    return hasattr(obj, 'fill') and hasattr(obj, 'compute')", "def is_fill_compute_el(obj):\n    return isinstance(obj, Fill) and hasattr(obj, 'compute')\n", "def is_fill_compute_el(obj):\n    return ((obj.__class__ is Fill and obj.fill_method is not None) or\n            (obj.__class__ is Compute and obj.fill_method is not None))\n", "def is_fill_compute_el(obj):\n    return hasattr(obj, '_fill_compute') and hasattr(obj, '_compute')\n", "def is_fill_compute_el(obj):\n    return hasattr(obj, '_fill_compute') and hasattr(obj, '_compute')\n", "def is_fill_compute_el(obj):\n    return (\n        inspect.isclass(obj)\n        and issubclass(obj, FillCompute)\n        and hasattr(obj, \"fill\")\n        and hasattr(obj, \"compute\")\n    )\n", "def is_fill_compute_el(obj):\n    return hasattr(obj, '_fill_methods') and hasattr(obj, '_compute_methods')\n", "def is_fill_compute_el(obj):\n    return (hasattr(obj, \"fill\") and hasattr(obj, \"compute\") and\n            callable(obj.fill) and callable(obj.compute))\n", "def is_fill_compute_el(obj):\n    return (hasattr(obj, '__class__') and\n            obj.__class__ in _fill_compute_methods)\n", "def is_fill_compute_el(obj):\n    return hasattr(obj, 'fill_') and hasattr(obj, 'compute_')\n"]}
{"_id": "62b87af19a0c4fa8b80b34f7", "generate_results": ["def difference(d1, d2, level=-1):\n    d = d1.copy()\n    for k, v in d2.items():\n        if k not in d:\n            d[k] = v\n    return d\n", "def difference(d1, d2, level=-1):\n    \n    \n    if not isinstance(d1, dict) or not isinstance(d2, dict):\n        return d2\n\n    if level == 0:\n        return d1\n\n    d = {}\n    for k in d1:\n        if k not in d2 or d1[k]!= d2[k]:\n            d[k] = d1[k]\n\n    return d\n", "def difference(d1, d2, level=-1):\n    \n    \n    diff = {}\n    for k, v in d1.items():\n        if k not in d2:\n            diff[k] = v\n    if level == -1:\n        return diff\n    else:\n        return difference_level(diff, level)\n", "def difference(d1, d2, level=-1):\n    return dict([(k, v) for k, v in d1.iteritems() if k not in d2])\n", "def difference(d1, d2, level=-1):\n    return __diff(d2, d1, 'difference', level)\n", "def difference(d1, d2, level=-1):\n    d = {}\n    for k, v in d1.items():\n        if k not in d2:\n            d[level] = v\n    return d\n", "def difference(d1, d2, level=-1):\n    return dict((key, value) for key, value in d1.iteritems() if key not in d2)", "def difference(d1, d2, level=-1):\n    d = {}\n    for k in d1:\n        if k not in d2:\n            d[k] = d1[k]\n        elif d1[k]!= d2[k]:\n            d[k] = d1[k]\n    if level >= 0:\n        for k in d2:\n            if k in d1:\n                d[k] = d2[k]\n    return d", "def difference(d1, d2, level=-1):\n    if level == 0:\n        return d1.copy()\n    d2 = d2.copy()\n    for k in d1:\n        if k not in d2:\n            d2[k] = d1[k]\n    return d2\n", "def difference(d1, d2, level=-1):\n    d = {}\n    for k, v in d1.iteritems():\n        if k not in d2:\n            d[k] = v\n    if level >= 0:\n        d = {k: v for k, v in d.iteritems() if k not in d1}\n    return d\n"]}
{"_id": "62b87af09a0c4fa8b80b34f1", "generate_results": ["def fill(self, coord, weight=1):\n    if coord in self.cells:\n        self.cells[coord].weight = weight\n        return True\n    return False", "def fill(self, coord, weight=1):\n    \n    \n    if not self.is_valid(coord):\n        return False\n    else:\n        self.board[coord] = weight\n        return True\n", "def fill(self, coord, weight=1):\n    if coord is None:\n        raise ValueError('coord is None')\n    self._coords.append(coord)\n    self._weights.append(weight)", "def fill(self, coord, weight=1):\n    \n    \n    return self._fill(coord, weight)", "def fill(self, coord, weight=1):\n    self.grid[coord[1]][coord[0]] = weight", "def fill(self, coord, weight=1):\n    self.place_at(coord, weight)", "def fill(self, coord, weight=1):\n    if not coord:\n        return\n    self.__fill(coord, weight)\n", "def fill(self, coord, weight=1):\n    \n    \n    pass", "def fill(self, coord, weight=1):\n    self.set_at(coord, weight)", "def fill(self, coord, weight=1):\n    if coord in self.coords:\n        self.coords[coord] += weight\n    else:\n        self.coords[coord] = weight\n"]}
{"_id": "62b86aa3b4d922cb0e688d36", "generate_results": ["def _validate_labels(labels):\n    validate_key(labels, 'labels')\n    validate_value(labels, 'labels', 'value')\n", "def _validate_labels(labels):\n    for key, value in labels.items():\n        if key not in _VALID_LABELS:\n            raise ValueError('Invalid label: %s. Valid labels: %s' %\n                             (key, _VALID_LABELS))\n        if isinstance(value, str):\n            raise ValueError('Invalid label: %s. Valid labels: %s' %\n                             (key, _VALID_LABELS))\n", "def _validate_labels(labels):\n    if not isinstance(labels, dict):\n        raise ValueError('labels must be a dict.')\n    if not all(isinstance(key, str) for key in labels.keys()):\n        raise ValueError('labels must contain only keys and values.')\n    if not all(isinstance(value, str) for value in labels.values()):\n        raise ValueError('labels must contain only keys and values.')\n", "def _validate_labels(labels):\n    for label in labels:\n        _validate_key(label)\n        _validate_value(label)\n", "def _validate_labels(labels):\n    if labels is None:\n        return\n    label_values = set(labels.values())\n    label_values.discard('')\n    if label_values!= set(('',)):\n        raise ValueError('invalid labels: %s' % str(labels))\n", "def _validate_labels(labels):\n    labels = labels.copy()\n    for k, v in labels.items():\n        if isinstance(v, dict):\n            _validate_labels(v)\n        elif isinstance(v, list):\n            for i in v:\n                _validate_labels(i)\n        elif v is None:\n            pass\n        elif not isinstance(v, string_types):\n            raise ValueError(\"Label '%s' must be a string\" % k)\n    return labels\n", "def _validate_labels(labels):\n    if labels is None:\n        return\n\n    if not isinstance(labels, dict):\n        raise TypeError('labels must be a dictionary')\n\n    if 'key' not in labels:\n        raise KeyError('labels must contain a key')\n\n    if 'value' not in labels:\n        raise ValueError('labels must contain a value')\n\n    if len(labels)!= len(set(labels.values())):\n        raise ValueError('labels must have unique values')\n", "def _validate_labels(labels):\n    for label in labels:\n        if not label.key:\n            raise ValueError(\"Label key is required\")\n\n        if not label.value:\n            raise ValueError(\"Label value is required\")\n", "def _validate_labels(labels):\n    for label in labels:\n        _validate_key(label)\n        _validate_value(label)\n", "def _validate_labels(labels):\n    for label in labels:\n        validate_key(label)\n        validate_value(label)\n"]}
{"_id": "62b86a9eb4d922cb0e688d25", "generate_results": ["def _get_resource_name_regex():\n    \n    \n    return [\n        r'^/projects/(?P<project>.+?)/resourceGroups/(?P<resource_group>.+?)/providers/Microsoft.Network'\n        r'/networks/(?P<network_name>.+?)/subnets/(?P<subnet>.+?)/routeRoutes/(?P<route_name>.+?)/gatewayRoutes/(?P<gateway_name>.+?)$',\n    ]\n", "def _get_resource_name_regex():\n    return [\n        r'^(?P<resource_name>.+)\\-(?P<resource_type>.+)$',\n        r'^(?P<resource_name>.+)\\-(?P<resource_type>.+)$',\n    ]\n", "def _get_resource_name_regex():\n    return r\"^(?P<resource_name>.*)\\.(?P<resource_version>\\d+)$\"\n", "def _get_resource_name_regex():\n    return r\"^.+/projects/(?P<project>.+)/zones/(?P<zone>.+)/clusters/(?P<cluster>.+)/resourceGroups/(?P<resource_group>.+)/providers/Microsoft.Network/subnets/(?P<subnet>.+)$\"", "def _get_resource_name_regex():\n    return [\n        r\"^resource-name/(?P<resource_name>.*)$\",\n    ]\n", "def _get_resource_name_regex():\n    return r\"^(?P<resource_name>.+)$\"\n", "def _get_resource_name_regex():\n    return [r\"^/(?P<project>.+?)/(?P<service>.+?)/(?P<resource_name>.+?)$\"]\n", "def _get_resource_name_regex():\n    return re.compile(r'^((?:https?://)?(?:www\\.)?krake\\.)?'\n                      r'((?:shared|shared_)?projects)/(.+)$')\n", "def _get_resource_name_regex():\n    return r\"^(?:(?:https?://)?(?:www\\.)?krake\\.com/resource/)?([\\w\\-_\\.]+)\"", "def _get_resource_name_regex():\n    return r\"(?i)^(?P<resource_name>[a-zA-Z0-9\\-\\_]+)(\\.(?P<version>\\d+))?$\"\n"]}
{"_id": "62b86a4fb4d922cb0e688cf8", "generate_results": ["def validate_value(value):\n    return re.match(REGEX, value)\n", "def validate_value(value):\n    if not value:\n        raise ValidationError(\n            _('This field cannot be empty.'),\n            code='empty',\n        )\n    if not re.search(r'^[a-zA-Z0-9_-]+$', value):\n        raise ValidationError(\n            _('This field must be alphanumeric.'),\n            code='invalid',\n        )\n", "def validate_value(value):\n    try:\n        re.compile(value)\n    except re.error as e:\n        raise ValidationError(str(e))\n", "def validate_value(value):\n    return bool(re.match(_REGEX, value))\n", "def validate_value(value):\n    \n    \n    if isinstance(value, six.string_types):\n        if value == '':\n            raise ValueError('Empty value is not allowed.')\n        return value\n    return re.compile(value)", "def validate_value(value):\n    \n    \n    try:\n        re.compile(value)\n    except re.error as e:\n        raise ValidationError(e)", "def validate_value(value):\n    if not re.match(REGEX, value):\n        raise ValidationError('Invalid value')\n", "def validate_value(value):\n    \n    \n    return __regex.match(value)\n", "def validate_value(value):\n    return _regex.match(value)\n", "def validate_value(value):\n    \n    \n    try:\n        return re.match(regex, value)\n    except TypeError:\n        raise ValidationError('Invalid value')\n"]}
{"_id": "62b86a4fb4d922cb0e688cf7", "generate_results": ["def validate_key(key):\n    return re.match(KEY_REGEX, key)\n", "def validate_key(key):\n    \n    \n    return re.match(KEY_REGEX, key)\n", "def validate_key(key):\n    \n    \n    return re.match(KEY_PATTERN, key)", "def validate_key(key):\n    return bool(re.match(RE_KEY, key))\n", "def validate_key(key):\n    if key is None:\n        return True\n    return _key_re.match(key)\n", "def validate_key(key):\n    \n    \n    return _KEY_RE.match(key)", "def validate_key(key):\n    return re.match(r'^[a-zA-Z0-9]+$', key)\n", "def validate_key(key):\n    if key not in _KEYS:\n        raise ValueError(\"Invalid key: {}\".format(key))\n", "def validate_key(key):\n    if re.match(REGEX_KEY, key):\n        return True\n    return False\n", "def validate_key(key):\n    return re.match(r'^[a-zA-Z0-9_]+$', key)"]}
{"_id": "62b86a01b4d922cb0e688ccc", "generate_results": ["def generate_default_observer_schema_dict(manifest_dict, first_level=False):\n    # Generate new dict with key values\n    default_schema_dict = {}\n    for key, value in manifest_dict.items():\n        if first_level:\n            default_schema_dict[key] = value\n        else:\n            default_schema_dict[key] = {'type':'string', 'default': value}\n    return default_schema_dict\n", "def generate_default_observer_schema_dict(manifest_dict, first_level=False):\n    new_dict = {}\n    for key, value in manifest_dict.items():\n        if first_level:\n            new_dict[key] = {}\n        else:\n            new_dict[key] = {\"type\": value.type, \"id\": value.id}\n    return new_dict\n", "def generate_default_observer_schema_dict(manifest_dict, first_level=False):\n    schema_dict = {}\n    for key, value in manifest_dict.items():\n        if first_level:\n            schema_dict[key] = {'type': value.type, 'value': value.value}\n        else:\n            schema_dict[key] = {'type': value.type, 'value': value.value}\n    return schema_dict\n", "def generate_default_observer_schema_dict(manifest_dict, first_level=False):\n    default_observer_schema_dict = {\n        \"type\": \"object\",\n        \"properties\": {},\n        \"additionalProperties\": False,\n    }\n\n    if first_level:\n        default_observer_schema_dict[\"properties\"][\"levels\"] = {}\n\n    default_observer_schema_dict[\"properties\"][\"levels\"][\"valueType\"] = \"object\"\n\n    return default_observer_schema_dict\n", "def generate_default_observer_schema_dict(manifest_dict, first_level=False):\n    observer_schema = {}\n\n    for key in manifest_dict:\n        if first_level:\n            observer_schema[key] = manifest_dict[key]\n        else:\n            observer_schema[key] = manifest_dict[key].get('type')\n\n    return observer_schema\n", "def generate_default_observer_schema_dict(manifest_dict, first_level=False):\n    return generate_default_observer_schema(manifest_dict, first_level=first_level)\n", "def generate_default_observer_schema_dict(manifest_dict, first_level=False):\n    default_observer_schema = {}\n    for key, value in manifest_dict.items():\n        default_observer_schema[key] = generate_default_observer_schema(value)\n    if first_level:\n        return default_observer_schema\n    return default_observer_schema[\"levels\"][0]\n", "def generate_default_observer_schema_dict(manifest_dict, first_level=False):\n\n    if not first_level:\n        return generate_default_observer_schema_dict(manifest_dict['root'])\n\n    return generate_default_observer_schema_dict(manifest_dict['root'])", "def generate_default_observer_schema_dict(manifest_dict, first_level=False):\n    return generate_default_observer_schema_dict_from_dict(manifest_dict, first_level)\n", "def generate_default_observer_schema_dict(manifest_dict, first_level=False):\n    if not first_level:\n        # add a new dict entry for the observer type\n        manifest_dict['observer_type'] = manifest_dict['observer_type'] + '_observer_type'\n    return manifest_dict\n"]}
{"_id": "62b869ebb4d922cb0e688cc6", "generate_results": ["def update_last_applied_manifest_list_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    result = []\n    for last_applied_manifest_item in last_applied_manifest:\n        last_applied_manifest_item.update(observer_schema)\n        result.append(last_applied_manifest_item)\n    return result\n", "def update_last_applied_manifest_list_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    if last_applied_manifest is None:\n        last_applied_manifest = {}\n\n    last_applied_manifest[\"last_applied_manifest\"] = response\n    last_applied_manifest[\"observer_schema\"] = observer_schema\n\n    return last_applied_manifest\n", "def update_last_applied_manifest_list_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    \n    \n    last_applied_manifest.applied = observer_schema.validate_date(response.last_applied)\n", "def update_last_applied_manifest_list_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    \n    \n    last_applied_manifest.update(response)\n    last_applied_manifest.save()\n", "def update_last_applied_manifest_list_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    \n    \n    last_applied_manifest[\"observer_schema\"] = observer_schema\n    last_applied_manifest[\"last_update_time\"] = response[\"lastUpdateTime\"]\n    return last_applied_manifest\n", "def update_last_applied_manifest_list_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    if not response:\n        return\n\n    last_applied_manifest[\"last_applied_manifest_list\"] = response\n", "def update_last_applied_manifest_list_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    \n    \n    last_applied_manifest.applied_manifests = list(\n        map(lambda x: x.to_dict(), response.applied_manifests)\n    )\n    last_applied_manifest.save()\n", "def update_last_applied_manifest_list_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    if response is not None:\n        last_applied_manifest.update_from_resp(response)\n", "def update_last_applied_manifest_list_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    \n    \n    last_applied_manifest.applied = response.data.get(\n        \"applied\", last_applied_manifest.applied\n    )\n    last_applied_manifest.save()\n", "def update_last_applied_manifest_list_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    \n    \n    last_applied_manifest.append(observer_schema)\n"]}
{"_id": "62b869eab4d922cb0e688cc5", "generate_results": ["def update_last_applied_manifest_dict_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    last_applied_manifest[\"last_applied_manifest\"] = response.json()\n    return last_applied_manifest\n", "def update_last_applied_manifest_dict_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    \n    \n    last_applied_manifest.update_from_resp(observer_schema, response)\n", "def update_last_applied_manifest_dict_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    last_applied_manifest.update_from_resp(\n        observer_schema, response, last_applied_manifest.last_applied_manifest_dict\n    )\n", "def update_last_applied_manifest_dict_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    last_applied_manifest[\"observer\"] = observer_schema.dumps(\n        response.json()\n    )\n", "def update_last_applied_manifest_dict_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    last_applied_manifest[\"last_applied_manifest\"] = response\n", "def update_last_applied_manifest_dict_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    last_applied_manifest.update(response.json())\n", "def update_last_applied_manifest_dict_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    if last_applied_manifest is None:\n        return\n    last_applied_manifest.update_from_resp(observer_schema, response)\n", "def update_last_applied_manifest_dict_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    \n    \n    last_applied_manifest.update_from_resp(observer_schema, response)\n", "def update_last_applied_manifest_dict_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    \n    \n    last_applied_manifest.update(observer_schema.dump(response))\n    return last_applied_manifest\n", "def update_last_applied_manifest_dict_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    \n    \n    last_applied_manifest[\"last_applied_manifest\"] = response\n    return last_applied_manifest\n"]}
{"_id": "62b869eab4d922cb0e688cbf", "generate_results": ["def generate_default_observer_schema(app):\n    manifest = app.spec.manifest\n    for resource in manifest.resources:\n        if resource.custom_observer_schema is None:\n            resource.custom_observer_schema = generate_observer_schema(app)\n", "def generate_default_observer_schema(app):\n    generate_custom_observer_schema(app, spec=spec)\n", "def generate_default_observer_schema(app):\n    if app.config.get('KubernetesResourceObserverSchema') is None:\n        return None\n    return app.config.get('KubernetesResourceObserverSchema')\n", "def generate_default_observer_schema(app):\n    for resource_spec in app.config.get('SPEC', {}).get('resources', []):\n        generate_default_resource_observer_schema(app, resource_spec)\n", "def generate_default_observer_schema(app):\n    for name, spec in app.resources.items():\n        if spec.custom_observer_schema:\n            app.resources[name]['custom_observer_schema'] = generate_default_observer_schema(app, spec.custom_observer_schema)\n", "def generate_default_observer_schema(app):\n    manifest = app.spec.manifest\n    custom_observer_schema = manifest.get('customObserverSchema', {})\n    if custom_observer_schema is not None:\n        for k, v in custom_observer_schema.items():\n            if k not in manifest['customObserverSchema']:\n                manifest['customObserverSchema'][k] = v\n", "def generate_default_observer_schema(app):\n    for resource in app.env.resources:\n        if resource.type == 'custom' and resource.name not in app.config.observer_schema_specs:\n            app.env.observer_schema_specs[resource.name] = resource.spec\n", "def generate_default_observer_schema(app):\n    for resource in app.api.resources.values():\n        if resource.custom_observer_schema is None:\n            resource.custom_observer_schema = generate_custom_observer_schema(\n                resource, app\n            )\n", "def generate_default_observer_schema(app):\n    for s in app.api.generate_custom_observer_schema():\n        yield s\n", "def generate_default_observer_schema(app):\n    for manifest_file in app.manifest.files:\n        if manifest_file.name == 'observer':\n            return\n\n    raise RuntimeError(\"No observer schema was found in the manifest\")\n"]}
{"_id": "62b43427903eeb48555d3ea5", "generate_results": ["def format(\n\t\tself,\n\t\tsql: str,\n*,\nconverter: Optional[Type[Converter]] = None,\n) -> str:\n\n\nif converter is None:\nconverter = self._converter\n\nreturn converter.convert(sql)", "def format(\n\t\tself,\n\t\tsql: str,\nparams: Optional[Dict[str, Any]] = None,\n) -> str:\nif params is None:\nparams = {}\nparams[\"sql\"] = sql\nreturn self._converter.convert(params)", "def format(\n\t\tself,\n\t\tsql: str,\n*,\nencoding: str = \"utf-8\",\n) -> str:\n\n\nreturn self._converter.convert(sql, encoding=encoding)\n", "def format(\n\t\tself,\n\t\tsql: str,\n*args,\n**kwargs\n) -> str:\nreturn self._converter.format(sql, *args, **kwargs)", "def format(\n\t\tself,\n\t\tsql: str,\n*,\nencoding: str = \"utf-8\",\n) -> str:\nreturn self._converter.convert(sql, encoding=encoding)", "def format(\n\t\tself,\n\t\tsql: str,\n*,\nencoding: str = \"utf-8\",\n) -> str:\nreturn self._converter.convert(sql, encoding)", "def format(\n\t\tself,\n\t\tsql: str,\n*args: Any,\n**kwargs: Any,\n) -> str:\nreturn self._converter.convert(sql, *args, **kwargs)\n", "def format(\n\t\tself,\n\t\tsql: str,\n*args: Any,\n**kwargs: Any\n) -> str:\n\n\nreturn self._converter.convert(sql, *args, **kwargs)", "def format(\n\t\tself,\n\t\tsql: str,\n*args: Any,\n**kwargs: Any\n) -> str:\nreturn self._converter.format(sql, *args, **kwargs)", "def format(\n\t\tself,\n\t\tsql: str,\n*args: Any,\n**kwargs: Any\n) -> str:\nreturn self._converter.convert(sql, *args, **kwargs)"]}
{"_id": "62b43428903eeb48555d3eaa", "generate_results": ["def formatmany(\n\t\tself,\n\t\tsql: str,\n*,\nconv: Optional[Callable[[Iterable[Any]], Any]] = None,\n) -> str:\nreturn self._converter.convert_many(sql, conv)", "def formatmany(\n\t\tself,\n\t\tsql: str,\nfmt: str,\nencoding: str = 'utf-8',\n) -> Iterator[str]:\nreturn self._converter.format_many(sql, fmt, encoding)\n", "def formatmany(\n\t\tself,\n\t\tsql: str,\nfmt: str = 'json',\n) -> Dict[str, Any]:\n\n\n\nreturn self._converter.convert_many(sql, fmt)", "def formatmany(\n\t\tself,\n\t\tsql: str,\nconverter: Converter,\n*,\nverbose: bool = False,\n) -> Iterable[Tuple[str, Any]]:\nreturn self._converter.convert_many(\nsql,\nself._converter.converters,\nself._converter.field_names,\nself._converter.converters,\nverbose=verbose\n)\n", "def formatmany(\n\t\tself,\n\t\tsql: str,\nconv_fn: Callable[[Sequence[Any]], Any]\n) -> str:\nreturn self._converter.formatmany(sql, conv_fn)", "def formatmany(\n\t\tself,\n\t\tsql: str,\n*,\nconverter: Callable[[List[Any]], str] = None,\n**kwargs: Any\n) -> str:\n\n\nreturn self._converter.convert_many(sql, converter=converter, **kwargs)\n", "def formatmany(\n\t\tself,\n\t\tsql: str,\n*,\nnames: List[str] = None,\n) -> List[str]:\nreturn self._converter.convert_many(\nsql,\nnames=names\n)", "def formatmany(\n\t\tself,\n\t\tsql: str,\n*,\nas_dict: bool = True,\nas_list: bool = True,\n) -> list:\n\n\nif as_dict:\nreturn self._converter.convert_many(sql, self._db)\nelse:\nreturn self._converter.convert_many(sql, self._db, as_list=as_list)", "def formatmany(\n\t\tself,\n\t\tsql: str,\nparams: Optional[Mapping[str, Any]] = None,\n) -> str:\n\n\nreturn self._converter.format_many(\nsql, params=params\n)", "def formatmany(\n\t\tself,\n\t\tsql: str,\n*args: str,\n**kwargs: Any\n) -> Any:\nreturn self._converter.convert_many(sql, *args, **kwargs)"]}
{"_id": "62b45df05108cfac7f2109ce", "generate_results": ["def validate(self, path):\n    try:\n        self._fs.stat(path)\n        return True\n    except OSError:\n        return False", "def validate(self, path):\n    return self.__validate(path)", "def validate(self, path):\n    \n    \n    return self._validate(path)\n", "def validate(self, path):\n    \n    \n    try:\n        return self._validate_path(path)\n    except ValueError:\n        return False", "def validate(self, path):\n    \n    \n    try:\n        self.__get_object_info(path)\n        return True\n    except Exception:\n        return False", "def validate(self, path):\n    \n    \n    try:\n        self._request(path)\n        return True\n    except (ValueError, TypeError):\n        return False", "def validate(self, path):\n    \n    \n    if not os.path.exists(path):\n        raise ValueError(\"path does not exist\")\n    try:\n        self._validate_file(path)\n    except IOError:\n        raise IOError(\"path does not exist\")\n    except Exception as e:\n        raise ValueError(\"Exception in validate: %s\" % e)\n    return True\n", "def validate(self, path):\n    \n    \n    if not os.path.exists(path):\n        raise OCFLNotFound('Path does not exist:'+ path)\n    if not os.path.exists(os.path.dirname(path)):\n        raise OCFLNotFound('Path does not exist:'+ os.path.dirname(path))\n    return True\n", "def validate(self, path):\n    try:\n        self._get_ocfl_object(path)\n    except OCFLError:\n        return False\n    return True\n", "def validate(self, path):\n    return self._validate(path) is not None"]}
{"_id": "62b45df15108cfac7f2109dc", "generate_results": ["def status_str(self, prefix=''):\n    messages = []\n    for m in self.messages:\n        if not m.visible:\n            continue\n        messages.append('%s%s' % (prefix, m.name))\n    return '\\n'.join(messages)\n", "def status_str(self, prefix=''):\n    status_str = ''\n    for message in self.messages:\n        status_str += prefix + str(message) + '\\n'\n    return status_str\n", "def status_str(self, prefix=''):\n    if len(self.messages) == 0:\n        return '[empty]'\n    else:\n        return '[' + prefix + ']'+ ', '.join([msg.status_str() for msg in self.messages])\n", "def status_str(self, prefix=''):\n    return '%s%s' % (prefix, ','.join(self.messages))\n", "def status_str(self, prefix=''):\n    result = prefix + '\\n'\n    for msg in self.messages:\n        result += msg.status_str(prefix=prefix +' ')\n    return result", "def status_str(self, prefix=''):\n    if len(self.messages) == 0:\n        return ''\n    s = prefix + '['\n    for m in self.messages:\n        s += str(m) + ', '\n    s = s[:-2] + ']'\n    return s", "def status_str(self, prefix=''):\n    return '%s%s' % (prefix,''.join([msg.status_str() for msg in self.messages]))\n", "def status_str(self, prefix=''):\n    return '\\n'.join('{}{}'.format(prefix, m) for m in self.messages)\n", "def status_str(self, prefix=''):\n    return '%s%s\\n' % (prefix, '\\n'.join(sorted(self.messages)))", "def status_str(self, prefix=''):\n    s = prefix + ''\n    for m in self.messages:\n        s += m.status_str()\n    return s"]}
{"_id": "62b45df15108cfac7f2109dd", "generate_results": ["def status_str(self, prefix=''):\n    \n    \n    if prefix:\n        return '%s %s %s' % (prefix, self.log.status_str, self.log.remote_status_str)\n    else:\n        return self.log.status_str\n", "def status_str(self, prefix=''):\n    return \"{} {}\".format(prefix, self.log.status_str)", "def status_str(self, prefix=''):\n    if self.log.status_str is not None:\n        return prefix + self.log.status_str\n    else:\n        return ''\n", "def status_str(self, prefix=''):\n    return prefix + self.log.status_str + '\\n'", "def status_str(self, prefix=''):\n    \n    \n    return '%s%s' % (prefix, self.log.status_str)", "def status_str(self, prefix=''):\n    return '{0}{1}'.format(prefix, self.log.status_str)\n", "def status_str(self, prefix=''):\n    return '{} {} {}'.format(prefix, self.log.status_str, self.status)\n", "def status_str(self, prefix=''):\n    return prefix + ':'+ self.log.status_str\n", "def status_str(self, prefix=''):\n    return '%s%s: %s' % (prefix, self.log.status_str, self.log.message)\n", "def status_str(self, prefix=''):\n    return '%s%s' % (prefix, self.status_str)"]}
{"_id": "62b45e135108cfac7f2109f4", "generate_results": ["def is_valid(self, identifier):\nreturn True", "def is_valid(self, identifier):\n    return True", "def is_valid(self, identifier):\nreturn True", "def is_valid(self, identifier):\n    return True", "def is_valid(self, identifier):\n    return True", "def is_valid(self, identifier):\nreturn True\n", "def is_valid(self, identifier):\nreturn True\n\n", "def is_valid(self, identifier):\n    return True", "def is_valid(self, identifier):\nreturn True", "def is_valid(self, identifier):\nreturn True"]}
{"_id": "62b45e145108cfac7f210a07", "generate_results": ["def validate(self, inventory, extract_spec_version=False):\n    raise NotImplementedError", "def validate(self, inventory, extract_spec_version=False):\n    if extract_spec_version:\n        try:\n            inventory._spec_version\n        except AttributeError:\n            raise InventoryError(\"Unable to find the spec version of the inventory\")\n        else:\n            inventory._spec_version = extract_spec_version\n    return inventory\n", "def validate(self, inventory, extract_spec_version=False):\n    if extract_spec_version:\n        version = inventory.get_spec_version()\n        if not version:\n            raise Exception(\"No spec version found in inventory.\")\n        inventory.spec_version = version\n\n    if self.validator(inventory):\n        return inventory\n    else:\n        raise Exception(\"Invalid inventory type or version.\")\n", "def validate(self, inventory, extract_spec_version=False):\n    if extract_spec_version:\n        inventory = extract_inventory_spec_version(inventory)\n\n    for key, value in inventory.items():\n        if key in self.VALID_KEYS:\n            if value in self.VALID_VALUES:\n                return True\n    return False", "def validate(self, inventory, extract_spec_version=False):\n    return self.validate_with_spec_version(inventory, extract_spec_version)\n", "def validate(self, inventory, extract_spec_version=False):\n    if extract_spec_version:\n        inventory.validate_version()\n\n    for host in inventory.hosts:\n        host.validate()\n", "def validate(self, inventory, extract_spec_version=False):\n    return self.__validate(inventory, extract_spec_version)\n", "def validate(self, inventory, extract_spec_version=False):\n    return super(InventoryModule, self).validate(inventory, extract_spec_version)\n", "def validate(self, inventory, extract_spec_version=False):\n    if extract_spec_version:\n        inventory.validate_spec_version()\n    else:\n        inventory.validate_type()\n", "def validate(self, inventory, extract_spec_version=False):\n    if extract_spec_version:\n        type_value = inventory.get('type')\n        if type_value is None or type_value == '':\n            type_value = self.spec_version\n    else:\n        type_value = inventory.get('type')\n    validate_type(type_value, self.valid_types)\n    validate_value(inventory.get('value'), self.valid_values)\n"]}
{"_id": "62b45e145108cfac7f210a09", "generate_results": ["def check_digests_present_and_used(self, manifest_files, digests_used):\n    error = \"\"\n    for manifest_file in manifest_files:\n        if not manifest_file.startswith(\"/\"):\n            manifest_file = os.path.join(self.manifest_dir, manifest_file)\n        for digest in manifest_file.split(\"/\"):\n            if digest not in digests_used:\n                error += \"Manifest file does not contain digest '%s'.\\n\" % digest\n    return error\n", "def check_digests_present_and_used(self, manifest_files, digests_used):\n    for digest in manifest_files:\n        if digest not in digests_used:\n            return \"Digest '%s' is not present in manifest. Use '--use' to use it.\" % digest\n    return None", "def check_digests_present_and_used(self, manifest_files, digests_used):\n\n    for digest in digests_used:\n        if digest not in manifest_files:\n            return \"Digest %s is not present in manifest!\" % digest\n        if digest in manifest_files:\n            return \"Digest %s is already used!\" % digest\n\n    return \"\"", "def check_digests_present_and_used(self, manifest_files, digests_used):\n    for digest in manifest_files:\n        if digest not in digests_used:\n            print('Digest not used: {}'.format(digest))\n            return 'Digest not used: {}'.format(digest)\n    return None\n", "def check_digests_present_and_used(self, manifest_files, digests_used):\n    error = \"\"\n\n    for digest in digests_used:\n        if digest not in manifest_files:\n            error += \"Error: %s is not in manifest.\\n\" % digest\n\n    return error\n", "def check_digests_present_and_used(self, manifest_files, digests_used):\n    errors = []\n    for manifest_file in manifest_files:\n        for digest in manifest_file.get('digests', []):\n            if digest not in digests_used:\n                errors.append(\"Digest {} not in manifest file {}\".format(\n                    digest, manifest_file.get('name')))\n    return errors\n", "def check_digests_present_and_used(self, manifest_files, digests_used):\n    errors = []\n    for manifest_file in manifest_files:\n        if manifest_file.digest not in digests_used:\n            errors.append(\n                \"Digest {digest} is missing from manifest file {file}\".format(\n                    digest=manifest_file.digest, file=manifest_file.path\n                )\n            )\n\n    return errors\n", "def check_digests_present_and_used(self, manifest_files, digests_used):\n    for file in manifest_files:\n        if not digests_used[file]:\n            return \"Digests for file {} are missing\".format(file)\n\n    return None\n", "def check_digests_present_and_used(self, manifest_files, digests_used):\n    for manifest_file in manifest_files:\n        manifest = self._read_manifest_file(manifest_file)\n        for digest in manifest.digests:\n            if digest in digests_used:\n                return digest\n    return \"error\"\n", "def check_digests_present_and_used(self, manifest_files, digests_used):\n    errors = []\n    for file_ in manifest_files:\n        for digest in digests_used:\n            if file_.digest == digest:\n                errors.append('Found digest %s' % digest)\n                break\n        else:\n            errors.append('Digest %s not found in manifest' % digest)\n    return errors\n"]}
{"_id": "62b45e165108cfac7f210a16", "generate_results": ["def validate_as_prior_version(self, prior):\n    if not isinstance(prior, InventoryValidator):\n        raise ValueError('prior must be an InventoryValidator object')\n\n    if not self.is_valid_version(prior.version):\n        raise ValueError('invalid version: {} for inventory: {}'.format(prior.version, self.version))", "def validate_as_prior_version(self, prior):\n    if not isinstance(prior, InventoryValidator):\n        raise TypeError('validate_as_prior_version() requires a valid InventoryValidator object.')\n\n    return error('validate_as_prior_version() requires a valid InventoryValidator object.')\n", "def validate_as_prior_version(self, prior):\n    if not isinstance(prior, InventoryValidator):\n        raise TypeError(\"prior must be an InventoryValidator\")\n    if not prior.validate(self):\n        raise ValueError(\"Validation of inventory does not succeed\")", "def validate_as_prior_version(self, prior):\n    return NotImplementedError(\"validate_as_prior_version not implemented.\")", "def validate_as_prior_version(self, prior):\n    return NotImplementedError()\n", "def validate_as_prior_version(self, prior):\n    return error('invalid-prior-version', 'Prior version must be a valid prior version of the current inventory.', self.name)\n", "def validate_as_prior_version(self, prior):\n    if not isinstance(prior, InventoryValidator):\n        raise TypeError('Expected inventory validator object.')\n\n    return prior.error()\n", "def validate_as_prior_version(self, prior):\n    if not isinstance(prior, InventoryValidator):\n        return \"Prior must be an instance of a valid InventoryValidator.\"\n    return None", "def validate_as_prior_version(self, prior):\n    if not isinstance(prior, InventoryValidator):\n        raise TypeError('Expected valid InventoryValidator object. Got {}'.format(type(prior)))\n    if prior.name!= self.name:\n        raise ValueError('Cannot assign prior version to a different inventory version.')\n    return None\n", "def validate_as_prior_version(self, prior):\n\n    error(\"An inventory object cannot be built from a prior version of itself\")\n\n    return None\n"]}
{"_id": "62b45e165108cfac7f210a17", "generate_results": ["def get_logical_path_map(inventory, version):\n    return {\n        state.name: state.path\n        for state in inventory.states\n        if state.name in inventory.get_logical_paths(version)\n    }\n", "def get_logical_path_map(inventory, version):\n    return get_path_map(inventory, version, 'logical')\n", "def get_logical_path_map(inventory, version):\n    return {\n        path: os.path.join(path, '{}.yml'.format(version))\n        for path in inventory.keys()\n    }\n", "def get_logical_path_map(inventory, version):\n    return {\n        'node-0': inventory.get('node-0', {}).get('states', []),\n        'node-1': inventory.get('node-1', {}).get('states', []),\n        'node-2': inventory.get('node-2', {}).get('states', []),\n        'node-3': inventory.get('node-3', {}).get('states', []),\n        'node-4': inventory.get('node-4', {}).get('states', []),\n        'node-5': inventory.get('node-5', {}).get('states', []),\n        'node-6': inventory.get('node-6', {}).get('states', [])\n    }\n", "def get_logical_path_map(inventory, version):\n    return inventory['inventory_path'][version]\n", "def get_logical_path_map(inventory, version):\n    return {\n        (x[\"name\"], x[\"version\"]): x[\"path\"]\n        for x in inventory[\"states\"]\n        if x[\"version\"] == version\n    }\n", "def get_logical_path_map(inventory, version):\n    \n    \n    return {\n        os.path.realpath(f): os.path.basename(f)\n        for f in inventory['_meta']['paths'][version]\n    }\n", "def get_logical_path_map(inventory, version):\n    return {\n        name: os.path.join(dirname, name)\n        for name, dirname in inventory.items()\n        if is_logical_state_name(name, version)\n    }\n", "def get_logical_path_map(inventory, version):\n    \n    \n    logical_path_map = {}\n    for item in inventory:\n        path = inventory[item]['path']\n        if path not in logical_path_map:\n            logical_path_map[path] = []\n        logical_path_map[path].append(item)\n    return logical_path_map\n", "def get_logical_path_map(inventory, version):\n    \n    \n    return {\n        s['name']: os.path.join(inventory['path'], s['name'])\n        for s in inventory['states']\n        if s['type'] == version\n    }"]}
{"_id": "62b45e175108cfac7f210a19", "generate_results": ["def validate_fixity(self, fixity, manifest_files):\n    error = None\n    for file in manifest_files:\n        if file in fixity:\n            error = 'Fixity file {0} already exists'.format(file)\n    return error", "def validate_fixity(self, fixity, manifest_files):\n    return True", "def validate_fixity(self, fixity, manifest_files):\n    errors = []\n    for file_name in fixity:\n        if file_name in manifest_files:\n            errors.append('%s is referenced in manifest' % file_name)\n    return errors", "def validate_fixity(self, fixity, manifest_files):\n    errors = []\n    if not manifest_files:\n        errors.append('No files found in the manifest.')\n    if len(errors) > 0:\n        return errors\n    return []\n", "def validate_fixity(self, fixity, manifest_files):\n    error = []\n    for manifest_file in manifest_files:\n        if not self.__is_file(manifest_file):\n            error.append(\"The manifest file '%s' does not exist.\" % manifest_file)\n    if error:\n        return error\n    for line in fixity:\n        if line.strip() == \"\":\n            error.append(\"The fixity block is empty.\")\n    if error:\n        return error\n", "def validate_fixity(self, fixity, manifest_files):\n    for file in manifest_files:\n        if file not in fixity.files:\n            raise ValueError(\"Invalid fixity file %s\" % file)\n\n    return self.error()", "def validate_fixity(self, fixity, manifest_files):\n    if fixity.files == []:\n        return \"Fixity block is empty\"\n\n    for f in fixity.files:\n        if f not in manifest_files:\n            return \"Fixity file '%s' not in manifest\" % f\n\n    return \"\"", "def validate_fixity(self, fixity, manifest_files):\n    if not manifest_files:\n        return 'No manifest files specified.'\n\n    for f in manifest_files:\n        if f not in fixity:\n            return 'Fixity block {} does not contain file {}.'.format(\n                fixity['name'], f)\n\n    return ''", "def validate_fixity(self, fixity, manifest_files):\n    return self.validate_fixity_inventory(fixity, manifest_files)\n", "def validate_fixity(self, fixity, manifest_files):\n\nif not self.check_fixity_validity(fixity):\nreturn True\n\nif self.check_fixity_manifest(fixity, manifest_files):\nreturn True\n\nreturn False"]}
{"_id": "62b463153879012d19481498", "generate_results": ["def files_list(path):\n    \n    \n    return [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n", "def files_list(path):\n    return [os.path.join(path, f) for f in os.listdir(path)]\n", "def files_list(path):\n    return [os.path.join(path, filename) for filename in os.listdir(path)]\n", "def files_list(path):\n    return [os.path.join(path, f) for f in os.listdir(path)]\n", "def files_list(path):\n    return [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]", "def files_list(path):\n    files = []\n    for f in os.listdir(path):\n        fp = os.path.join(path, f)\n        if os.path.isfile(fp):\n            files.append(fp)\n    return files\n", "def files_list(path):\n    return [f for f in listdir(path) if isfile(join(path, f))]\n", "def files_list(path):\n    return [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n", "def files_list(path):\n    return [file for file in os.listdir(path) if os.path.isfile(os.path.join(path, file))]\n", "def files_list(path):\n    return sorted([f for f in listdir(path) if isfile(join(path, f))])\n"]}
{"_id": "62b463153879012d1948149a", "generate_results": ["def _group_files_by_xml_filename(source, xmls, files):\n    for xml in xmls:\n        yield _group_files_by_xml_filename_from_file(source, xml, files)\n", "def _group_files_by_xml_filename(source, xmls, files):\n    xml_filenames = {}\n    for xml in xmls:\n        filename = xml.filename\n        if filename in files:\n            xml_filenames[xml.filename] = files[filename]\n            files.pop(filename)\n        else:\n            xml_filenames[xml.filename] = None\n    return xml_filenames\n", "def _group_files_by_xml_filename(source, xmls, files):\n    \n    \n    xml_files = {}\n    for xml in xmls:\n        xml_files[xml] = []\n    for file in files:\n        xml_file = source.xpath(file)\n        if len(xml_file) > 0:\n            for xml in xml_file:\n                xml_files[xml].append(file)\n    return xml_files\n", "def _group_files_by_xml_filename(source, xmls, files):\n    result = {}\n    for xml, filename in zip(xmls, files):\n        result[filename] = _group_files_by_xml_filename_xml(source, xml, filename)\n    return result", "def _group_files_by_xml_filename(source, xmls, files):\n    \n    \n    groups = defaultdict(list)\n    for xml, filename in zip(xmls, files):\n        groups[filename].append(xml)\n    return groups\n", "def _group_files_by_xml_filename(source, xmls, files):\n    \n    \n    out = {}\n    for xml_filename, filename in zip(xmls, files):\n        out.setdefault(xml_filename, []).append(filename)\n    return out\n", "def _group_files_by_xml_filename(source, xmls, files):\n    files_by_xml_filename = {}\n    for filename in files:\n        files_by_xml_filename[filename] = {}\n        for xml_filename in xmls:\n            if filename.startswith(xml_filename):\n                files_by_xml_filename[filename][xml_filename] = source.get(filename, '')\n    return files_by_xml_filename\n", "def _group_files_by_xml_filename(source, xmls, files):\n    \n    \n    return {xml_filename: _group_files_by_xml_filename_in_dict(source, xml_filename, files) for xml_filename in xmls}\n", "def _group_files_by_xml_filename(source, xmls, files):\n    \n    \n    return {\n        filename: _group_files_by_xml_filename_helper(source, xmls, files, filename)\n        for filename in files\n    }\n", "def _group_files_by_xml_filename(source, xmls, files):\n    xml_files = [xml.filename for xml in xmls]\n    groups = {}\n    for filename in files:\n        if filename in xml_files:\n            groups[filename] = source.get(filename)\n    return groups\n"]}
{"_id": "62b463153879012d1948149b", "generate_results": ["def match_file_by_prefix(prefix, file_path):\n    return (file_path.startswith(prefix) or\n            file_path.startswith(\"-\") or\n            file_path.startswith(\".\" + prefix))\n", "def match_file_by_prefix(prefix, file_path):\n    if file_path.startswith(prefix):\n        return True\n    if file_path.startswith(\"-\") or file_path.startswith(\".\" + prefix):\n        return True\n    return False", "def match_file_by_prefix(prefix, file_path):\n    basename = os.path.basename(file_path)\n    return basename.startswith(prefix) or \".\" in basename or prefix in basename", "def match_file_by_prefix(prefix, file_path):\n    filename = os.path.basename(file_path)\n    if filename.startswith(prefix):\n        return True\n    if filename.startswith(\"-\") and filename.endswith(\"-\"):\n        return True\n    if filename.startswith(\".\" + prefix):\n        return True\n    if filename.startswith(\".\" + \"-\" * len(prefix)):\n        return True\n    return False\n", "def match_file_by_prefix(prefix, file_path):\n    return (prefix + \"-\" if file_path.startswith(prefix) else file_path.startswith(prefix) or\n            file_path.startswith(prefix + \".\" if prefix else \"\"))", "def match_file_by_prefix(prefix, file_path):\n    if not file_path:\n        return False\n    if file_path.startswith(prefix):\n        return True\n    if file_path.startswith(\"-\"):\n        return True\n    if file_path.startswith(\".\"):\n        return True\n    return False\n", "def match_file_by_prefix(prefix, file_path):\n    basename = os.path.basename(file_path)\n    if basename.startswith(prefix):\n        return True\n    return False\n", "def match_file_by_prefix(prefix, file_path):\n    return match_file_by_basename(file_path, prefix) \\\n            or match_file_by_basename(file_path[:-1], prefix + \"-\")", "def match_file_by_prefix(prefix, file_path):\n    return (file_path.startswith(prefix) and\n            file_path.endswith(\"-\") or\n            file_path.endswith(\".\" + prefix))\n", "def match_file_by_prefix(prefix, file_path):\n    return file_path.startswith(prefix + \"-\") or \\\n        file_path.startswith(prefix + \".\" + os.path.sep)"]}
{"_id": "62b463153879012d1948149c", "generate_results": ["def select_filenames_by_prefix(prefix, files):\n    return [f for f in files if f.startswith(prefix)]\n", "def select_filenames_by_prefix(prefix, files):\n    return [f for f in files if f.startswith(prefix)]", "def select_filenames_by_prefix(prefix, files):\n    return [f for f in files if f.startswith(prefix)]", "def select_filenames_by_prefix(prefix, files):\n    return [f for f in files if f.startswith(prefix)]\n", "def select_filenames_by_prefix(prefix, files):\n    for f in files:\n        if f.startswith(prefix):\n            yield f\n", "def select_filenames_by_prefix(prefix, files):\n    return [f for f in files if f.startswith(prefix)]\n", "def select_filenames_by_prefix(prefix, files):\n    result = []\n    for file in files:\n        if file.startswith(prefix):\n            result.append(file)\n    return result\n", "def select_filenames_by_prefix(prefix, files):\n    return [f for f in files if f.startswith(prefix)]\n", "def select_filenames_by_prefix(prefix, files):\n    \n    \n    return [f for f in files if f.startswith(prefix)]\n", "def select_filenames_by_prefix(prefix, files):\n    return [f for f in files if f.startswith(prefix)]\n"]}
{"_id": "62b463153879012d1948149d", "generate_results": ["def _explore_folder(folder):\n    \n    \n    for filename in _group_files_by_xml_filename(folder):\n        yield filename", "def _explore_folder(folder):\n    \n    \n    files = [f for f in listdir(folder) if isfile(join(folder, f))]\n    files = [_group_files_by_xml_filename(f) for f in files]\n    return files\n", "def _explore_folder(folder):\n    \n    \n    for root, dirs, files in os.walk(folder):\n        for f in files:\n            if f.endswith(\".xml\"):\n                _group_files_by_xml_filename(os.path.join(root, f))", "def _explore_folder(folder):\n    \n    \n    group = []\n    for filename in os.listdir(folder):\n        if filename.endswith(\".xml\"):\n            group.append(os.path.join(folder, filename))\n    return _group_files_by_xml_filename(group)\n", "def _explore_folder(folder):\n    groups = {}\n    for filename in os.listdir(folder):\n        if os.path.isdir(os.path.join(folder, filename)):\n            groups[filename] = _group_files_by_xml_filename(folder, filename)\n        else:\n            groups[filename] = {}\n    return groups\n", "def _explore_folder(folder):\n    return [\n        _group_files_by_xml_filename(path)\n        for path in sorted(os.listdir(folder))\n        if not path.startswith('.')\n    ]\n", "def _explore_folder(folder):\n    for f in os.listdir(folder):\n        if f.endswith(\".xml\"):\n            _group_files_by_xml_filename(os.path.join(folder, f))\n", "def _explore_folder(folder):\n    for f in folder.iterdir():\n        if f.is_dir():\n            _explore_folder(f)\n        else:\n            _group_files_by_xml_filename(f)\n", "def _explore_folder(folder):\n    \n    \n    for (dirpath, dirnames, filenames) in os.walk(folder):\n        for f in filenames:\n            fn = os.path.join(dirpath, f)\n            if os.path.isfile(fn):\n                yield _group_files_by_xml_filename(fn)\n", "def _explore_folder(folder):\n    group_by_filename = {}\n    for f in os.listdir(folder):\n        full_path = os.path.join(folder, f)\n        if os.path.isfile(full_path):\n            group_by_filename[f] = _group_files_by_xml_filename(full_path)\n    return group_by_filename"]}
{"_id": "62b463153879012d1948149f", "generate_results": ["def _eval_file(prefix, file_path):\n    # TODO: Add more checks here.\n    if file_path.endswith('.xml'):\n        return _eval_xml_file(prefix, file_path)\n    elif file_path.endswith('.pdf'):\n        return _eval_pdf_file(prefix, file_path)\n    else:\n        return None\n", "def _eval_file(prefix, file_path):\n    if file_path.startswith(prefix):\n        return {\"component_id\": file_path[len(prefix):], \"file_path\": file_path}\n    else:\n        return None\n", "def _eval_file(prefix, file_path):\n    if file_path.lower().startswith(prefix.lower()):\n        return {'component_id': prefix, 'file_path': file_path,\n                'ftype': 'pdf', 'file_path': file_path}\n    if file_path.lower().startswith(prefix + '.'):\n        return {'component_id': prefix, 'file_path': file_path,\n                'ftype': 'xml', 'file_path': file_path}\n", "def _eval_file(prefix, file_path):\n    return {} if (os.path.splitext(file_path)[1] == \".pdf\") else {\n        \"component_id\": \"xml\",\n        \"file_path\": file_path,\n        \"ftype\": \"pdf\",\n        \"file_path_xml\": file_path\n    }\n", "def _eval_file(prefix, file_path):\n    if file_path.endswith('.xml'):\n        return None\n    elif file_path.endswith('.pdf'):\n        return {'component_id': 'pdf', 'file_path': file_path}\n    elif file_path.endswith('.pdf') and file_path.endswith('.xml'):\n        return {'component_id': 'xml', 'file_path': file_path}\n    else:\n        return None\n", "def _eval_file(prefix, file_path):\n    if prefix is None:\n        return None\n\n    if file_path.endswith(\".xml\"):\n        return {\"component_id\": file_path[:-5], \"file_path\": file_path, \"ftype\": \"xml\", \"file_path\": file_path}\n\n    if file_path.endswith(\".pdf\"):\n        return {\"component_id\": file_path[:-4], \"file_path\": file_path, \"ftype\": \"pdf\", \"file_path\": file_path}\n\n    return None\n", "def _eval_file(prefix, file_path):\n    if file_path.startswith(prefix):\n        return {\"component_id\": file_path[len(prefix):],\n                \"file_path\": file_path,\n                \"ftype\": \"xml\",\n                \"file_path\": file_path[len(prefix):]}\n    return None\n", "def _eval_file(prefix, file_path):\n    if file_path.endswith(\".xml\"):\n        return {\n            \"component_id\": None,\n            \"file_path\": file_path,\n            \"ftype\": \"xml\",\n            \"file_path\": file_path,\n        }\n    if file_path.endswith(\".pdf\"):\n        return {\n            \"component_id\": None,\n            \"file_path\": file_path,\n            \"ftype\": \"pdf\",\n        }\n", "def _eval_file(prefix, file_path):\n    if file_path.endswith('.xml'):\n        return {'component_id': prefix, 'file_path': file_path, 'ftype': 'xml'}\n    elif file_path.endswith('.pdf'):\n        return {'component_id': prefix, 'file_path': file_path, 'ftype': 'pdf'}\n    return None\n", "def _eval_file(prefix, file_path):\n    if file_path.startswith(prefix):\n        return {\n            \"component_id\": prefix,\n            \"file_path\": file_path,\n            \"ftype\": \"pdf\",\n            \"file_path\": file_path,\n        }\n    return None\n"]}
{"_id": "62b463153879012d194814a1", "generate_results": ["def add_rendition(self, lang, file_path):\n    self._renditions[lang] = file_path\n", "def add_rendition(self, lang, file_path):\n    self._renditions[lang] = file_path", "def add_rendition(self, lang, file_path):\n    self._renditions[lang] = file_path\n", "def add_rendition(self, lang, file_path):\n    if lang in self._renditions:\n        self._renditions[lang]['filepath'] = file_path", "def add_rendition(self, lang, file_path):\n    self._renditions[lang] = file_path\n", "def add_rendition(self, lang, file_path):\n    if lang not in self._renditions:\n        self._renditions[lang] = []\n\n    if file_path not in self._renditions[lang]:\n        self._renditions[lang].append(file_path)\n", "def add_rendition(self, lang, file_path):\n    self._renditions[lang] = file_path\n", "def add_rendition(self, lang, file_path):\n    self._renditions[lang] = file_path", "def add_rendition(self, lang, file_path):\n    self._renditions[lang] = file_path", "def add_rendition(self, lang, file_path):\n    if lang not in self._renditions:\n        self._renditions[lang] = {}\n    self._renditions[lang][file_path] = file_path"]}
{"_id": "62b463163879012d194814a2", "generate_results": ["def add_asset(self, basename, file_path):\n    self._assets[basename] = file_path", "def add_asset(self, basename, file_path):\n    if basename not in self._assets:\n        self._assets[basename] = file_path\n", "def add_asset(self, basename, file_path):\n    self._assets[basename] = file_path", "def add_asset(self, basename, file_path):\n    self._assets[basename] = file_path", "def add_asset(self, basename, file_path):\n    self._assets[basename] = file_path", "def add_asset(self, basename, file_path):\n    self._assets[basename] = file_path", "def add_asset(self, basename, file_path):\n    self._assets[basename] = file_path", "def add_asset(self, basename, file_path):\n    self._assets[basename] = file_path\n", "def add_asset(self, basename, file_path):\n    self._assets[basename] = file_path\n", "def add_asset(self, basename, file_path):\n    self._assets[basename] = file_path"]}
{"_id": "62b463163879012d194814a4", "generate_results": ["def _explore_zipfile(zip_path):\n    return _group_files_by_xml_filename(zip_path)\n", "def _explore_zipfile(zip_path):\n    \n    \n    return _group_files_by_xml_filename(\n        _explore_zipfile_helper(zip_path))\n", "def _explore_zipfile(zip_path):\n    \n    \n    result = {}\n    for root, dirs, files in os.walk(zip_path):\n        for file in files:\n            result[os.path.relpath(os.path.join(root, file), zip_path)] = {\n                'path': os.path.join(root, file),\n                'filename': os.path.basename(file)\n            }\n    return result\n", "def _explore_zipfile(zip_path):\n    return _group_files_by_xml_filename(\n        _explore_zip(zip_path)\n    )\n", "def _explore_zipfile(zip_path):\n    \n    \n    filenames = os.listdir(zip_path)\n    filenames.sort()\n    for filename in filenames:\n        _group_files_by_xml_filename(zip_path, filename)\n", "def _explore_zipfile(zip_path):\n    file_names = _group_files_by_xml_filename(zip_path)\n    for file_name in file_names:\n        yield os.path.join(zip_path, file_name)\n", "def _explore_zipfile(zip_path):\n    \n    \n    groups = {}\n    for root, dirs, files in os.walk(zip_path):\n        for filename in files:\n            if filename.endswith('.xml'):\n                filepath = os.path.join(root, filename)\n                groups[filepath] = _group_files_by_xml_filename(filepath)\n    return groups\n", "def _explore_zipfile(zip_path):\n    \n    \n    return _group_files_by_xml_filename(_explore_zip(zip_path))\n", "def _explore_zipfile(zip_path):\n    return _group_files_by_xml_filename(\n        os.path.join(zip_path, '*.xml')\n    )\n", "def _explore_zipfile(zip_path):\n    return _group_files_by_xml_filename([zip_path])\n"]}
{"_id": "62b463163879012d194814a6", "generate_results": ["def files_list_from_zipfile(zip_path):\n    with zipfile.ZipFile(zip_path) as zf:\n        return zf.namelist()\n", "def files_list_from_zipfile(zip_path):\n    \n    \n    zip_file = ZipFile(zip_path)\n    return [filename.filename for filename in zip_file.infolist()]\n", "def files_list_from_zipfile(zip_path):\n    return [zfile.filename for zfile in zipfile.ZipFile(zip_path, 'r')]", "def files_list_from_zipfile(zip_path):\n    return zipfile.ZipFile(zip_path).namelist()\n", "def files_list_from_zipfile(zip_path):\n    if not zip_path:\n        return []\n    return [x for x in zipfile.ZipFile(zip_path).namelist() if x.endswith('/')]\n", "def files_list_from_zipfile(zip_path):\n    with zipfile.ZipFile(zip_path, 'r') as zip_file:\n        return zip_file.namelist()\n", "def files_list_from_zipfile(zip_path):\n    with zipfile.ZipFile(zip_path) as zip_file:\n        return zip_file.namelist()\n", "def files_list_from_zipfile(zip_path):\n    \n    \n    return [\n        os.path.join(zip_path, f)\n        for f in os.listdir(zip_path)\n        if os.path.isfile(os.path.join(zip_path, f))\n    ]\n", "def files_list_from_zipfile(zip_path):\n    with zipfile.ZipFile(zip_path, 'r') as zip_file:\n        return zip_file.namelist()\n", "def files_list_from_zipfile(zip_path):\n    return [f for f in zipfile.ZipFile(zip_path).namelist()]\n"]}
{"_id": "62b4631b3879012d194814dd", "generate_results": ["def fix_namespace_prefix_w(content):\n    return re.sub(r'w:([^:]+):st=\"([^\"]+)\"', r'w-st=\"\\1\"', content)\n", "def fix_namespace_prefix_w(content):\n    return re.sub(r'w:st=\"([^\"]+)\"', r'w-st=\"\\1\"', content)\n", "def fix_namespace_prefix_w(content):\n    return re.sub(r'<w:st=\"(.*?)\">', r'w-st=\"\\1\"', content)\n", "def fix_namespace_prefix_w(content):\n    \n    \n    return re.sub(r'w:st=\"(.*)\"', r'w-st=\"\\1\"', content)\n", "def fix_namespace_prefix_w(content):\n    return re.sub(r'\\s*w:st=\"(.*?)\"', r'w-st=\"{}\"'.format(WIDTH), content)\n", "def fix_namespace_prefix_w(content):\n    return re.sub(r'\\s+w:st=\"(.*?)\"', r'w-st=\"%s\"' % get_namespace_prefix(content), content)\n", "def fix_namespace_prefix_w(content):\n    \n    \n    return re.sub(r'w:st=\"(.*?)\"', r'w-st=\"\\1\"', content)\n", "def fix_namespace_prefix_w(content):\n    return re.sub(r' w:st=\"([^\"]*)\"', r' w-st=\"\\1\"', content)\n", "def fix_namespace_prefix_w(content):\n    return re.sub(r'w:(\\w+)=\"(.*?)\"', r'w-st=\"\\1\"', content)\n", "def fix_namespace_prefix_w(content):\n    \n    \n    return re.sub(r'w:st=\"(.*?)\"', r'w-st=\"\\1\"', content)"]}
{"_id": "62b463283879012d1948153d", "generate_results": ["def match_pubdate(node, pubdate_xpaths):\n    \n    \n    return node.xpath(pubdate_xpaths[0]).extract_first()", "def match_pubdate(node, pubdate_xpaths):\n    for pubdate_xpath in pubdate_xpaths:\n        pubdate = node.xpath(pubdate_xpath)\n        if pubdate:\n            return pubdate[0]\n", "def match_pubdate(node, pubdate_xpaths):\n    for pubdate_xpath in pubdate_xpaths:\n        pubdate = node.xpath(pubdate_xpath)[0].text\n        if pubdate:\n            return pubdate\n", "def match_pubdate(node, pubdate_xpaths):\n    for pubdate_xpath in pubdate_xpaths:\n        pubdate = node.find(pubdate_xpath)\n        if pubdate is not None:\n            return pubdate\n", "def match_pubdate(node, pubdate_xpaths):\n    return next((x for x in pubdate_xpaths if x.match(node)), None)", "def match_pubdate(node, pubdate_xpaths):\n    \n    \n    return node.xpath(pubdate_xpaths[0]).get().text_content()\n", "def match_pubdate(node, pubdate_xpaths):\n    \n    \n    for pubdate_xpath in pubdate_xpaths:\n        pubdate_node = node.xpath(pubdate_xpath)\n        if pubdate_node:\n            return pubdate_node[0]\n    return None\n", "def match_pubdate(node, pubdate_xpaths):\n    \n    \n    for pubdate_xpath in pubdate_xpaths:\n        match = node.xpath(pubdate_xpath)\n        if match:\n            return match[0]\n    return None\n", "def match_pubdate(node, pubdate_xpaths):\n    for pubdate_xpath in pubdate_xpaths:\n        pubdate = node.xpath(pubdate_xpath)\n        if pubdate:\n            return pubdate[0]\n    return None\n", "def match_pubdate(node, pubdate_xpaths):\n    for pubdate_xpath in pubdate_xpaths:\n        pubdate_el = node.xpath(pubdate_xpath)\n        if pubdate_el:\n            return pubdate_el[0].text\n"]}
{"_id": "62b463303879012d19481579", "generate_results": ["def _extract_number_and_supplment_from_issue_element(issue):\n    \n    \n    number = issue.find('.//number').text\n    suppl = issue.find('.//supplement').text\n    return number, suppl\n", "def _extract_number_and_supplment_from_issue_element(issue):\n    number = issue.find('.//number').text\n    sup = issue.find('.//supplement').text\n    return number, sup\n", "def _extract_number_and_supplment_from_issue_element(issue):\n    return issue.find('.//number').text, issue.find('.//sup').text\n", "def _extract_number_and_supplment_from_issue_element(issue):\n    return (\n        issue.find(\"number\", recursive=False).text,\n        issue.find(\"sup\", recursive=False).text,\n    )\n", "def _extract_number_and_supplment_from_issue_element(issue):\n    number = issue.find('number').text\n    sup = issue.find('sup').text\n    return number, sup\n", "def _extract_number_and_supplment_from_issue_element(issue):\n    return (_extract_number_from_issue_element(issue),\n            _extract_supplement_from_issue_element(issue))\n", "def _extract_number_and_supplment_from_issue_element(issue):\n    number = issue.find('.//{http://purl.org/dc/elements/1.1/}number').text\n    sup = issue.find('.//{http://purl.org/dc/elements/1.1/}sup').text\n    return number, sup\n", "def _extract_number_and_supplment_from_issue_element(issue):\n    number_and_supplment = issue.find(\n        './/{http://purl.org/dc/elements/1.1/}number').text\n    return number_and_supplment\n", "def _extract_number_and_supplment_from_issue_element(issue):\n    number = _extract_element_text(issue, 'number')\n    if number is None:\n        raise ValueError('No number found in issue element.')\n    sup = _extract_element_text(issue,'sup')\n    if sup is None:\n        raise ValueError('No sup found in issue element.')\n    return number, sup\n", "def _extract_number_and_supplment_from_issue_element(issue):\n    number = issue.find('.//number').text\n    sup = issue.find('.//supplement').text\n    return number, sup\n"]}
{"_id": "62b46740d2f69a53b466171a", "generate_results": ["def pretty(self, indent=0, debug=False):\n    return debug_pretty(self, indent, debug)\n", "def pretty(self, indent=0, debug=False):\n    debug_details = \"\"\n    if debug:\n        debug_details = f\"{self.__class__.__name__}({self.obj})\"\n    return f\"{indent * indent}{self.__class__.__name__}({debug_details}{self.obj})\"\n", "def pretty(self, indent=0, debug=False):\n    return (\n        f\"{self.__class__.__name__}({debug_details}{self.obj})\"\n        if debug\n        else f\"{self.__class__.__name__}({self.obj})\"\n    )\n", "def pretty(self, indent=0, debug=False):\n    return (\n        f\"{self.__class__.__name__}(\"\n        f\"{self.obj}\"\n        f\")\"\n    )\n", "def pretty(self, indent=0, debug=False):\n    if debug:\n        return \"{}({})\".format(self.__class__.__name__, repr(self))\n    else:\n        return \"{}({})\".format(self.__class__.__name__, repr(self))", "def pretty(self, indent=0, debug=False):\n    if debug:\n        print(f\"{self.__class__.__name__}({self.obj})\")\n        return \"\"\n    return f\"{self.__class__.__name__}({self.obj})\"\n", "def pretty(self, indent=0, debug=False):\n    debug_details = f\"{self.__class__.__name__}({self.obj})\"\n    return (\n        (indent * \" \" + \"\\n\")\n        if debug\n        else (indent * \" \" + \"\\n\")\n        + debug_details\n    )\n", "def pretty(self, indent=0, debug=False):\n    return f\"{self.__class__.__name__}({debug_details}{self.obj})\"\n", "def pretty(self, indent=0, debug=False):\n    indent = indent * \" \"\n    obj = str(self)\n    if debug:\n        print(\"pretty: {}\".format(obj))\n    if isinstance(obj, str):\n        return obj\n    else:\n        return f\"{indent}{obj}\"\n", "def pretty(self, indent=0, debug=False):\n    return (\n        f\"{self.__class__.__name__}({self.obj})\"\n        if isinstance(self.obj, str)\n        else f\"{self.__class__.__name__}({self.obj}, {debug_details})\"\n    )\n"]}
{"_id": "62b46746d2f69a53b4661722", "generate_results": ["def absorb(self, args):\n    return [ absorb_expr(self, arg) for arg in args ]", "def absorb(self, args):\n    return [self] + args", "def absorb(self, args):\n    return self.assign(*args)", "def absorb(self, args):\n    return args", "def absorb(self, args):\n    return self.absorb_expr(args)", "def absorb(self, args):\n    return [arg + self for arg in args]", "def absorb(self, args):\n    args = list(args)\n    for arg in args:\n        if isinstance(arg, Expr):\n            arg.absorb()\n        else:\n            self.absorb([arg])\n    return args", "def absorb(self, args):\n    return list(self.absorb_expr(args))", "def absorb(self, args):\n    return self.__class__(*[absorb_expr(arg) for arg in args])", "def absorb(self, args):\n    return [self] + [arg.absorb() for arg in args]\n"]}
{"_id": "62b86707b4d922cb0e688c2a", "generate_results": ["def on(self, hook):\ndef decorator(f):\nself._hooks.append((hook, f))\nreturn f\nreturn decorator", "def on(self, hook):\n    def decorator(func):\n        self.registry[hook].append(func)\n        return func\n    return decorator", "def on(self, hook):\n    def decorator(f):\n        self.hooks[hook].append(f)\n        return f\n    return decorator", "def on(self, hook):\n    def decorator(f):\n        self.register[hook].append(f)\n        return f\n    return decorator", "def on(self, hook):\n    def decorator(f):\n        self.registry.hooks[hook].append(f)\n        return f\n    return decorator\n", "def on(self, hook):\n\n    def decorator(func):\n        self._registry[hook].append(func)\n        return func\n\n    return decorator\n", "def on(self, hook):\n\ndef decorator(func):\nself.registry[hook].append(func)\nreturn func\n\nreturn decorator", "def on(self, hook):\ndef decorator(f):\nself.registry[hook].append(f)\nreturn f\nreturn decorator\n", "def on(self, hook):\n\ndef decorator(f):\nself._hooks[hook].append(f)\nreturn f\nreturn decorator", "def on(self, hook):\n    def decorator(func):\n        self.hooks[hook] = func\n        return func\n    return decorator"]}
{"_id": "62b86729b4d922cb0e688c2f", "generate_results": ["def base_config(user, etcd_host=\"localhost\", etcd_port=2379):\n    return {\n        \"etcd_host\": etcd_host,\n        \"etcd_port\": etcd_port,\n        \"user\": user,\n        \"etcd_auth\": \"none\",\n        \"etcd_key\": \"\",\n        \"etcd_docs\": \"\",\n        \"etcd_log\": \"\"\n    }\n", "def base_config(user, etcd_host=\"localhost\", etcd_port=2379):\n    config = {\"tls\": {\"client\": \"https://localhost:%s\" % etcd_port,\n                      \"ca_cert\": \"/etc/etcd/ca.crt\"},\n              \"authentication\": {\"client\": \"https://localhost:%s\" % etcd_port,\n                                 \"client_ca\": \"/etc/etcd/client.crt\"},\n              \"authorization\": {\"client\": \"https://localhost:%s\" % etcd_port,\n                                 \"client_ca\": \"/etc/etcd/client.crt\"},\n              \"docs\": {}}\n    return config\n", "def base_config(user, etcd_host=\"localhost\", etcd_port=2379):\n    config = {\n        \"tls\": {\n            \"host\": etcd_host,\n            \"port\": etcd_port,\n        },\n        \"authentication\": {\n            \"username\": user,\n            \"password\": \"password\",\n        },\n        \"authorization\": {\n            \"username\": user,\n            \"password\": \"password\",\n        },\n        \"docs\": {\n            \"auth\": {\n                \"username\": user,\n                \"password\": \"password\",\n            },\n        },\n    }\n    return config", "def base_config(user, etcd_host=\"localhost\", etcd_port=2379):\n    etcd_base_url = \"http://{}:{}/\".format(etcd_host, etcd_port)\n\n    return {\n        \"etcd_base_url\": etcd_base_url,\n        \"user\": user,\n        \"etcd_port\": etcd_port,\n        \"etcd_tls\": True,\n        \"etcd_authentication\": \"tls\",\n        \"etcd_authorization\": \"authorization\",\n        \"etcd_docs\": \"docs\",\n        \"etcd_log\": \"log\"\n    }\n", "def base_config(user, etcd_host=\"localhost\", etcd_port=2379):\n    cfg = Config()\n    cfg.tls = True\n    cfg.authentication = \"basic\"\n    cfg.authorization = \"basic\"\n    cfg.etcd = True\n    cfg.docs = True\n    cfg.log = True\n    cfg.etcd_host = etcd_host\n    cfg.etcd_port = etcd_port\n    cfg.user = user\n    return cfg\n", "def base_config(user, etcd_host=\"localhost\", etcd_port=2379):\n    return {\n        \"etcd\": {\n            \"host\": etcd_host,\n            \"port\": etcd_port,\n        },\n        \"docs\": {\n            \"authentication\": \"basic\",\n            \"authorization\": \"basic\",\n        },\n        \"log\": {\n            \"level\": \"INFO\",\n            \"format\": \"json\",\n            \"timestamp\": True,\n            \"level\": \"DEBUG\",\n        },\n    }\n", "def base_config(user, etcd_host=\"localhost\", etcd_port=2379):\n    etcd_conf = {\"etcd\": {\"host\": etcd_host, \"port\": etcd_port}}\n    etcd_conf.update({\"tls\": {\"secure\": True, \"ca_certs\": None}})\n    etcd_conf.update({\"authentication\": {\"cert_reqs\": ssl.CERT_NONE}})\n    etcd_conf.update({\"authorization\": {\"cert_reqs\": ssl.CERT_NONE}})\n    etcd_conf.update({\"docs\": {\"cert_reqs\": ssl.CERT_NONE}})\n    etcd_conf.update({\"log\": {\"cert_reqs\": ssl.CERT_NONE}})\n    return etcd_conf\n", "def base_config(user, etcd_host=\"localhost\", etcd_port=2379):\n    config = Config()\n    config.user = user\n    config.etcd_host = etcd_host\n    config.etcd_port = etcd_port\n    config.docs = \"\"\n    config.log = \"\"\n    return config\n", "def base_config(user, etcd_host=\"localhost\", etcd_port=2379):\n    return {\"tls\": {\"host\": etcd_host, \"port\": etcd_port}, \"authentication\": {\"username\": user, \"password\": \"\"},\n            \"authorization\": {\"username\": user, \"password\": \"\"}, \"docs\": {\"/\": {\"tls\": {\"private-key\": \"\", \"key\": \"\"}, \"etcd\": {\"etcd\": {\"etcd\": {\"etcd\": {\"etcd\": {\"etcd\": {\"etcd\": {\"etcd\": {\"etcd\": {\"etcd\": {\"etcd\": {\"etcd\": {\"etcd\": {\"etcd\": {\"etcd\": {\"etcd\": {\"etcd\": {\"etcd\": {\"etcd\": {\"etcd\": {\"etcd\": {\"etcd\": {\"etcd\": {\"etcd\": {\"etcd\": {\"etcd\": {\"etcd\": {\"etcd\": {\"etcd\": {\"etcd\": {\"etcd\": {\"etcd\": {\"etcd\": {\"etcd\": {\"etcd\": {\"etcd\": {\"etcd\": {\"etcd\": {\"etcd\": {\"etcd\": {\"etcd\": {\"etcd\": {\"etcd\": {\"etcd\": {\"etcd\"}\"}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}", "def base_config(user, etcd_host=\"localhost\", etcd_port=2379):\n    return {\n        \"etcd_host\": etcd_host,\n        \"etcd_port\": etcd_port,\n        \"etcd_user\": user,\n        \"etcd_password\": \"\",\n        \"etcd_data_dir\": \"/var/lib/etcd/data\",\n        \"etcd_doc_dir\": \"/var/lib/etcd/docs\",\n        \"etcd_log_dir\": \"/var/lib/etcd/logs\"\n    }\n"]}
{"_id": "62b8a4a4755ee91dce50a3d2", "generate_results": ["def _fromutc(self, dt):\n    if dt.tzinfo is None:\n        raise TypeError(\"Cannot fromutc a naive datetime.\")\n    return dt.astimezone(self._tzinfo)", "def _fromutc(self, dt):\n    return dt.astimezone(self.timezone)", "def _fromutc(self, dt):\n    return dt.astimezone(self.tzinfo)", "def _fromutc(self, dt):\n    if dt.tzinfo is None:\n        raise ValueError('Datetime cannot be fromutc.')\n    return dt.astimezone(self._tzinfo)\n", "def _fromutc(self, dt):\n    # type: (datetime) -> datetime\n    if self._tzinfo is None:\n        raise ValueError(\"a fromutc() must be called before a datetime.fromutc()\")\n    return dt.astimezone(self._tzinfo)\n", "def _fromutc(self, dt):\n    return self._tz.fromutc(dt)\n", "def _fromutc(self, dt):\n    if dt.tzinfo:\n        raise TypeError(\"Can't fromutc on timezone with tzinfo\")\n    return dt.replace(tzinfo=self.tzinfo)\n", "def _fromutc(self, dt):\n    return dt.astimezone(self.tz)", "def _fromutc(self, dt):\n    # type: (datetime) -> datetime\n    return dt.astimezone(self.tz)\n", "def _fromutc(self, dt):\n    return dt.astimezone(self.tz)\n"]}
{"_id": "62b8982f755ee91dce50a241", "generate_results": ["def normalized(self):\n    return Time(self._hours * 3600, self._minutes * 60, self._seconds)\n", "def normalized(self):\n    \n    \n    return self / self.units.normalized()\n", "def normalized(self):\n    return self * (1 / self.to(u.s).value)", "def normalized(self):\n    return self.__class__(self._magnitude.normalized(), self._units)\n", "def normalized(self):\n    return self / self.to('s')", "def normalized(self):\n    \n    \n    return Time(self.value / self._units, format='sec')\n", "def normalized(self):\n    \n    \n    return self.to_time('ms')", "def normalized(self):\n    return self.to_time().to_integer()", "def normalized(self):\n    return self.to_time().to_time_int()\n", "def normalized(self):\n    for unit in self.units:\n        self.units[unit] = int(self.units[unit])\n    return self"]}
{"_id": "62b89640755ee91dce50a114", "generate_results": ["def tzname_in_python2(namefunc):\n    \n    \n    if six.PY2:\n        return namefunc\n    else:\n        return namefunc.encode('utf-8')\n", "def tzname_in_python2(namefunc):\n\n    def decorator(cls):\n        for k, v in cls.__dict__.items():\n            if isinstance(v, unicode):\n                cls.__dict__[k] = v.encode('utf-8')\n        cls.__dict__['__unicode__'] = cls.__dict__['__str__']\n        cls.__dict__['__str__'] = namefunc(cls)\n        return cls\n    return decorator", "def tzname_in_python2(namefunc):\n    def tzname(self, dt):\n        name = namefunc(self, dt)\n        return name.encode('utf-8')\n    return tzname", "def tzname_in_python2(namefunc):\n    \n    \n    def wrapper(self, *args, **kwargs):\n        name = namefunc(self, *args, **kwargs)\n        if six.PY2:\n            name = name.encode('utf-8')\n        return name\n    return wrapper\n", "def tzname_in_python2(namefunc):\n    def inner(self):\n        return namefunc(self).encode(\"utf-8\")\n    return inner\n", "def tzname_in_python2(namefunc):\n    return lambda x: namefunc(x.encode(\"utf-8\"))\n", "def tzname_in_python2(namefunc):\n    if sys.version_info[0] < 3:\n        return namefunc\n    else:\n        return functools.partial(namefunc, encoding='utf-8')", "def tzname_in_python2(namefunc):\n\n    def wrapper(self, dt):\n        if not isinstance(dt, datetime.datetime):\n            raise ValueError('datetime expected')\n        if dt.tzinfo is None:\n            dt = dt.replace(tzinfo=pytz.utc)\n        return namefunc(self, dt)\n\n    return wrapper\n", "def tzname_in_python2(namefunc):\n    \n    \n    def inner(tzname):\n        if sys.version_info < (3, 0):\n            return namefunc(tzname.encode('utf-8'))\n        else:\n            return namefunc(tzname)\n    return inner\n", "def tzname_in_python2(namefunc):\n\n    def wrapper(tz):\n        if isinstance(tz, tzinfo):\n            return tz.zone\n        else:\n            return tz\n\n    return wrapper(tzname)(namefunc)\n"]}
{"_id": "62b87d24d292efb640a55670", "generate_results": ["def get_versions():\n    try:\n        return _versions\n    except NameError:\n        return DEFAULT_VERSIONS\n", "def get_versions():\n    try:\n        from. import __version__\n        return __version__\n    except ImportError:\n        return '1.0.0'", "def get_versions():\n    return get_version(\"versions\")\n", "def get_versions():\n    return __version__", "def get_versions():\n    return __version__\n", "def get_versions():\n    return _versions\n", "def get_versions():\n    if VERSION is None:\n        return DEFAULT_VERSIONS\n    return VERSION\n", "def get_versions():\n    return __version__", "def get_versions():\n    return _get_versions()\n", "def get_versions():\n    versions = get_versions_dict()\n\n    if not versions:\n        return {}\n\n    return versions"]}
{"_id": "62b87d24d292efb640a5566f", "generate_results": ["def render(pieces, style):\n    for piece in pieces:\n        piece.render(style)\n", "def render(pieces, style):\n    output = ''\n    for piece in pieces:\n        output += piece.render(style)\n    return output", "def render(pieces, style):\n    return ''.join([style for piece in pieces for style in piece])", "def render(pieces, style):\n    \n    \n    styles = {'default': style}\n    return ''.join(render_piece(piece, styles[piece['style']])\n                   for piece in pieces)\n", "def render(pieces, style):\n    for piece in pieces:\n        piece.render(style)", "def render(pieces, style):\n    if style == 'full':\n        print(''.join(pieces))\n    elif style == 'line':\n        for piece in pieces:\n            print(piece)\n    elif style == 'column':\n        print(''.join([''* piece_length for piece_length in pieces]))\n", "def render(pieces, style):\n    for piece in pieces:\n        piece.render(style)", "def render(pieces, style):\n    \n    \n    for piece in pieces:\n        piece.render(style)\n", "def render(pieces, style):\n    \n    \n    for piece in pieces:\n        piece.render(style)\n", "def render(pieces, style):\n    return '\\n'.join(render_piece(piece, style) for piece in pieces)\n"]}
{"_id": "62b87d24d292efb640a5566d", "generate_results": ["def plus_or_dot(pieces):\n    return \".\" if \"+\" in pieces else \"+\"\n", "def plus_or_dot(pieces):\n    if \"+\" in pieces:\n        return \".\"\n    else:\n        return \"+\"\n", "def plus_or_dot(pieces):\n    for i in range(len(pieces)):\n        if pieces[i].tag == \"+\":\n            return \".\" if pieces[i].closest_tag == \"+\" else \"+\"\n    return \"+\"\n", "def plus_or_dot(pieces):\n    if pieces[-1] == \"+\":\n        return \".\"\n    else:\n        return \"+\"\n", "def plus_or_dot(pieces):\n    return \".\" if pieces[-1] == \"+\" else \"+\"\n", "def plus_or_dot(pieces):\n    if \"+\" in pieces:\n        return \".\"\n    else:\n        return \"+\"\n", "def plus_or_dot(pieces):\n    return \".\".join(pieces) if pieces else \"+\"\n", "def plus_or_dot(pieces):\n    return \".\" if \"+\" in pieces.lower() else \"+\"\n", "def plus_or_dot(pieces):\n    return \".\" if pieces[-1] == \"+\" else \"+\"\n", "def plus_or_dot(pieces):\n    return \"+\" if \"+\" in pieces.lower() else \".\"\n"]}
{"_id": "62b87d23d292efb640a5566b", "generate_results": ["def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    return run_commands(commands, args, cwd, verbose, hide_stderr, env)\n", "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    return run(commands, args, cwd, verbose, hide_stderr, env)\n", "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    if not env:\n        env = {}\n    if verbose:\n        env['PYTHONVERBOSE'] = '1'\n    if cwd:\n        env['PYTHONCWD'] = cwd\n    proc = subprocess.Popen(commands, env=env, cwd=cwd, stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=False)\n    out, err = proc.communicate(args)\n    return out, err, proc.returncode\n", "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    return commands.run(args, cwd, verbose, hide_stderr, env)\n", "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    print(\"running command: %s\" % commands)\n    if not env:\n        env = os.environ.copy()\n    result = subprocess.run(\n        args, stdout=subprocess.PIPE, stderr=subprocess.PIPE, cwd=cwd, env=env, check=True,\n        universal_newlines=True, shell=False, capture_output=True, universal_newlines=True, verbose=verbose\n    )\n    if not hide_stderr:\n        sys.stderr.write(result.stderr)\n        sys.stderr.write(result.stdout)\n    return result.returncode\n", "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    return run_commands(commands, args, cwd, verbose, hide_stderr, env)", "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    \n    \n    try:\n        return execute_command(commands, args, cwd, verbose, hide_stderr, env)\n    except Exception:\n        raise Exception('{0}'.format(traceback.format_exc()))", "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    \n    \n    return commands", "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    \n    \n    if not env:\n        env = os.environ.copy()\n    for command in commands:\n        args = ['sh'] + args + [command]\n        if verbose:\n            print(' '.join(args))\n        if hide_stderr:\n            print(' '.join(args))\n        subprocess.call(args, cwd=cwd, env=env)\n", "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    if not args:\n        return None\n\n    if len(args) == 1:\n        return run_command_single(commands, args, cwd, verbose, hide_stderr, env)\n\n    return run_command_list(commands, args, cwd, verbose, hide_stderr, env)\n"]}
{"_id": "62b87d23d292efb640a55668", "generate_results": ["def get_config():\n    # these strings are filled in when'setup.py versioneer' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = \"git\"\n    cfg.style = \"pep440\"\n    cfg.tag_prefix = \"\"\n    cfg.parentdir_prefix = \"None\"\n    cfg.versionfile_source = \"src/ete2/_version.py\"\n    cfg.verbose = False\n    return cfg\n", "def get_config():\n    # these strings are filled in when'setup.py versioneer' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = \"git\"\n    cfg.style = \"pep440\"\n    cfg.tag_prefix = \"\"\n    cfg.parentdir_prefix = \"None\"\n    cfg.versionfile_source = \"src/utils/_version.py\"\n    cfg.verbose = False\n    return cfg\n", "def get_config():\n    # these strings are filled in when'setup.py versioneer' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = \"git\"\n    cfg.style = \"pep440-post\"\n    cfg.tag_prefix = \"v\"\n    cfg.parentdir_prefix = \"None\"\n    cfg.versionfile_source = \"v_workflow/_version.py\"\n    cfg.verbose = False\n    return cfg\n", "def get_config():\n    # these strings are filled in when'setup.py versioneer' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = \"git\"\n    cfg.style = \"pep440\"\n    cfg.tag_prefix = \"\"\n    cfg.parentdir_prefix = \"None\"\n    cfg.versionfile_source = \"src/asyncio/_version.py\"\n    cfg.verbose = False\n    return cfg\n", "def get_config():\n    # these strings are filled in when'setup.py versioneer' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = \"git\"\n    cfg.style = \"pep440\"\n    cfg.tag_prefix = \"\"\n    cfg.parentdir_prefix = \"\"\n    cfg.versionfile_source = \"espresso/_version.py\"\n    cfg.verbose = False\n    return cfg\n", "def get_config():\n    # these strings are filled in when'setup.py versioneer' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = \"git\"\n    cfg.style = \"pep440\"\n    cfg.tag_prefix = \"\"\n    cfg.parentdir_prefix = \"None\"\n    cfg.versionfile_source = \"src/dst/_version.py\"\n    cfg.verbose = False\n    return cfg\n", "def get_config():\n    # these strings are filled in when'setup.py versioneer' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = \"git\"\n    cfg.style = \"pep440\"\n    cfg.tag_prefix = \"v\"\n    cfg.parentdir_prefix = \"None\"\n    cfg.versionfile_source = \"maas/_version.py\"\n    cfg.verbose = False\n    return cfg\n", "def get_config():\n    # these strings are filled in when'setup.py versioneer' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = \"git\"\n    cfg.style = \"pep440\"\n    cfg.tag_prefix = \"\"\n    cfg.parentdir_prefix = \"None\"\n    cfg.versionfile_source = \"tutorial/_version.py\"\n    cfg.verbose = False\n    return cfg\n", "def get_config():\n    # these strings are filled in when'setup.py versioneer' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = \"git\"\n    cfg.style = \"pep440\"\n    cfg.tag_prefix = \"\"\n    cfg.parentdir_prefix = \"None\"\n    cfg.versionfile_source = \"talos/_version.py\"\n    cfg.verbose = False\n    return cfg\n", "def get_config():\n    # these strings are filled in when'setup.py versioneer' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = \"git\"\n    cfg.style = \"pep440\"\n    cfg.tag_prefix = \"\"\n    cfg.parentdir_prefix = \"None\"\n    cfg.versionfile_source = \"src/nextgen/_version.py\"\n    cfg.verbose = False\n    return cfg\n"]}
{"_id": "62b87d23d292efb640a55667", "generate_results": ["def register_vcs_handler(vcs, method):\n    \n    \n    def decorator(method):\n        method.vcs = vcs\n        method.handler = method\n        return method\n    return decorator\n", "def register_vcs_handler(vcs, method):\n    \n    \n    def decorator(f):\n        vcs.handlers[method] = f\n        return f\n    return decorator", "def register_vcs_handler(vcs, method):\n    \n    \n    def register(f):\n        \"\"\"\n        Mark a method as the handler of a object\n        \"\"\"\n        if not hasattr(f, \"_vcs_handler\"):\n            f._vcs_handler = []\n        f._vcs_handler.append(method)\n        return f\n    return register\n", "def register_vcs_handler(vcs, method):\n    def decorator(func):\n        setattr(func, HANDLER_ATTR, method)\n        return func\n    return decorator\n", "def register_vcs_handler(vcs, method):\n    def decorator(func):\n        vcs._handlers[method] = func\n        return func\n    return decorator\n", "def register_vcs_handler(vcs, method):\n    \n    \n    def decorator(fn):\n        fn.__vcs__ = vcs\n        fn.__method__ = method\n        return fn\n    return decorator", "def register_vcs_handler(vcs, method):\n    \n    \n    def decorator(f):\n        if not hasattr(f, '__vcs_handlers__'):\n            f.__vcs_handlers__ = set()\n\n        f.__vcs_handlers__.add(method)\n\n        return f\n\n    return decorator\n", "def register_vcs_handler(vcs, method):\n    \n    \n    def decorator(f):\n        handler = {'vcs': vcs,'method': method}\n        setattr(f, '_vcs_handler', handler)\n        return f\n    return decorator\n", "def register_vcs_handler(vcs, method):\n    def _register_vcs_handler(method):\n        if not hasattr(method, '_vcs_handlers'):\n            method._vcs_handlers = set()\n        method._vcs_handlers.add((vcs, method))\n        return method\n    return _register_vcs_handler\n", "def register_vcs_handler(vcs, method):\n    def decorator(func):\n        setattr(vcs, method, func)\n        return func\n    return decorator"]}
{"_id": "62b45e945108cfac7f210a4a", "generate_results": ["def validate_hierarchy(self, validate_objects=True, check_digests=True, show_warnings=False):\n    \n    \n    pass", "def validate_hierarchy(self, validate_objects=True, check_digests=True, show_warnings=False):\n    if validate_objects:\n        return validate_hierarchy_objects(self, check_digests=check_digests, show_warnings=show_warnings)\n    return True\n", "def validate_hierarchy(self, validate_objects=True, check_digests=True, show_warnings=False):\n    \n    \n    pass", "def validate_hierarchy(self, validate_objects=True, check_digests=True, show_warnings=False):\n    return True\n", "def validate_hierarchy(self, validate_objects=True, check_digests=True, show_warnings=False):\n    return None\n", "def validate_hierarchy(self, validate_objects=True, check_digests=True, show_warnings=False):\n    \n    \n    pass", "def validate_hierarchy(self, validate_objects=True, check_digests=True, show_warnings=False):\n    \n    \n    pass", "def validate_hierarchy(self, validate_objects=True, check_digests=True, show_warnings=False):\n    return True", "def validate_hierarchy(self, validate_objects=True, check_digests=True, show_warnings=False):\n    \n    \n    pass", "def validate_hierarchy(self, validate_objects=True, check_digests=True, show_warnings=False):\n    if validate_objects:\n        self.validate_objects()\n    if check_digests:\n        self.check_digests()\n    if show_warnings:\n        self.show_warnings()"]}
{"_id": "62b45e515108cfac7f210a3c", "generate_results": ["def initialize(self):\n    \n    \n    return self._init_with_defaults()", "def initialize(self):\n    \n    \n    self._ocfl_root = self._ocfl.new_ocfl_root()\n", "def initialize(self):\n    \n    \n    self._storage_root = OCFLStorageRoot(self)\n    self._storage_root.initialize()\n    self._storage_root.initialize_data()\n    self._storage_root.initialize_cache()\n    self._storage_root.initialize_cache_storage()\n    self._storage_root.initialize_cache_data_storage()\n    self._storage_root.initialize_cache_cache_storage()", "def initialize(self):\n    \n    \n    self.__init__(self.__storage_root__)\n", "def initialize(self):\n    \n    \n    if not self._initialized:\n        self._initialized = True\n        self._storage_root_path = self._storage_root.create()", "def initialize(self):\n    \n    \n    OCFL_STORAGE_ROOT = self._get_config()['OCFL_STORAGE_ROOT']\n    self._init_from_config(OCFL_STORAGE_ROOT)\n", "def initialize(self):\n    \n    \n    pass", "def initialize(self):\n    \n    \n    return ocfl_storage_root()", "def initialize(self):\n    \n    \n    self.__init__()", "def initialize(self):\n    \n    \n    return ocfl_storage_root()"]}
{"_id": "62b45e2eb89c9fd354170232", "generate_results": ["def next_version(version):\n    \n    \n    version_len = len(version)\n    return version + (version_len * (version_len - 1))\n", "def next_version(version):\n    if version in PATTERNS:\n        return PATTERNS[version]\n    else:\n        return None\n", "def next_version(version):\n    return int(version.split('.')[0]) + 1\n", "def next_version(version):\n    return version + 1\n", "def next_version(version):\n    return version + 1\n", "def next_version(version):\n    return version + 1", "def next_version(version):\n    \n    \n    return int(version.split('.')[0]) + 1\n", "def next_version(version):\n    \n    \n    while True:\n        if version == 0:\n            return 1\n        elif version == 1:\n            return 2\n        else:\n            version += 1\n", "def next_version(version):\n    return '%s-%s' % (version, next_version_num(version))\n", "def next_version(version):\n    pattern = r'\\d+'\n    next = re.findall(pattern, version)\n    return int(next[0])\n"]}
{"_id": "62b45e23e0d4551b0392c90a", "generate_results": ["def validate_version_inventories(self, version_dirs):\n    if version_dirs is None:\n        return\n\n    for version_dir in version_dirs:\n        if not os.path.isdir(version_dir):\n            raise ValueError('{} is not a directory'.format(version_dir))\n\n        if not os.access(version_dir, os.R_OK):\n            raise ValueError('{} is not readable'.format(version_dir))", "def validate_version_inventories(self, version_dirs):\n    \n    \n    return True", "def validate_version_inventories(self, version_dirs):\n    \n    \n    return True\n", "def validate_version_inventories(self, version_dirs):\n    pass\n", "def validate_version_inventories(self, version_dirs):\n    return version_dirs", "def validate_version_inventories(self, version_dirs):\n    if version_dirs is None:\n        return\n    for version_dir in version_dirs:\n        if not os.path.exists(version_dir):\n            raise ValueError(\n                \"Invalid version inventory directory {}\".format(version_dir)\n            )\n        elif not os.path.isdir(version_dir):\n            raise ValueError(\n                \"Invalid version inventory directory {}\".format(version_dir)\n            )\n", "def validate_version_inventories(self, version_dirs):\n    pass\n", "def validate_version_inventories(self, version_dirs):\n    return True\n", "def validate_version_inventories(self, version_dirs):\n    \n    \n    return True\n", "def validate_version_inventories(self, version_dirs):\n    \n    \n    pass"]}
{"_id": "62b45e21e0d4551b0392c8ed", "generate_results": ["def find_path_type(path):\n    if os.path.isfile(path):\n        return 'File'\n    elif os.path.isdir(path):\n        return 'Directory'\n    elif os.path.islink(path):\n        return 'Link'\n    else:\n        return 'Unknown'\n", "def find_path_type(path):\n    path_type = None\n    for p in path:\n        if p.kind == CursorKind.PATH_TYPE:\n            path_type = p.spelling\n            break\n    return path_type", "def find_path_type(path):\n    return os.path.splitext(path)[1][1:]\n", "def find_path_type(path):\n    \n    \n    if os.path.isfile(path):\n        return \"file\"\n    elif os.path.isdir(path):\n        return \"dir\"\n    elif os.path.islink(path):\n        return \"link\"\n    else:\n        return \"file\"", "def find_path_type(path):\n    \n    \n    return find_path_types(path)[0]", "def find_path_type(path):\n    for item in path:\n        if isinstance(item, (list, tuple)):\n            return 'list'\n        elif isinstance(item, dict):\n            return 'dict'\n        else:\n            return'str'", "def find_path_type(path):\n    \n    \n    if len(path) == 1:\n        return 'file'\n    elif len(path) == 2:\n        return 'dir'\n    else:\n        return 'unknown'\n", "def find_path_type(path):\n    for type_ in types:\n        if isinstance(type_, type):\n            return type_\n    raise ValueError(\"Could not find a valid type for path {}\".format(path))", "def find_path_type(path):\n    \n    \n    if isinstance(path, str):\n        path = [path]\n    for part in path:\n        if isinstance(part, str):\n            return \"file\"\n        if isinstance(part, list):\n            if isinstance(part[0], str):\n                return \"dir\"\n    return \"dir\"\n", "def find_path_type(path):\n    if not os.path.isdir(path):\n        return 'directory'\n    if not os.path.isfile(path):\n        return 'file'\n    if os.path.islink(path):\n        return 'link'\n    if os.path.isfile(path):\n        return 'file'\n    return 'directory'\n"]}
{"_id": "62b45b396decaeff903e1001", "generate_results": ["def amend_bzparams(self, params, bug_ids):\n    \n    \n    params[\"ids\"] = bug_ids\n    return params\n", "def amend_bzparams(self, params, bug_ids):\n    \n    \n    params['bug_ids'] = ','.join(bug_ids)\n    return params", "def amend_bzparams(self, params, bug_ids):\n    for bug_id in bug_ids:\n        params['id'] = bug_id\n        params['status'] = 'Open'\n        params['difficulty'] = 'Normal'\n        params['comment'] = ''\n        params['bug_type'] = 'Bug'\n        params['resolution'] = ''\n        params['importance'] = ''\n        params['priority'] = ''\n        params['severity'] = ''\n        params['status_change_date'] = ''\n        params['status_change_reason'] = ''\n        params['created_date'] = ''\n        params['updated_date'] = ''\n        params['version'] = ''", "def amend_bzparams(self, params, bug_ids):\n    for bz in bug_ids:\n        params['bz_id'] = bz\n        params['severity'] = 'INFO'\n        params['status'] = 'QUEUED'\n        params['bug_id'] = bz\n        params['description'] = ''\n        params['bug_id'] = bz\n        params['action'] = 'NEW'\n        params['status'] = 'QUEUED'\n        params['resolution'] = ''\n        params['status'] = 'CLOSED'\n        params['status'] = 'CLOSED'\n        params['status'] = 'CLOSED'\n        params['status'] = 'CLOSED'\n        params['status'] = 'CLOSED'", "def amend_bzparams(self, params, bug_ids):\n    \n    \n    if not bug_ids:\n        return params\n\n    if not isinstance(bug_ids, list):\n        bug_ids = [bug_ids]\n\n    params['bug_id'] = ','.join([str(i) for i in bug_ids])\n    return params", "def amend_bzparams(self, params, bug_ids):\n    \n    \n    params.update({\n        'bug_ids': bug_ids,\n    })\n    return params", "def amend_bzparams(self, params, bug_ids):\n    if bug_ids:\n        params['bug_ids'] = bug_ids\n    return params\n", "def amend_bzparams(self, params, bug_ids):\n    \n    \n    params['bug_ids'] = bug_ids\n    params['update'] = 'true'\n    return params\n", "def amend_bzparams(self, params, bug_ids):\n    params['bz_bug_ids'] = ','.join(bug_ids)\n    return params\n", "def amend_bzparams(self, params, bug_ids):\n    \n    \n    params['bug_ids'] = ','.join(bug_ids)\n    return params"]}
{"_id": "62b4567ed7d32e5b55cc83d9", "generate_results": ["def deep_merge_nodes(nodes):\n    result = nodes[0]\n    for node in nodes[1:]:\n        if node.value!= result.value:\n            result = node\n    return result\n", "def deep_merge_nodes(nodes):\n    return reduce(lambda d, k: d.setdefault(k, d.get(k, [])) + [k], nodes, [])\n", "def deep_merge_nodes(nodes):\n    result = nodes[0]\n    for node in nodes[1:]:\n        for key, value in node.items():\n            if isinstance(value, MappingNode):\n                if key in result:\n                    raise TypeError(\"Duplicate key {}\".format(key))\n                else:\n                    result[key] = value\n            else:\n                result[key] = value\n    return result", "def deep_merge_nodes(nodes):\n    if not nodes:\n        return nodes\n    result = {}\n    for k, v in nodes.items():\n        if isinstance(v, MappingNode):\n            r = deep_merge_nodes(v.items())\n            if r:\n                result[k] = r\n        else:\n            result[k] = v\n    return result", "def deep_merge_nodes(nodes):\n    result = []\n    for node in nodes:\n        if node.is_mapping_type():\n            result.append(deep_merge_nodes(node.values()))\n        else:\n            result.append(node)\n    return result\n", "def deep_merge_nodes(nodes):\n    new_nodes = []\n    for node in nodes:\n        if node.is_MappingNode:\n            new_nodes.extend(deep_merge_nodes(node.values))\n        else:\n            new_nodes.append(node)\n    return new_nodes", "def deep_merge_nodes(nodes):\n    return merge_dicts(nodes, nodes)\n", "def deep_merge_nodes(nodes):\n    result = []\n    for node in nodes:\n        if isinstance(node, MappingNode):\n            result.extend(node.values())\n        else:\n            result.append(node)\n    return result\n", "def deep_merge_nodes(nodes):\n    result = nodes[0]\n    for node in nodes[1:]:\n        if isinstance(node, MappingNode):\n            result = merge_mapping_nodes(result, node)\n        else:\n            result = merge_value(result, node)\n    return result\n", "def deep_merge_nodes(nodes):\n    duplicates = []\n    for node in nodes:\n        if isinstance(node, MappingNode):\n            if node.value in duplicates:\n                raise DuplicateKeyError(\"Duplicate key: {}\".format(node.value))\n            else:\n                duplicates.append(node.value)\n        else:\n            duplicates.append(node)\n    return duplicates\n"]}
{"_id": "62b4567ad7d32e5b55cc83af", "generate_results": ["def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--input\", \"-i\", type=str, required=True,\n                        help=\"The input file to process\")\n    parser.add_argument(\"--output\", \"-o\", type=str, required=True,\n                        help=\"The output file to write the results to\")\n    return parser.parse_args(*arguments)\n", "def parse_arguments(*arguments):\n    parser = ArgumentParser()\n\n    # Add all the arguments that were provided\n    for argument in arguments:\n        parser.add_argument(argument)\n\n    # Parse the arguments and return them as a argparse instance\n    return parser.parse_args()\n", "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser(description=__doc__)\n    return parser.parse_args(arguments)", "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser(\n        description=\"\"\"\n        Generates a JSON list of all of the assets in the database.\n        \"\"\"\n    )\n    parser.add_argument(\n        \"--file\",\n        dest=\"file\",\n        required=True,\n        help=\"The path to the file with the assets in the database.\",\n    )\n    return parser.parse_args(arguments)\n", "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser(\n        description=\"\"\"\\\n            Test the output of the 'diff' command.\n            \"\"\")\n\n    parser.add_argument(\n        '--diff', nargs='+',\n        help='The diff command to run')\n\n    return parser.parse_args(*arguments)\n", "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--data-dir', default='./data', help='data directory')\n    parser.add_argument('--model-dir', default='./model', help='model directory')\n    parser.add_argument('--save-dir', default='./save', help='save directory')\n    parser.add_argument('--exp-name', default='default', help='experiment name')\n    return parser.parse_args(*arguments)", "def parse_arguments(*arguments):\n    parser = ArgumentParser(\n        description=__doc__,\n        formatter_class=RawDescriptionHelpFormatter,\n        epilog=EXAMPLE_EXAMPLE,\n        formatter_description='A simple example usage example'\n    )\n\n    parser.add_argument('--input', type=str, help='The path to the input file.')\n    parser.add_argument('--output', type=str, help='The path to the output file.')\n\n    return parser.parse_args(*arguments)\n", "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--version', action='version', version='%(prog)s'+ __version__)\n    parser.add_argument('--debug', action='store_true', default=False, help='Debug mode')\n    return parser.parse_args(*arguments)\n", "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser(description=__doc__)\n    parser.add_argument(\"--config\", help=\"Configuration file\")\n    parser.add_argument(\"--host\", help=\"Host address\")\n    parser.add_argument(\"--port\", help=\"Port number\")\n    parser.add_argument(\"--logfile\", help=\"Log file name\")\n    parser.add_argument(\"--syslog\", help=\"Syslog enabled\")\n    parser.add_argument(\"--syslog-host\", help=\"Syslog host\")\n    parser.add_argument(\"--syslog-port\", help=\"Syslog port\")\n    return parser.parse_args(arguments)\n", "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser(description='')\n    parser.add_argument('-v', '--verbose', action='store_true',\n                        help='Show debug messages')\n    parser.add_argument('-d', '--debug', action='store_true',\n                        help='Show debug messages')\n    parser.add_argument('-o', '--output', help='Output file')\n\n    return parser.parse_args(arguments)\n"]}
{"_id": "62b45679d7d32e5b55cc83a9", "generate_results": ["def parser_flags(parser):\n    \n    \n    return parser.parse_args()\n", "def parser_flags(parser):\n    \n    \n    return parser.parse_args()", "def parser_flags(parser):\n    pass\n", "def parser_flags(parser):\n    \n    \n    parser.add_argument('--sys_exec', help='Executable to run system tests', type=str, default='')\n    return parser", "def parser_flags(parser):\n    \n    \n    pass\n", "def parser_flags(parser):\n    pass", "def parser_flags(parser):\n    \n    \n    pass\n", "def parser_flags(parser):\n    pass\n", "def parser_flags(parser):\n    pass", "def parser_flags(parser):\n    \n    \n    return None"]}
{"_id": "62b45665d7d32e5b55cc8365", "generate_results": ["def parse_arguments(*unparsed_arguments):\n    \n    \n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--file\", \"-f\", help=\"File to read from\")\n    parser.add_argument(\"--output\", \"-o\", help=\"Output file\")\n    args = parser.parse_args(unparsed_arguments)\n    return vars(args)\n", "def parse_arguments(*unparsed_arguments):\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--test_path\", type=str, help=\"path to test data\")\n    parser.add_argument(\"--output_path\", type=str, help=\"path to output file\")\n    args = parser.parse_args(unparsed_arguments)\n    return {\n        \"test_path\": args.test_path,\n        \"output_path\": args.output_path\n    }\n", "def parse_arguments(*unparsed_arguments):\n    parsed_arguments = {}\n    for arg in unparsed_arguments:\n        if arg in ('--', '-'):\n            continue\n        parsed_arguments[arg] = shlex.split(arg)\n    return parsed_arguments", "def parse_arguments(*unparsed_arguments):\n    \n    \n    return dict((arg.split(\"=\") for arg in unparsed_arguments))\n", "def parse_arguments(*unparsed_arguments):\n    \n    \n    parsed_arguments = {}\n\n    for argument in unparsed_arguments:\n        parsed_arguments[argument] = None\n\n    return parsed_arguments\n", "def parse_arguments(*unparsed_arguments):\n    parsed_arguments = {}\n    for arg in unparsed_arguments:\n        if isinstance(arg, str):\n            parsed_arguments[arg] = None\n        else:\n            parsed_arguments[arg[0]] = arg[1]\n\n    return parsed_arguments\n", "def parse_arguments(*unparsed_arguments):\n    \n    \n    arguments = {}\n    for i in unparsed_arguments:\n        for j in i.split(':'):\n            if j not in arguments:\n                arguments[j] = []\n            arguments[j].append(i)\n    return arguments\n", "def parse_arguments(*unparsed_arguments):\n    \n    \n    return dict(list(zip(unparsed_arguments[::2], unparsed_arguments[1::2])))\n", "def parse_arguments(*unparsed_arguments):\n    parsed_arguments = {}\n    for argument in unparsed_arguments:\n        if argument == '--version':\n            print('A tool for parsing the toolchain version')\n            sys.exit()\n        else:\n            # Strip the leading '-'\n            name = argument.split('-')[0]\n            parsed_arguments[name] = argument\n    return parsed_arguments\n", "def parse_arguments(*unparsed_arguments):\n    \n    \n    parsed_arguments = {}\n    for unparsed_argument in unparsed_arguments:\n        if unparsed_argument is None:\n            continue\n        if isinstance(unparsed_argument, str):\n            parsed_arguments[unparsed_argument] = None\n        elif isinstance(unparsed_argument, list):\n            parsed_arguments[unparsed_argument[0]] = [\n                None if i is None else i for i in unparsed_argument[1:]\n            ]\n        else:\n            raise ValueError('Unknown argument type: %s' % unparsed_argument)\n    return parsed_arguments\n"]}
{"_id": "62b45665d7d32e5b55cc8364", "generate_results": ["def parse_subparser_arguments(unparsed_arguments, subparsers):\n    pass", "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    return None", "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    \n    \n    return None\n", "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    pass\n", "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    pass\n", "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    \n    \n    pass\n", "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    raise Exception(\"Not implemented\")\n", "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    return\n", "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    \n    \n    pass\n", "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    return\n"]}
{"_id": "62b45665d7d32e5b55cc8363", "generate_results": ["def make_parsers():\n    parser = argparse.ArgumentParser(description='Extract data from an unpacked archive')\n    parser.add_argument('--source', required=True, help='Path to source directory')\n    parser.add_argument('--dest', required=True, help='Path to destination directory')\n    return parser.parse_args()", "def make_parsers():\n    parser = argparse.ArgumentParser()\n    subparsers = parser.add_subparsers(help='Subcommands')\n    build_parser(subparsers)\n    return parser, subparsers", "def make_parsers():\n    parser = argparse.ArgumentParser(description=\"Test the results of a test.\")\n    subparsers = parser.add_subparsers(dest=\"test_command\")\n    test_command_parser = subparsers.add_parser(\"test_command\")\n    test_command_parser.add_argument(\"--test_arg\", default=\"test_arg\", help=\"Test arg\")\n    return parser, subparsers\n", "def make_parsers():\n    parser = argparse.ArgumentParser()\n    subparsers = parser.add_subparsers()\n    add_common_parsers(subparsers)\n    return parser, subparsers", "def make_parsers():\n    parser = argparse.ArgumentParser(\n        description='Test a response from the Wikidata API.')\n    parser.add_argument('url', type=str,\n                        help='The URL of the Wikidata API.')\n    parser.add_argument('--verbose', '-v', action='store_true',\n                        help='Enable verbose output.')\n    parser.add_argument('--no-html', action='store_true',\n                        help='Do not generate HTML.')\n    return parser.parse_args()\n", "def make_parsers():\n    parser = argparse.ArgumentParser(\n        description='Install the given packages with pip')\n    subparsers = parser.add_subparsers(dest='command')\n    install_parser = subparsers.add_parser('install')\n    install_parser.add_argument(\n        'packages', nargs='*', default=None,\n        help='The packages to install. Defaults to all packages.')\n    install_parser.set_defaults(func=install)\n    return parser, subparsers\n", "def make_parsers():\n    parser = argparse.ArgumentParser(description='File validator')\n    parser.add_argument('--file', metavar='file', required=True, help='The file to validate')\n    return parser.parse_args()\n", "def make_parsers():\n    parser = argparse.ArgumentParser(description='Test the parser for the syslog server')\n    parser.add_argument('--host', default='localhost', help='Host name')\n    parser.add_argument('--port', default='8080', help='Port number')\n    parser.add_argument('--loglevel', default='INFO', help='Log level')\n    parser.add_argument('--timeout', default='30', help='Timeout in seconds')\n    return parser, parser.parse_args()\n", "def make_parsers():\n    parser = ArgumentParser(description='testing parser')\n    parser.add_argument('--foo', action='store_true', default=False)\n    return parser\n", "def make_parsers():\n    parser = argparse.ArgumentParser(description=__doc__)\n    parser.add_argument('--version', action='version',\n                        version='%(prog)s'+ __version__)\n    subparsers = parser.add_subparsers()\n    return parser, subparsers\n"]}
{"_id": "62b438ba66fea644fe22cca2", "generate_results": ["def deep_merge_nodes(nodes):\n    result = {}\n    for key, value in nodes.items():\n        if isinstance(value, MappingNode):\n            if value.has_key('$ref'):\n                result.setdefault(value['$ref'], []).append(key)\n            else:\n                result[key] = value\n        else:\n            result[key] = value\n    return result", "def deep_merge_nodes(nodes):\n    node_values = []\n    for node in nodes:\n        if isinstance(node, MappingNode):\n            node_values.extend(node.values())\n        else:\n            node_values.append(node)\n    return dict(reversed(node_values))\n", "def deep_merge_nodes(nodes):\n    result = []\n    for node in nodes:\n        if node is not None:\n            result.extend(_deep_merge_nodes(node))\n    return result", "def deep_merge_nodes(nodes):\n    result = []\n    for node in nodes:\n        if isinstance(node, MappingNode):\n            items = node.items()\n            keys = [key for key, _ in items]\n            if len(keys) > 1:\n                raise Exception(\"Deep merge node values for mapping node \"\n                                \"must be unique.\")\n            result.append(node.values()[keys[0]])\n        else:\n            result.append(node)\n    return result", "def deep_merge_nodes(nodes):\n    new_nodes = []\n    for node in nodes:\n        if isinstance(node, MappingNode):\n            new_nodes.extend(deep_merge_nodes(node.values()))\n        else:\n            new_nodes.append(node)\n    return new_nodes\n", "def deep_merge_nodes(nodes):\n    node_values = {}\n    for node in nodes:\n        node_values.update(node.values())\n\n    return node_values\n", "def deep_merge_nodes(nodes):\n    result = nodes.values()[0]\n    for key, value in nodes.items()[1:]:\n        if isinstance(value, MappingNode):\n            result = merge_nodes([result, deep_merge_nodes(value)])\n        else:\n            result = value\n    return result\n", "def deep_merge_nodes(nodes):\n    for k, v in nodes.items():\n        if isinstance(v, MappingNode):\n            v = deep_merge_nodes(v.values())\n        nodes[k] = v\n    return nodes", "def deep_merge_nodes(nodes):\n    result = []\n    for node in nodes:\n        if isinstance(node, MappingNode):\n            value = node.value\n            if value not in result:\n                result.append(value)\n        else:\n            result.append(node)\n    return result\n", "def deep_merge_nodes(nodes):\n    result = nodes[0]\n    for node in nodes[1:]:\n        if isinstance(node, MappingNode):\n            result.update(node)\n        else:\n            result = result.values()[-1]\n    return result\n"]}
{"_id": "62b438b666fea644fe22cc78", "generate_results": ["def parse_arguments(*arguments):\n\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--config\", dest=\"config\", help=\"Path to configuration file to use\")\n    parser.add_argument(\"--log\", dest=\"log\", help=\"Path to log file to use\")\n    return parser.parse_args(arguments)", "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser(description=__doc__, formatter_class=argparse.RawTextHelpFormatter)\n    parser.add_argument('-f', '--file', required=True, help='File to read from')\n    parser.add_argument('-d', '--directory', default='.', help='Directory to store the files in')\n    return parser.parse_args(*arguments)", "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--version', action='version', version='%(prog)s'+ __version__)\n    parser.add_argument('--output', default='-', help='output file (default: stdout)')\n    parser.add_argument('--no-color', action='store_true', help='do not color output')\n    parser.add_argument('--log-level', default='INFO', help='set log level (default: INFO)')\n    parser.add_argument('--log-format', default='%(message)s', help='set log format (default: %(message)s)')\n    return parser.parse_args(*arguments)\n", "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser(description='Run the script')\n\n    # Required arguments\n    parser.add_argument(\n        '--input_file',\n        dest='input_file',\n        type=str,\n        required=True,\n        help='Path to the input file')\n    parser.add_argument(\n        '--output_file',\n        dest='output_file',\n        type=str,\n        required=True,\n        help='Path to the output file')\n\n    return parser.parse_args(arguments)\n", "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--fname', help='The file to read from')\n    parser.add_argument('--output', help='The file to write to')\n    parser.add_argument('--separator', help='The separator to use',\n                        default='\\t')\n    parser.add_argument('--columns', help='The number of columns to output',\n                        default=None)\n    return parser.parse_args(*arguments)\n", "def parse_arguments(*arguments):\n\n    parser = argparse.ArgumentParser(description=\"\"\"\n    This script will run the given command line arguments and return the results\n    as an ArgumentParser instance.\n\n    \"\"\")\n\n    parser.add_argument(\"-d\", \"--directory\", help=\"\"\"\n    The path to the directory to use for the results files\n    \"\"\")\n\n    return parser.parse_args(arguments)\n", "def parse_arguments(*arguments):\n\n    parser = argparse.ArgumentParser(description=__doc__, formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n    parser.add_argument(\"--path\", type=str, default=None, help=\"Path to the simulation file\")\n    parser.add_argument(\"--time\", type=str, default=None, help=\"Time to run the simulation at\")\n    parser.add_argument(\"--number_time_steps\", type=int, default=10, help=\"Number of time steps to run the simulation\")\n    parser.add_argument(\"--number_steps\", type=int, default=10, help=\"Number of steps to run the simulation\")\n\n    return parser.parse_args(arguments)\n", "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser(description='Find the most important node in the graph')\n    parser.add_argument('--save_dir', type=str, default='./', help='Path to the directory where the data is saved')\n    parser.add_argument('--output_file', type=str, default='./', help='Path to the file where the nodes are saved')\n    parser.add_argument('--top_k', type=int, default=1, help='The top k nodes to output')\n    return parser.parse_args(arguments)\n", "def parse_arguments(*arguments):\n    parser = ArgumentParser(*arguments)\n    return parser.parse_args()", "def parse_arguments(*arguments):\n    parser = ArgumentParser(\n        description=\"Generate a hash of the passwords in the specified file\")\n    parser.add_argument('file', help='The file to hash')\n    return parser.parse_args(arguments)\n"]}
{"_id": "62b438b666fea644fe22cc72", "generate_results": ["def parser_flags(parser):\n    pass\n", "def parser_flags(parser):\n    return parser.parse_args()\n", "def parser_flags(parser):\n    \n    \n    pass", "def parser_flags(parser):\n    pass", "def parser_flags(parser):\n    pass\n", "def parser_flags(parser):\n    \n    \n    pass\n", "def parser_flags(parser):\n    return parser.parse_args()", "def parser_flags(parser):\n    pass\n", "def parser_flags(parser):\n    pass\n", "def parser_flags(parser):\n    \n    \n    return None\n"]}
{"_id": "62b438b566fea644fe22cc70", "generate_results": ["def bash_completion():\n    return [c for c in dir(argparse) if c.startswith('bash_')]\n", "def bash_completion():\n    parser = argparse.ArgumentParser(description=\"Borgmatic command-line interface\")\n    subparsers = parser.add_subparsers()\n    subparsers.required = True\n    subparsers.dest = \"bash_completion\"\n    bash_completion_subparser = subparsers.add_parser(\n        \"bash_completion\", help=\"A simple command-line interface that provides a basic \"\n        \"command-line interface for borgmatic to use with the command-line interface.\")\n    bash_completion_subparser.set_defaults(func=bash_completion)\n    return parser\n", "def bash_completion():\n    parser = argparse.ArgumentParser(\n        description='Analyze an exported Borgmatic project.')\n    subparsers = parser.add_subparsers(dest='command')\n    subparsers.required = True\n\n    for command in _commands:\n        parser = subparsers.add_parser(command.name,\n                                      help=command.help)\n        command.args = parser.parse_args()\n        command.args.func(command)\n", "def bash_completion():\n    return [c.dest for c in bash_commands()]\n", "def bash_completion():\n    parser = argparse.ArgumentParser(\n        prog=\"borgmatic\",\n        description=\"Command line interface to borgmatic tools.\")\n    parser.add_argument(\n        \"--log-level\", default=1,\n        help=\"Set log level (default: %(default)s).\")\n    return parser.parse_args()\n", "def bash_completion():\n    return ['borgmatic']", "def bash_completion():\n    # Produce the command line completion.\n    return ['borgmatic', '--help']\n", "def bash_completion():\n    \n    \n    return [\n        '--bash-completion',\n        '--bash-complete-with-args',\n        '--bash-complete-without-args',\n        '--bash-complete-with-no-args',\n        '--bash-complete-with-errors',\n        '--bash-complete-with-warnings',\n        '--bash-complete-with-unknown-arguments',\n    ]\n", "def bash_completion():\n    bash_completion = {}\n    for name, parser in bash_parser.items():\n        bash_completion[name] = parser.get_completer()\n    return bash_completion\n", "def bash_completion():\n    return ['borgmatic']\n"]}
{"_id": "62b438a266fea644fe22cc2e", "generate_results": ["def parse_arguments(*unparsed_arguments):\n    return unparsed_arguments", "def parse_arguments(*unparsed_arguments):\n    \n    \n    pass\n", "def parse_arguments(*unparsed_arguments):\n    \n    \n    pass\n", "def parse_arguments(*unparsed_arguments):\n    return unparsed_arguments\n", "def parse_arguments(*unparsed_arguments):\n    \n    \n    parser = argparse.ArgumentParser(description=\"Create a new manifest.\")\n    parser.add_argument('--output', required=True)\n    return parser.parse_args(unparsed_arguments)\n", "def parse_arguments(*unparsed_arguments):\n    \n    \n    pass\n", "def parse_arguments(*unparsed_arguments):\n    return None", "def parse_arguments(*unparsed_arguments):\n    return unparsed_arguments", "def parse_arguments(*unparsed_arguments):\n    return unparsed_arguments\n", "def parse_arguments(*unparsed_arguments):\n    return unparsed_arguments\n"]}
{"_id": "62b438a266fea644fe22cc2d", "generate_results": ["def parse_subparser_arguments(unparsed_arguments, subparsers):\n    pass\n", "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    \n    \n    pass\n", "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    \n    \n    pass\n", "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    return None", "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    pass", "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    pass\n", "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    pass", "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    pass\n", "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    pass\n", "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    pass\n"]}
{"_id": "62b438a266fea644fe22cc2c", "generate_results": ["def make_parsers():\n    return []\n", "def make_parsers():\n    return []", "def make_parsers():\n    return []\n", "def make_parsers():\n    return []\n", "def make_parsers():\n    return []\n", "def make_parsers():\n    return []", "def make_parsers():\n    return []\n", "def make_parsers():\n    return None", "def make_parsers():\n    return []\n", "def make_parsers():\n    return []"]}
{"_id": "62ece4982e6aefcf4aabbd5f", "generate_results": ["def paging(response, max_results):\n    for item in response:\n        yield item\n\n    while len(response) > max_results:\n        response = response[:max_results]\n\n        for item in response:\n            yield item", "def paging(response, max_results):\n    for response_json in response:\n        yield response_json\n        if len(response_json['results']) == max_results:\n            break\n", "def paging(response, max_results):\n    page = 0\n    while page <= max_results:\n        yield response[page:page + 1]\n        page += 1\n", "def paging(response, max_results):\n    for page in range(1, max_results + 1):\n        for response in response:\n            for result in response['results']:\n                yield result\n", "def paging(response, max_results):\n    if max_results > 0:\n        for page in range(1, max_results + 1):\n            yield response[page * MAX_PER_PAGE:page * MAX_PER_PAGE + MAX_PER_PAGE]\n        yield response[0:max_results]\n", "def paging(response, max_results):\n    while len(response) > max_results:\n        response = response[:max_results]\n        yield response\n", "def paging(response, max_results):\n    for response_page in response:\n        for response in response_page:\n            yield response\n\n        if len(response_page) > max_results:\n            break", "def paging(response, max_results):\n    for page in range(1, max_results + 1):\n        for result in response.json()['response']['docs']:\n            yield result\n", "def paging(response, max_results):\n    for item in response:\n        if item.get('length', 0) > max_results:\n            break\n        yield item", "def paging(response, max_results):\n    for page in range(1, max_results + 1):\n        for item in response:\n            yield item\n        if page == max_results:\n            break\n"]}
{"_id": "62ece4982e6aefcf4aabbd60", "generate_results": ["def size_to_bytes(size: str) -> int:\n    for unit in [\"\", \"K\", \"M\", \"G\", \"T\", \"P\"]:\n        if size.endswith(unit):\n            return int(float(size[:-len(unit)]))\n    raise ValueError(\"Unable to convert size '%s' to bytes\" % size)\n", "def size_to_bytes(size: str) -> int:\n    if size is None:\n        return 0\n    size = int(size)\n    for unit in ['B', 'KB', 'MB', 'GB']:\n        if size < 1024.0:\n            return size\n        size /= 1024.0\n    return size\n", "def size_to_bytes(size: str) -> int:\n    return size_to_units(size, 'B')\n", "def size_to_bytes(size: str) -> int:\n    return int(size.replace('B', ''))\n", "def size_to_bytes(size: str) -> int:\n    if size is None or size.lower() == 'null':\n        return None\n    if size.lower() == '0':\n        return 0\n    return int(size)\n", "def size_to_bytes(size: str) -> int:\n    unit = ('B', 'KB', 'MB', 'GB', 'TB')\n    for unit in unit:\n        if size.endswith(unit):\n            size = int(size.split(unit)[0])\n            break\n\n    if size < 1024:\n        return size\n\n    for i in range(1, 5):\n        size /= 1024.0\n        if size < 1024:\n            return size\n\n    return size", "def size_to_bytes(size: str) -> int:\n    try:\n        return int(size) * 1024\n    except ValueError:\n        raise ValueError(f\"Invalid file size: {size}\")", "def size_to_bytes(size: str) -> int:\n    for unit in ['', 'K', 'M', 'G', 'T', 'P', 'E', 'Z']:\n        if size < 1024.0:\n            return size\n        size /= 1024.0\n    return size", "def size_to_bytes(size: str) -> int:\n    size_map = {\n        'K': 1,\n        'M': 2,\n        'G': 3,\n        'T': 4,\n        'P': 5,\n        'E': 6\n    }\n\n    return int(float(size) * size_map[size.lower()])\n", "def size_to_bytes(size: str) -> int:\n    try:\n        return int(size)\n    except ValueError:\n        raise ValueError(f\"Invalid file size: {size}\")\n"]}
{"_id": "62ece4982e6aefcf4aabbd61", "generate_results": ["def _dictsum(dicts):\n    result = {}\n    for key, val in dicts.items():\n        result[key] = val\n    return result", "def _dictsum(dicts):\n\n    res = {}\n\n    for key, value in dicts.items():\n        res[key] = value\n\n    return res\n", "def _dictsum(dicts):\n    dic = {}\n    for key, value in dicts.items():\n        if key in dic:\n            dic[key] += value\n        else:\n            dic[key] = value\n    return dic\n", "def _dictsum(dicts):\n    return {k: v + dicts[k] for k, v in dicts.items()}\n", "def _dictsum(dicts):\n    dic = {}\n    for key, value in dicts.items():\n        dic[key] = sum(value.values())\n    return dic", "def _dictsum(dicts):\n    dict = dicts[0]\n    for i in range(1, len(dicts)):\n        dict = dict + dicts[i]\n    return dict", "def _dictsum(dicts):\n    return {key: sum(vals) for key, vals in dicts.items()}\n", "def _dictsum(dicts):\n    return {key: sum(values) for key, values in dicts.items()}\n", "def _dictsum(dicts):\n    dic = dicts[0]\n    for dict_ in dicts[1:]:\n        dic = _dictsum(dic, dict_)\n    return dic\n", "def _dictsum(dicts):\n    new_dict = {}\n    for dict_key, dict_value in dicts.items():\n        new_dict[dict_key] = dict_value + new_dict.get(dict_key, 0)\n    return new_dict\n"]}
{"_id": "62ece4982e6aefcf4aabbd62", "generate_results": ["def _replace_url_args(url, url_args):\n    return url.format(**url_args)\n", "def _replace_url_args(url, url_args):\n    for key, value in url_args.iteritems():\n        if value:\n            url = url.replace('%s=%s' % (key, value), url_args[key])\n    return url\n", "def _replace_url_args(url, url_args):\n    if url_args:\n        for key, value in url_args.items():\n            url = url.replace(\"{%s}\" % key, value)\n    return url\n", "def _replace_url_args(url, url_args):\n    if url_args:\n        for key, value in url_args.items():\n            url = url.replace('{{{0}}}'.format(key), value)\n    return url", "def _replace_url_args(url, url_args):\n    url_args = url_args or {}\n    for k, v in url_args.items():\n        if v:\n            url = url.replace('%s=%s' % (k, v), '%s=%s' % (k, v))\n    return url\n", "def _replace_url_args(url, url_args):\n    if url_args:\n        for key, value in url_args.iteritems():\n            if value is not None:\n                url = url.replace('{' + key + '}', value)\n    return url\n", "def _replace_url_args(url, url_args):\n    for (k, v) in url_args.items():\n        url = url.replace('{' + k + '}', v)\n    return url\n", "def _replace_url_args(url, url_args):\n    if url_args:\n        for k, v in url_args.items():\n            url = url.replace('{{' + k + '}}', v)\n    return url\n", "def _replace_url_args(url, url_args):\n    for key, value in url_args.items():\n        if value:\n            url = url.replace('{' + key + '}', value)\n    return url\n", "def _replace_url_args(url, url_args):\n    if url_args:\n        for key, value in url_args.items():\n            url = url.replace('{' + key + '}', value)\n    return url\n"]}
{"_id": "62ece4982e6aefcf4aabbd63", "generate_results": ["def is_none_string(val: str) -> bool:\n    if val is None:\n        return True\n    return is_string(val) and val.lower() == \"none\"\n", "def is_none_string(val: Any) -> bool:\n    return isinstance(val, str) and val.lower() == 'none'\n", "def is_none_string(val: str) -> bool:\n    return is_string(val) and val.lower() == 'none'\n", "def is_none_string(val: str) -> bool:\n    return is_string(val) and val.lower() == \"none\"\n", "def is_none_string(val: str) -> bool:\n    return (type(val) == str and val.lower() == 'none')\n", "def is_none_string(val: Any) -> bool:\n    return (\n        isinstance(val, str)\n        and val.lower() == \"none\"\n        and val!= \"none\"\n    )\n", "def is_none_string(val: Optional[str]) -> bool:\n    return is_string(val) and val.lower() == \"none\"\n", "def is_none_string(val: str) -> bool:\n    return isinstance(val, str) and val.lower() == 'none'\n", "def is_none_string(val: str) -> bool:\n    return is_string(val) and val.lower() == 'none'\n", "def is_none_string(val: AnyStr) -> bool:\n    return (isinstance(val, str) and val.lower() == 'none')\n"]}
{"_id": "62ece4982e6aefcf4aabbd64", "generate_results": ["def strip_root(path, root):\n    if root == \"/\":\n        return path\n    else:\n        if root == path:\n            return path\n        else:\n            return path.rsplit(root, 1)[0]\n", "def strip_root(path, root):\n    if not root:\n        return path\n\n    if path.startswith(root):\n        return path[len(root):]\n\n    return path\n", "def strip_root(path, root):\n    if path == root:\n        return path\n    else:\n        return path[len(root):]\n", "def strip_root(path, root):\n    if not path:\n        return path\n\n    if root and path.startswith(root):\n        return path[len(root):]\n\n    return path\n", "def strip_root(path, root):\n    if root == path:\n        return path\n    if path == '/':\n        return ''\n    if path.startswith(root + '/'):\n        return path[len(root):]\n    raise ValueError('Root %s not found in path %s' % (root, path))\n", "def strip_root(path, root):\n    if root in path:\n        return path.replace(root, '')\n    return path\n", "def strip_root(path, root):\n    return path.split(root)[0]", "def strip_root(path, root):\n    if not os.path.isabs(path):\n        raise Exception(\"Path not absolute: {}\".format(path))\n    if path == root:\n        return os.path.normpath(path)\n    else:\n        return os.path.normpath(os.path.join(path, root))\n", "def strip_root(path, root):\n    if path == root:\n        return path\n    if path.startswith(root):\n        return path[len(root):]\n    return path\n", "def strip_root(path, root):\n    if not path.startswith(root):\n        raise Exception(\"%s does not start with root %s\" % (path, root))\n    return path[len(root):]\n"]}
{"_id": "62ece4982e6aefcf4aabbd65", "generate_results": ["def parser_flags(parser):\n    return''.join(parser._flags)\n", "def parser_flags(parser):\n    flags = ''\n    for arg in parser._actions:\n        if arg.dest == '--flags':\n            flags = flags +'' + arg.dest\n            break\n    return flags\n", "def parser_flags(parser):\n    return''.join(['--' + flag for flag in parser._actions])\n", "def parser_flags(parser):\n    flags = []\n    for flag in parser._actions:\n        if isinstance(flag, argparse._StoreAction):\n            flags.append(flag.dest)\n        elif isinstance(flag, argparse._StoreFlag):\n            flags.append(flag.dest)\n        else:\n            flags.append(flag.dest)\n    return \" \".join(flags)\n", "def parser_flags(parser):\n    return''.join(f.name for f in parser._actions)\n", "def parser_flags(parser):\n    return''.join(parser._actions)\n", "def parser_flags(parser):\n    flags = []\n    for arg in parser._actions:\n        if hasattr(arg, 'dest'):\n            flags.append('--' + arg.dest.replace('_', '-'))\n        else:\n            flags.append(arg.default)\n    return''.join(flags)\n", "def parser_flags(parser):\n    return''.join(flag for flag in parser._get_args())\n", "def parser_flags(parser):\n    return''.join(parser._actions)\n", "def parser_flags(parser):\n    return \" \".join([str(f) for f in parser._actions])\n"]}
{"_id": "62ece4982e6aefcf4aabbd66", "generate_results": ["def was_processed(processed, path_name, verbose):\n    if path_name in processed:\n        return True\n\n    processed.add(path_name)\n    if verbose:\n        print(\"Adding {} to processed set\".format(path_name))\n    return False\n", "def was_processed(processed, path_name, verbose):\n    if path_name in processed:\n        if verbose:\n            print('[!] {} already processed'.format(path_name))\n        return True\n    processed.add(path_name)\n    return False\n", "def was_processed(processed, path_name, verbose):\n    if verbose:\n        print('Checking if {} already processed in {}.'.format(path_name, processed))\n    return path_name in processed\n", "def was_processed(processed, path_name, verbose):\n    if path_name in processed:\n        if verbose:\n            print(\"Skipping {}, already processed\".format(path_name))\n        return True\n    processed.add(path_name)\n    return False\n", "def was_processed(processed, path_name, verbose):\n    if path_name in processed:\n        return True\n    else:\n        processed.add(path_name)\n        return False\n", "def was_processed(processed, path_name, verbose):\n    if path_name in processed:\n        return True\n    else:\n        processed.add(path_name)\n        if verbose:\n            print('Added pathname:'+ path_name)\n        return False\n", "def was_processed(processed, path_name, verbose):\n    if verbose:\n        print(\"checking for {} in the set\".format(path_name))\n    if path_name in processed:\n        return True\n    processed.add(path_name)\n    return False\n", "def was_processed(processed, path_name, verbose):\n    if path_name in processed:\n        return True\n\n    processed.add(path_name)\n    if verbose:\n        print(\"adding {} to processed set\".format(path_name))\n\n    return False\n", "def was_processed(processed, path_name, verbose):\n    if path_name in processed:\n        return True\n    processed.add(path_name)\n    if verbose:\n        print('        {} is already in the set'.format(path_name))\n    return False\n", "def was_processed(processed, path_name, verbose):\n    if path_name in processed:\n        return True\n    processed.add(path_name)\n    if verbose:\n        print(\"Processed {}\".format(path_name))\n    return False\n"]}
{"_id": "62ece4982e6aefcf4aabbd67", "generate_results": ["def vertex3tuple(vertices):\n    vertices = [(0, 0), (0, 1), (1, 0), (1, 1)]\n    vertices = [(v[0], v[1]) for v in vertices]\n    return vertices\n", "def vertex3tuple(vertices):\n    vertices = np.array(vertices)\n    vertices = vertices.astype(np.int)\n    return [vertices[0], vertices[2], vertices[1]]\n", "def vertex3tuple(vertices):\n    vertices = np.array(vertices)\n    vertices[vertices < 0] = 0\n    vertices[vertices >= len(vertices)] = len(vertices)\n    return [vertices[0], vertices[1], vertices[2]]\n", "def vertex3tuple(vertices):\n    return [(vertices[0][i], vertices[1][i], vertices[2][i]) for i in range(3)]\n", "def vertex3tuple(vertices):\n    return [vertices[0], vertices[1], vertices[2]]\n", "def vertex3tuple(vertices):\n    return [(vertices[0][i], vertices[1][i], vertices[2][i]) for i in range(3)]\n", "def vertex3tuple(vertices):\n    return [tuple(v[i] for v in vertices) for i in (0, 1, 2)]\n", "def vertex3tuple(vertices):\n    return [vertices[0], vertices[2], vertices[1]]\n", "def vertex3tuple(vertices):\n    return [(vertices[i], vertices[i + 1]) for i in range(0, len(vertices), 2)]\n", "def vertex3tuple(vertices):\n    return [vertices[0], vertices[1], vertices[2]]\n"]}
{"_id": "62ece4982e6aefcf4aabbd68", "generate_results": ["def int_to_string(number: int, alphabet: List[str], padding: Optional[int] = None) -> str:\n    result = \"\"\n    while number:\n        result = alphabet[number % len(alphabet)] + result\n        number //= len(alphabet)\n    if padding:\n        result = result[:-padding]\n    return result\n", "def int_to_string(number: int, alphabet: List[str], padding=0) -> str:\n    digits = []\n    while number:\n        digits.append(alphabet[number % len(alphabet)])\n        number //= len(alphabet)\n    digits.reverse()\n    return \"\".join(digits) + str(padding)\n", "def int_to_string(number: int, alphabet: List[str], padding=0) -> str:\n    return \"\".join([alphabet[number % len(alphabet)] for _ in range(padding)])\n", "def int_to_string(number: int, alphabet: list, padding: int = 0) -> str:\n    return \"\".join([alphabet[number % len(alphabet)] for number in range(padding)])\n", "def int_to_string(number: int, alphabet: List[str], padding: int = 0) -> str:\n    return str(number).zfill(padding)\n", "def int_to_string(number: int, alphabet: List[str], padding: Optional[int] = None) -> str:\n    if number < 0:\n        raise ValueError(\"Invalid input number\")\n\n    result = str(number)\n    while number > 0:\n        result = alphabet[result[-1]] + result[:-1]\n        number = number // len(alphabet)\n\n    if padding is not None:\n        result = result[-padding:] + \"0\" * (padding - len(result))\n\n    return result\n", "def int_to_string(number: int, alphabet: List[str], padding: int = 0) -> str:\n    return ''.join([alphabet[int(n) % len(alphabet)] for n in str(number)]) + str(padding)\n", "def int_to_string(number: int, alphabet: List[str], padding: int = 0) -> str:\n    if padding > 0:\n        alphabet = alphabet[:-padding]\n    return \"\".join([alphabet[int(number % len(alphabet))]] + alphabet[int(number / len(alphabet)):])", "def int_to_string(number: int, alphabet: List[str], padding: int = 0) -> str:\n    return ''.join([alphabet[int((number >> (8 * i)) & 0xff)] for i in range(padding, -1, -1)])\n", "def int_to_string(number: int, alphabet: str = string.ascii_letters, padding=0) -> str:\n    if padding > 0:\n        alphabet = alphabet + ('0' * padding)\n    return alphabet[number % len(alphabet)]\n"]}
{"_id": "62ece4982e6aefcf4aabbd69", "generate_results": ["def _replace_register(flow_params, register_number, register_value):\n    \n    \n    del flow_params[register_number]\n    del flow_params[register_value]\n", "def _replace_register(flow_params, register_number, register_value):\n    if register_number in flow_params:\n        flow_params[register_number] = flow_params[register_number]\n        del flow_params[register_value]\n        return True\n    return False\n", "def _replace_register(flow_params, register_number, register_value):\n    if register_number in flow_params:\n        flow_params[register_number] = flow_params[register_number]\n        del flow_params[register_value]\n", "def _replace_register(flow_params, register_number, register_value):\n    if register_value in flow_params:\n        flow_params[register_value] = flow_params[register_number]\n        del flow_params[register_number]\n", "def _replace_register(flow_params, register_number, register_value):\n    if register_value in flow_params:\n        flow_params[register_number] = flow_params[register_value]\n        del flow_params[register_value]\n", "def _replace_register(flow_params, register_number, register_value):\n    if register_number in flow_params:\n        flow_params[register_number] = flow_params[register_value]\n        del flow_params[register_value]\n", "def _replace_register(flow_params, register_number, register_value):\n    if register_value in flow_params:\n        flow_params[register_number] = flow_params[register_value]\n        del flow_params[register_value]\n", "def _replace_register(flow_params, register_number, register_value):\n    if register_number in flow_params:\n        flow_params[register_number] = flow_params[register_number].replace(flow_params[register_value], '')\n        del flow_params[register_value]\n", "def _replace_register(flow_params, register_number, register_value):\n    \n    \n    flow_params[register_number] = flow_params[register_value]\n    del flow_params[register_value]\n    return flow_params\n", "def _replace_register(flow_params, register_number, register_value):\n    del flow_params[register_number]\n    flow_params[register_value] = flow_params[register_number]\n    del flow_params[register_number]\n"]}
{"_id": "62ece4982e6aefcf4aabbd6a", "generate_results": ["def replace_dots(value, arg):\n    return value.replace('.', arg)\n", "def replace_dots(value, arg):\n    return value.replace('.', arg)\n", "def replace_dots(value, arg):\n    return re.sub('\\.', arg, value)\n", "def replace_dots(value, arg):\n    return value.replace('.', arg)\n", "def replace_dots(value, arg):\n    return re.sub(r'\\.{2,}', arg, value)\n", "def replace_dots(value, arg):\n    return value.replace('.', arg)\n", "def replace_dots(value, arg):\n    return value.replace('.', arg)\n", "def replace_dots(value, arg):\n    return value.replace('.', arg)", "def replace_dots(value, arg):\n    return value.replace('.', arg)\n", "def replace_dots(value, arg):\n    return value.replace('.', arg)\n"]}
{"_id": "62ece4982e6aefcf4aabbd6b", "generate_results": ["def subclasses(cls):\n    \n    \n    if not issubclass(cls, object):\n        return []\n\n    return [cls] + [subclasses(cls) for c in cls.__subclasses__()]\n", "def subclasses(cls):\n    return cls.__subclasses__() + [g for s in cls.__subclasses__() for g in subclasses(s)]\n", "def subclasses(cls):\n    return cls.__subclasses__() + [g for s in cls.__subclasses__() for g in subclasses(s)]\n", "def subclasses(cls):\n    \n    \n    if not issubclass(cls, type):\n        raise TypeError(\"Can only call subclasses() on classes\")\n    return cls.__subclasses__() + [g for s in cls.__subclasses__() for g in subclasses(s)]", "def subclasses(cls):\n    return [subclass for subclass in cls.__subclasses__() if not subclass.__name__.startswith('_')]\n", "def subclasses(cls):\n    return cls.__subclasses__() + [g for s in cls.__subclasses__() for g in subclasses(s)]\n", "def subclasses(cls):\n    \n    \n    return cls.__subclasses__() + [g for s in cls.__subclasses__() for g in subclasses(s)]", "def subclasses(cls):\n    return cls.__subclasses__() + [g for s in cls.__subclasses__() for g in subclasses(s)]\n", "def subclasses(cls):\n    return [s for s in cls.__subclasses__() if not s.__bases__ == (object,)]\n", "def subclasses(cls):\n    return cls.__subclasses__() + [g for s in cls.__subclasses__() for g in subclasses(s)]\n"]}
{"_id": "62ece4982e6aefcf4aabbd6d", "generate_results": ["def string_to_int(string: str, alphabet: List[str]) -> int:\n    return sum([alphabet.index(letter) * (ALPHABET_SIZE ** i)\n                for i, letter in enumerate(string)])\n", "def string_to_int(string: str, alphabet: List[str]) -> int:\n    return sum((alphabet.index(letter) for letter in string))\n", "def string_to_int(string: str, alphabet: List[str]) -> int:\n    if not string:\n        return 0\n\n    if not string.isalpha():\n        raise ValueError(\"string must be a string of letters\")\n\n    if string.isupper():\n        return string_to_int(string.lower(), alphabet) * (len(string) - 1)\n\n    return sum((alphabet.index(c) + 1) * (string.count(c) + 1) for c in string)\n", "def string_to_int(string: str, alphabet: List[str]) -> int:\n    return sum((alphabet.index(letter) for letter in string))\n", "def string_to_int(string: str, alphabet: List[str]) -> int:\n    return sum(1 for _ in itertools.takewhile(lambda x: x in alphabet, string))\n", "def string_to_int(string: str, alphabet: List[str]) -> int:\n    num = 0\n    for letter in string:\n        if letter in alphabet:\n            num = num * len(alphabet) + alphabet.index(letter)\n        else:\n            raise ValueError(\"The character '{}' is not in the alphabet of the input string.\".format(letter))\n    return num\n", "def string_to_int(string: str, alphabet: list) -> int:\n    return sum((alphabet.index(letter) for letter in string))\n", "def string_to_int(string: str, alphabet: list) -> int:\n    # return sum([alphabet.index(letter) for letter in string])\n    return sum([alphabet.index(letter) for letter in string])\n", "def string_to_int(string: str, alphabet: List[str]) -> int:\n    if not string:\n        return 0\n    result = 0\n    for i, c in enumerate(string):\n        result += alphabet.index(c) * (26**i)\n    return result\n", "def string_to_int(string: str, alphabet: list) -> int:\n    return sum([alphabet.index(letter) for letter in string])\n"]}
{"_id": "62ece4982e6aefcf4aabbd6f", "generate_results": ["def get_repo_archive(url: str, destination_path: str) -> str:\n    try:\n        response = requests.get(url, stream=True)\n        response.raise_for_status()\n        tarball = tarfile.open(fileobj=response.raw)\n        tarball.extractall(destination_path)\n        return destination_path\n    except Exception as e:\n        print(e)\n        raise e\n", "def get_repo_archive(url: str, destination_path: str):\n    archive_path = get_archive_path(url, destination_path)\n    if os.path.exists(archive_path):\n        return archive_path\n\n    tar = tarfile.open(archive_path)\n    tar.extractall(path=destination_path)\n    tar.close()\n    return archive_path\n", "def get_repo_archive(url: str, destination_path: str) -> str:\n    return urllib.request.urlretrieve(url, destination_path)[0]", "def get_repo_archive(url: str, destination_path: str) -> str:\n    with urllib.request.urlopen(url) as response, open(destination_path, 'wb') as out_file:\n        shutil.copyfileobj(response, out_file)\n\n    return destination_path\n", "def get_repo_archive(url: str, destination_path: str) -> str:\n    # TODO Implement this function\n    return None\n", "def get_repo_archive(url: str, destination_path: str):\n    response = requests.get(url, stream=True)\n    with tarfile.open(fileobj=BytesIO(response.content)) as tar:\n        tar.extractall(destination_path)\n    return destination_path\n", "def get_repo_archive(url: str, destination_path: str) -> str:\n    response = requests.get(url)\n    with open(destination_path, \"wb\") as f:\n        f.write(response.content)\n    return destination_path", "def get_repo_archive(url: str, destination_path: str) -> str:\n    r = requests.get(url)\n    with open(destination_path, \"wb\") as f:\n        f.write(r.content)\n    tar = tarfile.open(destination_path)\n    tar.extractall(path=destination_path)\n    return destination_path\n", "def get_repo_archive(url: str, destination_path: str) -> str:\n    # TODO: add a way to specify the format of the archive file\n    urlretrieve(url, destination_path)\n    return destination_path\n", "def get_repo_archive(url: str, destination_path: str) -> str:\n    print(\"Downloading tarball for {}\".format(url))\n    response = requests.get(url, stream=True)\n    with tarfile.open(fileobj=io.BytesIO(response.content)) as tar:\n        tar.extractall(destination_path)\n    return destination_path\n"]}
{"_id": "62ece4982e6aefcf4aabbd70", "generate_results": ["def os_is_mac():\n    return sys.platform.startswith(\"darwin\")\n", "def os_is_mac():\n    return platform.system() == \"Darwin\"\n", "def os_is_mac():\n    return sys.platform == 'darwin'\n", "def os_is_mac():\n    return platform.system() == 'Darwin'", "def os_is_mac():\n    return sys.platform.startswith('darwin')\n", "def os_is_mac():\n    return platform.system() == \"Darwin\"\n", "def os_is_mac():\n    return platform.system() == \"Darwin\"\n", "def os_is_mac():\n    return sys.platform.startswith('darwin')\n", "def os_is_mac():\n    return platform.system() == 'Darwin'\n", "def os_is_mac():\n    return sys.platform.startswith(\"darwin\")\n"]}
{"_id": "62ece4982e6aefcf4aabbd71", "generate_results": ["def regex_dict(item):\n    return {\n        key: re.compile(value) if isinstance(value, str) else value\n        for key, value in item.items()\n    }\n", "def regex_dict(item):\n    for k, v in item.items():\n        if k.endswith(\".cpp\"):\n            item[k] = re.compile(v)\n\n    return item\n", "def regex_dict(item):\n    return {\n        key: re.compile(key + '$') if key!='src_filename' else key\n        for key in item\n    }\n", "def regex_dict(item):\n    item = dict(item)\n    for key, value in item.items():\n        if key.endswith('.cpp'):\n            item[key] = re.compile(value)\n    return item\n", "def regex_dict(item):\n    return dict((k, re.compile(v)) for k, v in item.items())", "def regex_dict(item):\n    for key, value in item.items():\n        if key.endswith('.cpp') and not key.endswith('.h'):\n            item[key] = regex_from_cpp(key, value)\n    return item\n", "def regex_dict(item):\n    return {k: regex_key(k) for k in item}\n", "def regex_dict(item):\n    return {k: re.compile(v) for k, v in item.items()}\n", "def regex_dict(item):\n    return {k: re.sub(r'\\.cpp\\$', '_', k) for k in item}\n", "def regex_dict(item):\n    for k in item:\n        if k.endswith('.cpp'):\n            item[k] = re.compile(item[k])\n    return item\n"]}
{"_id": "62ece4982e6aefcf4aabbd72", "generate_results": ["def unquote(name):\n    if not name:\n        return None\n    return name.replace('\"', '')\n", "def unquote(name):\n    if name[0] == '\"' and name[-1] == '\"':\n        return name[1:-1]\n    return name\n", "def unquote(name):\n    return re.sub(r\"'(.*)'\", r\"\\1\", name)\n", "def unquote(name):\n    return _QUOTES.sub('', name)\n", "def unquote(name):\n    return re.sub(r'[^a-zA-Z0-9]', '', name)", "def unquote(name):\n    return _QUOTES.sub(\"\", name)", "def unquote(name):\n    return re.sub(r\"\\'(.*?)\\'\", r\"\\1\", name)", "def unquote(name):\n    if not name:\n        return None\n    return re.sub(r'\\\"|\\'', '', name)\n", "def unquote(name):\n    return re.sub(r'(\\\"|\\')', '', name)\n", "def unquote(name):\n    return re.sub(r'\"([^\"]+)\"|(\\'([^\\']+)\\')', r'\\1', name)\n"]}
{"_id": "62ece4982e6aefcf4aabbd73", "generate_results": ["def split(s, platform='this'):\n    if platform == 'this':\n        return s.split(';')\n    elif platform == '1':\n        return s.split(':')\n    elif platform == '0':\n        return s.split(';')\n", "def split(s, platform='this'):\n    if platform == 'this':\n        if os.name == 'nt':\n            return s.split('\\\\')\n        else:\n            return s.split('/')\n    else:\n        if os.name == 'nt':\n            return s.split('/')\n        else:\n            return s.split('\\\\')\n", "def split(s, platform='this'):\n    if platform == 'this':\n        return s.split(' ')\n    elif platform == 1:\n        return s.split(':')\n    elif platform == 0:\n        return ['', '']\n    else:\n        raise ValueError('Invalid platform: %s' % platform)\n", "def split(s, platform='this'):\n    if platform == 'this':\n        return s.split('/')\n    elif platform == 1:\n        return s.split(':')\n    elif platform == 0:\n        return s.split('\\\\')\n    else:\n        raise ValueError('Unknown platform %d' % platform)\n", "def split(s, platform='this'):\n    if platform == 'this':\n        return s.split(' ')\n    elif platform == 'POSIX':\n        return s.split(';')\n    elif platform == 'windows':\n        return s.split(' ')\n    elif platform == 'cmd':\n        return s.split(' ')\n    else:\n        raise ValueError(\"Unknown platform '%s'\" % platform)", "def split(s, platform='this'):\n    if platform == 'this':\n        platform = os.name\n    if platform == 'posix':\n        return s.split('\\\\')\n    elif platform == 'windows':\n        return s.split('/')\n    else:\n        return []\n", "def split(s, platform='this'):\n    if platform == 'this':\n        return s.split(' ')\n    elif platform == 1:\n        return s.split(';')\n    elif platform == 0:\n        return s.split(':')\n    else:\n        raise ValueError('Unsupported platform')\n", "def split(s, platform='this'):\n    if platform == 'this':\n        platform = get_platform()\n    return s.split(platform)\n", "def split(s, platform='this'):\n    if platform == 'this':\n        platform = os.name\n    if platform == 'posix':\n        return s.split(' ')\n    elif platform == 0:\n        return s.split('\\n')\n    else:\n        return s.split('\\t')\n", "def split(s, platform='this'):\n    if platform == 'this':\n        return s.split(' ')\n    elif platform == 1:\n        return [s]\n    elif platform == 0:\n        return [s.replace('\\\\', '/')]\n    else:\n        return [s.replace('\\\\', '/')]\n"]}
{"_id": "62ece4982e6aefcf4aabbd74", "generate_results": ["def prepare_repository_from_archive(\n    archive_path: str, filename: str, tmp_path: str\n) -> str:\n    return _prepare_repository(\n        archive_path, filename, archive_path, tmp_path, filename\n    )\n", "def prepare_repository_from_archive(\n    archive_path: Path, filename: str, tmp_path: Path\n) -> str:\n    with tarfile.open(archive_path) as archive:\n        archive.extractall(tmp_path)\n    return f\"{tmp_path}/{filename}\"", "def prepare_repository_from_archive(\n    archive_path: str, filename: str, tmp_path: str\n) -> str:\n    assert os.path.exists(archive_path)\n    return prepare_repository(\n        archive_path, filename, tmp_path, extract=True\n    )\n", "def prepare_repository_from_archive(\n    archive_path: Path, filename: str, tmp_path: Path, *, repo_name: str\n) -> str:\n    uncompressed_path = archive_path / filename\n    with open(uncompressed_path, \"rb\") as f:\n        return prepare_repository_from_file(f, tmp_path, repo_name)\n", "def prepare_repository_from_archive(\n    archive_path: str, filename: str, tmp_path: str\n) -> str:\n    repo_url = _prepare_repository_from_archive(\n        archive_path, filename, tmp_path, \"\"\n    )\n    return repo_url\n", "def prepare_repository_from_archive(\n    archive_path: str,\n    filename: str,\n    tmp_path: str,\n) -> str:\n    if not os.path.exists(archive_path):\n        raise ValueError('archive does not exist')\n\n    return _prepare_repository(archive_path, filename, tmp_path)\n", "def prepare_repository_from_archive(\n    archive_path: str, filename: str, tmp_path: str\n) -> str:\n    uncompress_path = uncompress_file(archive_path, tmp_path)\n    repo_url = get_repo_url(uncompress_path)\n    return repo_url", "def prepare_repository_from_archive(\n    archive_path: str, filename: str, tmp_path: str\n) -> str:\n    return uncompress(archive_path, filename, tmp_path)\n", "def prepare_repository_from_archive(\n    archive_path: str, filename: str, tmp_path: str\n) -> str:\n    archive = ZipFile(archive_path)\n    archive.extractall(tmp_path)\n    return archive_url_from_file(archive_path, filename, tmp_path)\n", "def prepare_repository_from_archive(\n    archive_path: Path, filename: str, tmp_path: Path\n) -> str:\n    # Always use the same path as the file\n    file_path = archive_path / filename\n    return prepare_repository_from_file(file_path, tmp_path)"]}
{"_id": "62ece4982e6aefcf4aabbd75", "generate_results": ["def addignored(ignored):\n    files = []\n    for file in ignored:\n        files.append(file[1])\n    files.sort()\n    return \", \".join(files)", "def addignored(ignored):\n\n    files = subprocess.check_output([\"git\", \"ls-files\", \"--ignored\"]).splitlines()\n    files = [f.decode(\"utf-8\") for f in files]\n    ignored = [f for f in ignored if f not in files]\n    files.sort()\n    return \", \".join(files)", "def addignored(ignored):\n    output = subprocess.check_output([\"git\", \"ls-files\"])\n    ignored = [x.strip() for x in output.split('\\n') if x.strip() not in ignored]\n    return \",\".join(sorted(ignored))\n", "def addignored(ignored):\n    ignored = sorted(ignored)\n    ignored = [\"- \" + item for item in ignored]\n    return \"\\n\".join(ignored)", "def addignored(ignored):\n    cmd = ['git', 'ls-files']\n    output = subprocess.check_output(cmd)\n    files = output.decode().split('\\n')\n    ignored_files = []\n    for file in files:\n        if ignored in file:\n            ignored_files.append(file)\n    return ', '.join(ignored_files)", "def addignored(ignored):\n    files = []\n    for f in ignored:\n        files.append(f)\n    files.sort()\n    return ','.join(files)\n", "def addignored(ignored):\n\n    if len(ignored) == 0:\n        return \"\"\n\n    ret = \"\"\n    for i in range(0, len(ignored)):\n        if ignored[i] in IGNORED:\n            ret += ignored[i] + \",\"\n        else:\n            ret += ignored[i]\n    return ret", "def addignored(ignored):\n    files = []\n    for filename in ignored:\n        files.append(os.path.basename(filename))\n    files.sort()\n    return \"\\n\".join(files)", "def addignored(ignored):\n    # define the command to be used\n    command = \"git ls-files -z --ignore-submodules --others\"\n\n    # run the command and return the result\n    return subprocess.check_output(command, shell=True).decode('utf-8').split('\\n')", "def addignored(ignored):\n    filenames = []\n    for item in ignored:\n        filenames.append('\"' + item + '\"')\n    filenames.sort()\n    return ','.join(filenames)\n"]}
{"_id": "62ece4982e6aefcf4aabbd76", "generate_results": ["def match(filename):\n    return filename.lower().endswith('.doxyfile')\n", "def match(filename):\n    return filename.lower().endswith('.doxyfile')\n", "def match(filename):\n    return filename.lower().endswith(\".doxyfile\")\n", "def match(filename):\n    return filename.lower().endswith('.doxyfile')\n", "def match(filename):\n    return filename.lower().endswith(\".doxyfile\")\n", "def match(filename):\n    return filename.lower().endswith('.doxyfile')\n", "def match(filename):\n    return filename.lower().endswith(\".doxy\")\n", "def match(filename):\n    return filename.lower().endswith('.doxyfile')", "def match(filename):\n    return filename.lower().endswith('.doxyfile')\n", "def match(filename):\n    return filename.lower().endswith('.doxyfile')\n"]}
{"_id": "62ece4982e6aefcf4aabbd77", "generate_results": ["def parse_frequency(frequency):\n    if frequency in FREQUENCY_MAP:\n        return FREQUENCY_MAP[frequency]\n    else:\n        raise ValueError(\"Invalid frequency: %s\" % frequency)\n", "def parse_frequency(frequency):\n    if frequency in [\"always\", \"always-off\"]:\n        return None\n    if frequency in [\"number\", \"number-off\"]:\n        return datetime.timedelta(seconds=1)\n    if frequency in [\"unit\", \"unit-off\"]:\n        return datetime.timedelta(seconds=1 * timeunit_to_timedelta(frequency))\n    raise ValueError(\"Frequency %s is not a valid frequency\" % frequency)", "def parse_frequency(frequency):\n    if frequency is None:\n        return None\n    if frequency.lower() in (\"always\", \"never\"):\n        return None\n    try:\n        return timedelta(**{_unit_map[frequency.lower()]: None})\n    except KeyError:\n        raise ValueError(\"Invalid frequency: {}\".format(frequency))\n", "def parse_frequency(frequency):\n    if frequency in [\"always\", \"never\"]:\n        return None\n    try:\n        return _parse_timedelta(frequency)\n    except ValueError:\n        raise ValueError(\"Invalid frequency '{}'\".format(frequency))\n", "def parse_frequency(frequency):\n    if frequency is None:\n        return None\n    if frequency == \"always\":\n        return None\n    match = _FREQUENCY_RE.match(frequency)\n    if not match:\n        raise ValueError(\"Unable to parse frequency: %r\" % frequency)\n    groups = match.groupdict()\n    unit = groups[\"unit\"]\n    return timedelta(**{unit: int(groups[\"timeunit\"])})\n", "def parse_frequency(frequency):\n    if not frequency:\n        return None\n    if frequency in (\"always\", \"once\"):\n        return timedelta(seconds=1)\n    if frequency in (\"never\", \"no\"):\n        return timedelta(seconds=0)\n    raise ValueError(\"Invalid frequency: %s\" % frequency)\n", "def parse_frequency(frequency):\n    if frequency is None:\n        return None\n    elif frequency == \"always\":\n        return datetime.timedelta(hours=3)\n    else:\n        try:\n            return parse_timeunit(frequency)\n        except ValueError:\n            raise ValueError(\"Invalid frequency '%s'\" % frequency)", "def parse_frequency(frequency):\n    if frequency == \"always\":\n        return None\n    try:\n        return datetime.timedelta(**{freq: int(frequency[:-1]) for freq in frequency.split(\" \")})\n    except ValueError:\n        raise ValueError(\"Unrecognized frequency: \" + frequency)\n", "def parse_frequency(frequency):\n    if not frequency:\n        return None\n    if frequency[0] == \"n\":\n        return timedelta(seconds=None)\n    if frequency[0] == \"u\":\n        return timedelta(microseconds=None)\n    return timedelta(seconds=timeunit_to_timedelta(frequency[0]))\n", "def parse_frequency(frequency):\n    if frequency == \"always\":\n        return None\n    else:\n        return timedelta(seconds=int(frequency))\n"]}
{"_id": "62ece4992e6aefcf4aabbd78", "generate_results": ["def is_local(host):\n    return host.lower() in ['localhost', '127.0.0.1', 'localhost']\n", "def is_local(host):\n    return host == \"127.0.0.1\" or host == \"localhost\"\n", "def is_local(host):\n    if host is None:\n        return False\n    return host == '127.0.0.1' or host.endswith('.local') or host.endswith('.localhost')\n", "def is_local(host):\n    return host == '127.0.0.1' or host.startswith('localhost')\n", "def is_local(host):\n    if host == \"127.0.0.1\":\n        return True\n\n    if host.startswith(\"localhost\"):\n        return True\n\n    if host.startswith(\"localhost\"):\n        return False\n\n    return host == \"127.0.0.1\"\n", "def is_local(host):\n    if host == '127.0.0.1':\n        return True\n    else:\n        return False", "def is_local(host):\n    return host == '127.0.0.1' or host == 'localhost'\n", "def is_local(host):\n    return host == '127.0.0.1' or host == 'localhost' or host == 'localhost.localdomain'\n", "def is_local(host):\n    if host == '127.0.0.1':\n        return True\n    if host.startswith('localhost'):\n        return True\n    if host.startswith('127.0.0.1'):\n        return False\n    if host.startswith('localhost') or host.startswith('127.0.0.1'):\n        return True\n    return False\n", "def is_local(host):\n    return host in ['127.0.0.1', 'localhost', 'localhost.localdomain']\n"]}
{"_id": "62ece4992e6aefcf4aabbd79", "generate_results": ["def make_find_paths(find_paths):\n    return tuple(make_find_path(path) for path in find_paths)\n", "def make_find_paths(find_paths):\n    return tuple(\n        (glob(p) for p in find_paths if (p is not None) and (not isfile(p))))\n", "def make_find_paths(find_paths):\n    patterns = []\n    for path in find_paths:\n        for pattern in path_to_glob(path):\n            patterns.append(pattern)\n    return tuple(patterns)\n", "def make_find_paths(find_paths):\n  return tuple(make_glob_paths(find_path) for find_path in find_paths)\n", "def make_find_paths(find_paths):\n    return tuple(\n        glob.glob(path)\n        for path in find_paths\n    )\n", "def make_find_paths(find_paths):\n    return tuple(make_glob_paths(find_path) for find_path in find_paths)\n", "def make_find_paths(find_paths):\n  return tuple(make_find_path(path) for path in find_paths)\n", "def make_find_paths(find_paths):\n  return tuple(make_find_path(path) for path in find_paths)\n", "def make_find_paths(find_paths):\n    for path in find_paths:\n        if is_glob(path):\n            yield glob.glob(path)\n        else:\n            yield path\n", "def make_find_paths(find_paths):\n    return tuple([make_find_path(p) for p in find_paths])\n"]}
{"_id": "62ece4992e6aefcf4aabbd7a", "generate_results": ["def is_gitbash():\n\n    return 'git' in sys.platform\n", "def is_gitbash():\n    return platform.system() == \"Windows\"", "def is_gitbash():\n    return os.name == \"nt\"\n", "def is_gitbash():\n    return os.getenv(\"GIT_TERMINAL\") == \"gitbash\"", "def is_gitbash():\n    return os.name == 'nt'\n", "def is_gitbash():\n    return sys.platform == 'win32' and \\\n        os.environ.get('GITBASH_PATH', None) and \\\n        os.environ.get('GITBASH_PATH').endswith('.git')\n", "def is_gitbash():\n    return sys.platform == 'win32' and os.environ.get('GITBASH')\n", "def is_gitbash():\n    return is_windows() and 'gitbash' in os.environ\n", "def is_gitbash():\n    return os.environ.get('GITBASH') is not None\n", "def is_gitbash():\n    return os.name == 'nt' and '.gitbash' in os.listdir('.')\n"]}
{"_id": "62ece4992e6aefcf4aabbd7b", "generate_results": ["def write_configuration(config_filename, rendered_config, mode=0o600, overwrite=False):\n    if not overwrite:\n        return\n\n    if os.path.exists(config_filename):\n        if not overwrite and os.path.isfile(config_filename):\n            log.error('%s already exists', config_filename)\n            return\n\n    with open(config_filename, mode) as config_file:\n        config_file.write(rendered_config)\n", "def write_configuration(config_filename, rendered_config, mode=0o600, overwrite=False):\n    if overwrite is False:\n        abort(\"Overwrite is False. Aborting.\")\n\n    if os.path.exists(config_filename):\n        abort(\"File already exists. Aborting.\")\n\n    with open(config_filename, mode) as config_file:\n        config_file.write(rendered_config)\n\n    if os.path.exists(config_filename) is False:\n        abort(\"File was not created. Aborting.\")", "def write_configuration(config_filename, rendered_config, mode=0o600, overwrite=False):\n\n    if not os.path.exists(config_filename):\n        if not overwrite:\n            return\n        with open(config_filename, \"w\") as f:\n            f.write(rendered_config)\n\n    else:\n        if not overwrite:\n            return\n        with open(config_filename, \"r\") as f:\n            content = yaml.load(f, Loader=yaml.FullLoader)\n            content.update(rendered_config)", "def write_configuration(config_filename, rendered_config, mode=0o600, overwrite=False):\n    if os.path.exists(config_filename) and not overwrite:\n        abort('Configuration file already exists. Abort.')\n    with open(config_filename, 'w') as f:\n        f.write(rendered_config)\n", "def write_configuration(config_filename, rendered_config, mode=0o600, overwrite=False):\n    if not os.path.exists(config_filename):\n        if not overwrite:\n            click.echo('Configuration file \"{}\" does not exist. Skipping.'.format(config_filename))\n            return\n        else:\n            click.echo('Creating new configuration file \"{}\"'.format(config_filename))\n            os.makedirs(os.path.dirname(config_filename), mode=mode)\n    with open(config_filename, 'w') as f:\n        f.write(rendered_config)\n", "def write_configuration(config_filename, rendered_config, mode=0o600, overwrite=False):\n    if not overwrite and os.path.isfile(config_filename):\n        abort('file {} already exists'.format(config_filename))\n    with open(config_filename, mode) as f:\n        f.write(rendered_config)\n", "def write_configuration(config_filename, rendered_config, mode=0o600, overwrite=False):\n    if not os.path.exists(config_filename) or overwrite:\n        with open(config_filename, mode) as f:\n            f.write(rendered_config)\n    else:\n        raise ConfigurationException(\"Configuration file already exists\")\n", "def write_configuration(config_filename, rendered_config, mode=0o600, overwrite=False):\n    if not os.path.isfile(config_filename) or overwrite:\n        with open(config_filename, mode) as outfile:\n            yaml.safe_dump(rendered_config, outfile)\n            outfile.flush()\n    else:\n        log.error('Configuration file already exists')\n", "def write_configuration(config_filename, rendered_config, mode=0o600, overwrite=False):\n    if overwrite:\n        if os.path.isfile(config_filename):\n            os.remove(config_filename)\n        with open(config_filename, mode) as config_file:\n            config_file.write(rendered_config)\n    else:\n        with open(config_filename, mode) as config_file:\n            config_file.write(rendered_config)", "def write_configuration(config_filename, rendered_config, mode=0o600, overwrite=False):\n    if overwrite or not os.path.exists(config_filename):\n        with open(config_filename, mode) as f:\n            f.write(rendered_config)\n    else:\n        raise RuntimeError(\"Configuration already exists: %s\" % config_filename)\n"]}
{"_id": "62ece4992e6aefcf4aabbd7c", "generate_results": ["def oneline(script, seperator=\" && \"):\n    return seperator.join(script.split(\"\\n\"))\n", "def oneline(script, seperator=\" && \"):\n  return seperator.join(script.splitlines())\n", "def oneline(script, seperator=\" && \"):\n  return seperator.join(script.splitlines())\n", "def oneline(script, seperator=\" && \"):\n    return seperator.join(script.split(\"\\n\"))\n", "def oneline(script, seperator=\" && \"):\n  return seperator.join(script.split(\"\\n\"))\n", "def oneline(script, seperator=\" && \"):\n    return \"\\n\".join(script.split(seperator))", "def oneline(script, seperator=\" && \"):\n    return seperator.join(script.split(\"\\n\"))", "def oneline(script, seperator=\" && \"):\n  return seperator.join(script.splitlines())", "def oneline(script, seperator=\" && \"):\n  return seperator.join(script.split(\"\\n\"))\n", "def oneline(script, seperator=\" && \"):\n  return seperator.join(script.splitlines())\n"]}
{"_id": "62ece4992e6aefcf4aabbd7d", "generate_results": ["def subprocess_run_helper(func, *args, timeout, extra_env=None):\n    with tempfile.NamedTemporaryFile() as f:\n        if extra_env is not None:\n            os.environ.update(extra_env)\n        subprocess.run(\n            args,\n            stdout=f,\n            stderr=subprocess.PIPE,\n            env=os.environ,\n            timeout=timeout,\n        )\n    return CompletedProcess(f.name)\n", "def subprocess_run_helper(func, *args, timeout, extra_env=None):\n    env = os.environ.copy()\n    if extra_env is not None:\n        env.update(extra_env)\n\n    return subprocess.run(\n        [str(func)] + list(args), stdout=subprocess.PIPE, env=env, timeout=timeout\n    )\n", "def subprocess_run_helper(func, *args, timeout, extra_env=None):\n    p = subprocess.run(\n        [sys.executable, func.__module__, *args, timeout],\n        env=extra_env,\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE,\n    )\n    return p\n", "def subprocess_run_helper(func, *args, timeout, extra_env=None):\n    return subprocess.run(\n        ['python', func.__module__, *args],\n        stdout=subprocess.PIPE,\n        stderr=subprocess.STDOUT,\n        env=extra_env or {},\n        timeout=timeout\n    )\n", "def subprocess_run_helper(func, *args, timeout, extra_env=None):\n    env = os.environ.copy()\n    env.update(extra_env or {})\n    proc = subprocess.run(\n        args, stdout=subprocess.PIPE, stderr=subprocess.PIPE, env=env, timeout=timeout\n    )\n    return proc\n", "def subprocess_run_helper(func, *args, timeout, extra_env=None):\n    if extra_env is None:\n        extra_env = {}\n    return subprocess_run(\n        func,\n        *args,\n        timeout=timeout,\n        env=extra_env,\n    )\n", "def subprocess_run_helper(func, *args, timeout, extra_env=None):\n    return subprocess_run(\n        func, *args, timeout=timeout, env=extra_env, stdout=subprocess.PIPE\n    )\n", "def subprocess_run_helper(func, *args, timeout, extra_env=None):\n    args = [sys.executable, '-m','subprocess'] + list(args)\n    if extra_env is not None:\n        args.extend(extra_env)\n    return subprocess.run(args, timeout=timeout, stdout=subprocess.PIPE,\n                          stderr=subprocess.PIPE, env=os.environ.copy())\n", "def subprocess_run_helper(func, *args, timeout, extra_env=None):\n    return subprocess_run(\n        func,\n        *args,\n        timeout=timeout,\n        extra_env=extra_env,\n    )\n", "def subprocess_run_helper(func, *args, timeout, extra_env=None):\n    env = {} if extra_env is None else extra_env\n    with tempfile.TemporaryDirectory() as tmpdir:\n        tmpdir = pathlib.Path(tmpdir)\n        tmpdir.mkdir(parents=True, exist_ok=True)\n        command = [str(tmpdir)] + list(args)\n        return subprocess_run_helper_helper(command, timeout, env)"]}
{"_id": "62ece4992e6aefcf4aabbd7e", "generate_results": ["def _resolve_string(matcher):\n    var_name = matcher.group('name')\n    if var_name not in os.environ:\n        raise Error('Variable %s not defined in environment' % var_name)\n    var_val = os.environ[var_name]\n    if var_val == '':\n        raise Error('Variable %s is empty' % var_name)\n    return var_val\n", "def _resolve_string(matcher):\n    name = matcher.group('name')\n    default = matcher.group('default')\n    if default is None:\n        raise ValueError('No default value provided')\n    return os.environ[name]\n", "def _resolve_string(matcher):\n    try:\n        return os.environ[matcher.name]\n    except KeyError:\n        try:\n            return matcher.groupdict()[matcher.group(matcher.name)]\n        except KeyError:\n            raise Error(\"Undefined environment variable %s\" % matcher.name)\n", "def _resolve_string(matcher):\n    env_name = matcher.group(1)\n    default = matcher.group(2)\n    try:\n        return os.environ[env_name]\n    except KeyError:\n        if default is None:\n            raise Error('Environment variable \"{}\" is not defined'.format(env_name))\n        return default\n", "def _resolve_string(matcher):\n    env_name = matcher.group('name')\n    env_value = os.environ.get(env_name, None)\n    if env_value is None:\n        raise ValueError('Environment variable %s not defined' % env_name)\n    return env_value\n", "def _resolve_string(matcher):\n    name, default = matcher.groupdict().popitem()\n    try:\n        value = os.environ[name]\n    except KeyError:\n        if default is not None:\n            return default\n        raise Error(\"Undefined variable '{}'\".format(name))\n    return _resolve_string_list(matcher, value)\n", "def _resolve_string(matcher):\n    match = matcher.groupdict()\n    if match['name'] in os.environ:\n        return os.environ[match['name']]\n    if match['default'] is None:\n        raise ValueError(\"Environment variable %s not defined\" % match['name'])\n    return match['default']", "def _resolve_string(matcher):\n    name = matcher.group(1)\n    if name in os.environ:\n        return os.environ[name]\n    elif name in _defaults:\n        return _defaults[name]\n    else:\n        raise Error(\"Undefined variable {!r}\".format(name))\n", "def _resolve_string(matcher):\n    name, default = matcher.groupdict()\n    try:\n        value = os.environ[name]\n    except KeyError:\n        if default is None:\n            raise Error('Missing environment variable %s' % name)\n        value = default\n    return value\n", "def _resolve_string(matcher):\n    value = os.environ.get(matcher.group(\"name\"), matcher.group(\"default\"))\n    if value == \"\":\n        raise ValueError(\"Environment variable '%s' is not set\" % matcher.group(\"name\"))\n    return value"]}
{"_id": "62ece4992e6aefcf4aabbd7f", "generate_results": ["def _parse_image_ref(image_href: str) -> Tuple[str, str, bool]:\n    match = _IMAGE_REF_REGEX.match(image_href)\n    if not match:\n        raise ValueError(\"Invalid image reference: %s\" % image_href)\n    netloc = match.group(\"netloc\")\n    use_ssl = match.group(\"use_ssl\")\n    image_id = match.group(\"image_id\")\n    return image_id, netloc, use_ssl\n", "def _parse_image_ref(image_href: str) -> Tuple[str, str, bool]:\n    image_id = _image_id_from_href(image_href)\n    netloc = _netloc_from_href(image_href)\n    use_ssl = _use_ssl_from_href(image_href)\n    return image_id, netloc, use_ssl\n", "def _parse_image_ref(image_href: str) -> Tuple[str, str, bool]:\n    if not image_href:\n        raise ValueError(\"Image href is empty\")\n    image_url = urlparse(image_href)\n    return (image_url.path.split(\"/\")[-1], image_url.netloc, image_url.use_ssl)\n", "def _parse_image_ref(image_href: str) -> Tuple[str, str, bool]:\n    image_href = image_href.strip('/')\n    image_id = image_href.split('/')[-1]\n    netloc = urllib.parse.urlparse(image_href).netloc\n    use_ssl = image_href.startswith('https://')\n    return image_id, netloc, use_ssl\n", "def _parse_image_ref(image_href: str) -> Tuple[str, str, bool]:\n    image_parts = urlparse(image_href)\n    if image_parts.scheme!= \"https\":\n        raise ValueError(\"Unsupported scheme for image reference: %s\" % image_href)\n    return image_parts.netloc, image_parts.path.lstrip(\"/\"), image_parts.query\n", "def _parse_image_ref(image_href: str) -> Tuple[str, str, bool]:\n    if image_href.startswith('/'):\n        image_href = image_href[1:]\n    path = urllib.parse.urlparse(image_href).path\n    if not path:\n        raise ValueError('Image href %s is not valid' % image_href)\n    netloc = urllib.parse.urlparse(image_href).netloc\n    use_ssl = False\n    return path, netloc, use_ssl\n", "def _parse_image_ref(image_href: str) -> Tuple[str, str, bool]:\n    image_id = image_href.split('/')[-1]\n    netloc = urllib.parse.urlparse(image_href).netloc\n    use_ssl = False\n    if'ssl' in image_href:\n        use_ssl = True\n    return image_id, netloc, use_ssl\n", "def _parse_image_ref(image_href: str) -> Tuple[str, str, bool]:\n    image_id = image_href.split(\"/\")[-1]\n    netloc = urlparse(image_href).netloc\n    use_ssl = False\n\n    if image_href.startswith(\"https://\"):\n        use_ssl = True\n        image_href = image_href.replace(\"https://\", \"\")\n\n    return image_id, netloc, use_ssl\n", "def _parse_image_ref(image_href: str) -> Tuple[str, str, bool]:\n    if '://' not in image_href:\n        raise ValueError('Image href is not a valid URL: {}'.format(image_href))\n\n    image_id, netloc = image_href.rsplit('/', 1)\n\n    use_ssl = False\n\n    return image_id, netloc, use_ssl\n", "def _parse_image_ref(image_href: str) -> Tuple[str, str, bool]:\n    parsed = urlparse(image_href)\n    if not parsed.netloc:\n        raise ValueError('Image reference must be an image reference '\n                         'without netloc.')\n    image_id = parsed.path.split('/')[-1]\n    netloc = parsed.netloc\n    use_ssl = False if parsed.scheme == 'https' else True\n    return image_id, netloc, use_ssl\n"]}
{"_id": "62ece4992e6aefcf4aabbd80", "generate_results": ["def remove_ending_os_sep(input_list):\n    if input_list is None:\n        return []\n    if len(input_list) <= 1:\n        return input_list\n    return [input_list[0]] + remove_ending_os_sep(input_list[1:])", "def remove_ending_os_sep(input_list):\n    if input_list is None:\n        return []\n    if len(input_list) == 0:\n        return []\n    if len(input_list[-1]) > 1 and input_list[-1][-1] == '\\\\':\n        input_list.pop()\n    return input_list", "def remove_ending_os_sep(input_list):\n    if input_list is None:\n        return []\n    if len(input_list) <= 1:\n        return input_list\n    return [item[:-1] if item[-1]!= os.sep else item for item in input_list]\n", "def remove_ending_os_sep(input_list):\n    if input_list is None:\n        return []\n    if not isinstance(input_list, list):\n        raise TypeError('Input list is not a list')\n    if len(input_list) == 0:\n        return []\n    if len(input_list) == 1:\n        return input_list\n    return [input_list[0]] + remove_ending_os_sep(input_list[1:])\n", "def remove_ending_os_sep(input_list):\n    if input_list is None:\n        return []\n    if len(input_list) <= 1:\n        return input_list\n    return [input_list[0]] + remove_ending_os_sep(input_list[1:])\n", "def remove_ending_os_sep(input_list):\n    if input_list is None:\n        return []\n\n    if len(input_list) > 0:\n        return [input_list[0]] + remove_ending_os_sep(input_list[1:])\n\n    return []\n", "def remove_ending_os_sep(input_list):\n    if input_list is None:\n        return []\n\n    if len(input_list) == 0:\n        return input_list\n\n    return [input_list[0]] + remove_ending_os_sep(input_list[1:])\n", "def remove_ending_os_sep(input_list):\n    if input_list is None:\n        return []\n    if len(input_list) == 0:\n        return []\n    if len(input_list) == 1:\n        return [input_list[0]]\n    return [input_list[0]] + remove_ending_os_sep(input_list[1:])\n", "def remove_ending_os_sep(input_list):\n    if input_list is None:\n        return []\n    else:\n        return [item.rstrip('\\\\/') for item in input_list]\n", "def remove_ending_os_sep(input_list):\n    if input_list is None:\n        return []\n\n    if len(input_list) > 0:\n        return input_list[:-1]\n    else:\n        return []\n"]}
{"_id": "62ece4992e6aefcf4aabbd82", "generate_results": ["def get_pattern(pattern, strip=True):\n    if isinstance(pattern, str):\n        pattern = re.compile(pattern)\n\n    if strip:\n        return pattern.strip()\n    else:\n        return pattern", "def get_pattern(pattern, strip=True):\n    if isinstance(pattern, str):\n        pattern = re.compile(pattern)\n    if strip:\n        return pattern.strip()\n    return pattern\n", "def get_pattern(pattern, strip=True):\n    if isinstance(pattern, basestring):\n        pattern = re.compile(pattern)\n    elif isinstance(pattern, re._pattern_type):\n        pass\n    else:\n        raise ValueError('%s is not a valid pattern' % pattern)\n    if strip:\n        return pattern.strip()\n    else:\n        return pattern\n", "def get_pattern(pattern, strip=True):\n    if isinstance(pattern, basestring):\n        pattern = re.compile(pattern, re.I)\n    if strip:\n        return re.compile(pattern.strip())\n    return re.compile(pattern)\n", "def get_pattern(pattern, strip=True):\n    if isinstance(pattern, str):\n        pattern = re.compile(pattern)\n    elif isinstance(pattern, re._pattern_type):\n        pass\n    else:\n        raise TypeError('input must be string or re._pattern_type')\n    if strip:\n        pattern = re.sub('^(?!\\s)', '', pattern)\n        pattern = re.sub('\\s+', '', pattern)\n    return pattern\n", "def get_pattern(pattern, strip=True):\n    return re.compile(pattern, re.DOTALL if strip else re.UNICODE)\n", "def get_pattern(pattern, strip=True):\n    return re.compile(pattern, re.MULTILINE if strip else re.DOTALL)\n", "def get_pattern(pattern, strip=True):\n    if isinstance(pattern, str):\n        pattern = re.compile(pattern, re.I)\n    if strip:\n        pattern = pattern.strip()\n    return pattern\n", "def get_pattern(pattern, strip=True):\n    if isinstance(pattern, str):\n        pattern = re.compile(pattern)\n    elif not isinstance(pattern, re._pattern_type):\n        raise ValueError(\"Expected str or regex pattern object\")\n    if strip:\n        pattern = pattern.strip()\n    return pattern\n", "def get_pattern(pattern, strip=True):\n    if isinstance(pattern, str):\n        pattern = re.compile(pattern)\n    if strip:\n        return pattern.strip(\" \\t\\n\\r\")\n    return pattern"]}
{"_id": "62ece4992e6aefcf4aabbd83", "generate_results": ["def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    return run_commands(commands, args, cwd, verbose, hide_stderr, env)[0]", "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    process = subprocess.Popen(\n        commands,\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE,\n        cwd=cwd,\n        env=env,\n        close_fds=True,\n        verbose=verbose,\n        shell=False,\n        args=args,\n    )\n    stdout, stderr = process.communicate()\n    return stdout, process.returncode\n", "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    result = []\n    for cmd in commands:\n        result.append(subprocess.run(cmd, args, cwd, verbose, hide_stderr, env))\n    return result[0].stdout, result[0].returncode\n", "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    if not isinstance(commands, list):\n        commands = [commands]\n    return subprocess.run(\n        commands,\n        stdout=subprocess.PIPE,\n        stderr=subprocess.STDOUT,\n        check=True,\n        cwd=cwd,\n        shell=False,\n        env=env,\n        universal_newlines=True,\n        verbose=verbose,\n        hide_stderr=hide_stderr,\n    ).stdout,\n", "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    if env is None:\n        env = os.environ.copy()\n    env['PATH'] = os.pathsep.join([os.path.abspath(os.path.dirname(__file__)), env['PATH']])\n    proc = subprocess.Popen(commands, stdout=subprocess.PIPE, stderr=subprocess.PIPE, cwd=cwd, env=env)\n    stdout, stderr = proc.communicate()\n    return stdout, proc.returncode", "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    return subprocess.run(commands, args, cwd=cwd, check=False, shell=True, env=env, check_returncode=True, verbose=verbose, hide_stderr=hide_stderr)", "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    result = None\n    try:\n        result = subprocess.run(\n            commands, stdout=subprocess.PIPE, stderr=subprocess.PIPE, cwd=cwd, env=env, check=False, args=args\n        )\n    except subprocess.CalledProcessError as e:\n        if verbose:\n            print(\" \".join(e.cmd))\n            print(\" \".join(e.output))\n            print(e.returncode)\n    return result\n", "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    if isinstance(commands, basestring):\n        commands = [commands]\n    result = subprocess.run(commands, stdout=subprocess.PIPE, stderr=subprocess.PIPE, check=False, cwd=cwd, env=env)\n    if verbose:\n        print(result.stdout.decode('utf-8'))\n        print(result.stderr.decode('utf-8'))\n    return result.stdout.decode('utf-8'), result.returncode\n", "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    p = subprocess.Popen(\n        commands, stdout=subprocess.PIPE, stderr=subprocess.PIPE, cwd=cwd, env=env\n    )\n    out, err = p.communicate(input=args)\n    if p.returncode!= 0:\n        raise RuntimeError(\n            \"Command '{}' returned non-zero exit status {}\".format(\n               ''.join(commands), p.returncode\n            )\n        )\n    if verbose:\n        print(out)\n    return out, p.returncode\n", "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    results = []\n    for command in commands:\n        result = run_command_with_env(command, args, cwd, verbose, hide_stderr, env)\n        results.append(result)\n    return results\n"]}
{"_id": "62ece4992e6aefcf4aabbd84", "generate_results": ["def is_ipv4(target):\n    return is_ipv4_address(target) or is_ipv6_address(target)\n", "def is_ipv4(target):\n    try:\n        socket.inet_pton(socket.AF_INET, target)\n    except (AttributeError, socket.error):\n        return False\n    return True\n", "def is_ipv4(target):\n    return is_ipv4_target(target) or is_ipv6_target(target)\n", "def is_ipv4(target):\n    try:\n        socket.inet_aton(target)\n        return True\n    except socket.error:\n        return False\n", "def is_ipv4(target):\n    try:\n        ipaddress.IPv4Address(target)\n        return True\n    except ValueError:\n        return False\n", "def is_ipv4(target):\n    try:\n        return (\n            isinstance(target, str)\n            and len(target) == 4\n            and target[0] == '.'\n            and target[1] == '.'\n            and target[2] == '.'\n            and target[3] == '.'\n        )\n    except TypeError:\n        return False\n", "def is_ipv4(target):\n    try:\n        return netaddr.valid_ipv4(target)\n    except Exception:\n        return False\n", "def is_ipv4(target):\n    try:\n        socket.inet_pton(socket.AF_INET, target)\n    except socket.error:\n        return False\n    return True\n", "def is_ipv4(target):\n    return is_ip(target) and ':' in target\n", "def is_ipv4(target):\n    try:\n        socket.inet_aton(target)\n        return True\n    except socket.error:\n        return False\n"]}
{"_id": "62ece4992e6aefcf4aabbd85", "generate_results": ["def find_roots(\n    graph: Graph,\n    prop: URIRef,\n    roots: Optional[List[URIRef]] = None,\n) -> Set[URIRef]:\n    if roots is None:\n        roots = set()\n    if prop not in graph:\n        return roots\n    for sub in graph[prop]:\n        roots.update(find_roots(graph, sub))\n    return roots\n", "def find_roots(\n    graph: Graph,\n    prop: URIRef,\n    roots: Optional[List[URIRef]] = None,\n) -> Set[URIRef]:\n    if roots is None:\n        roots = set()\n\n    if prop in graph:\n        roots.update(graph[prop])\n\n    for child in graph[prop].values():\n        find_roots(child, roots)\n\n    return roots\n", "def find_roots(\n    graph: Graph,\n    prop: URIRef,\n    roots: Optional[Set[URIRef]] = None,\n) -> Set[URIRef]:\n    if roots is None:\n        roots = set()\n    for triple in graph.objects(prop, RDFS.subClassOf):\n        if triple.subject is None:\n            continue\n        roots.add(triple.subject)\n    return roots\n", "def find_roots(\n    graph: Graph, prop: URIRef, roots: Optional[List[URIRef]] = None\n) -> Set[URIRef]:\n    if roots is None:\n        roots = set()\n    for subclass in graph.objects(prop, RDFS.subClassOf):\n        roots.update(find_roots(graph, subclass))\n    return roots\n", "def find_roots(\n    graph: Graph, prop: URIRef, roots: Optional[List[URIRef]] = None\n) -> Set[URIRef]:\n    if roots is None:\n        roots = set()\n\n    for cls in graph.objects(prop, RDFS.subClassOf):\n        roots = roots.union(find_roots(graph, cls, roots))\n\n    return roots\n", "def find_roots(\n    graph: Graph, prop: URIRef, roots: Optional[List[URIRef]] = None\n) -> Set[URIRef]:\n    if not roots:\n        roots = set()\n\n    for child in graph.objects(prop, RDFS.subClassOf):\n        roots.update(find_roots(graph, child, roots))\n\n    return roots\n", "def find_roots(\n    graph: Graph,\n    prop: URIRef,\n    roots: Optional[List[Set[URIRef]]] = None,\n) -> Set[URIRef]:\n    if roots is None:\n        roots = set()\n\n    for sub in graph.objects(prop, RDFS.subClassOf):\n        roots = roots.union(find_roots(graph, sub))\n\n    return roots\n", "def find_roots(\n    graph: Graph, prop: URIRef, roots: Optional[List[URIRef]] = None\n) -> Optional[Set[URIRef]]:\n    if not roots:\n        roots = set([])\n    for c, p, o in graph.triples(\n        (prop, RDFS.subClassOf, None)\n    ):\n        roots.add(o)\n        find_roots(graph, p, roots)\n    return roots\n", "def find_roots(\n    graph: Graph,\n    prop: URIRef,\n    roots: Optional[List[URIRef]] = None,\n) -> Set[URIRef]:\n    if roots is None:\n        roots = set()\n    for sub in graph.objects(prop, RDFS.subClassOf):\n        roots.add(sub)\n        roots |= find_roots(graph, sub, roots)\n    return roots\n", "def find_roots(\n    graph: Graph, prop: URIRef, roots: Optional[Set[URIRef]] = None\n) -> Set[URIRef]:\n    if not roots:\n        roots = set()\n    for cls in graph.objects(prop, SKOS.broader):\n        roots.add(cls)\n        find_roots(graph, cls, roots)\n    return roots\n"]}
{"_id": "62ece4992e6aefcf4aabbd86", "generate_results": ["def _dump_string(obj, dumper=None):\n    return dumper.represent_scalar(u'tag:yaml.org,2002:str', str(obj))\n", "def _dump_string(obj, dumper=None):\n    return dumper.represent_scalar(\"tag:yaml.org,2002:str\", obj, style=\"|\")\n", "def _dump_string(obj, dumper=None):\n    return dumper or yaml.Dumper\n", "def _dump_string(obj, dumper=None):\n    return dumper.represent_scalar('tag:yaml.org,2002:str', str(obj))\n", "def _dump_string(obj, dumper=None):\n    if not dumper:\n        dumper = yaml.SafeDumper\n\n    return yaml.dump(obj, Dumper=dumper)\n", "def _dump_string(obj, dumper=None):\n    if not dumper:\n        dumper = yaml.SafeDumper\n\n    return dumper.dump(obj)\n", "def _dump_string(obj, dumper=None):\n    return dumper.dump(obj).strip() if dumper else yaml.dump(obj)\n", "def _dump_string(obj, dumper=None):\n    return dumper.represent_scalar('tag:yaml.org,2002:str', str(obj))\n", "def _dump_string(obj, dumper=None):\n    return dumper.represent_scalar(u'tag:yaml.org,2002:str', u'')\n", "def _dump_string(obj, dumper=None):\n    return dumper.dump(obj)\n"]}
{"_id": "62ece4992e6aefcf4aabbd87", "generate_results": ["def build_app_logger(name='app', logfile='app.log', debug=True):\n    logging.basicConfig(level=logging.INFO)\n    logger = logging.getLogger(name)\n    logger.setLevel(logging.INFO)\n    handler = logging.FileHandler(logfile)\n    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n    handler.setFormatter(formatter)\n    logger.addHandler(handler)\n    if debug:\n        logger.setLevel(logging.DEBUG)\n    return logger", "def build_app_logger(name='app', logfile='app.log', debug=True):\n    logger = logging.getLogger(name)\n    logger.setLevel(logging.INFO)\n\n    if debug:\n        logger.setLevel(logging.DEBUG)\n    else:\n        logger.setLevel(logging.INFO)\n\n    fh = logging.FileHandler(logfile)\n    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n    fh.setFormatter(formatter)\n\n    logger.addHandler(fh)\n\n    return logger", "def build_app_logger(name='app', logfile='app.log', debug=True):\n    logger = logging.getLogger(name)\n    logger.setLevel(logging.INFO)\n    handler = logging.FileHandler(logfile, mode='w')\n    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n    handler.setFormatter(formatter)\n    logger.addHandler(handler)\n    if debug:\n        logger.setLevel(logging.DEBUG)\n    return logger", "def build_app_logger(name='app', logfile='app.log', debug=True):\n\n    logging.basicConfig(level=logging.DEBUG if debug else logging.INFO,\n                        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n                        filename=logfile,\n                        filemode='w')\n\n    logger = logging.getLogger(name)\n    logger.setLevel(logging.DEBUG)\n\n    return logger\n", "def build_app_logger(name='app', logfile='app.log', debug=True):\n\n    logger = logging.getLogger(name)\n    logger.setLevel(logging.INFO)\n    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n\n    file_handler = logging.FileHandler(logfile)\n    file_handler.setLevel(logging.DEBUG)\n    file_handler.setFormatter(formatter)\n\n    logger.addHandler(file_handler)\n\n    if debug:\n        logger.setLevel(logging.DEBUG)\n\n    return logger\n", "def build_app_logger(name='app', logfile='app.log', debug=True):\n    logger = logging.getLogger(name)\n    handler = logging.FileHandler(logfile)\n    formatter = logging.Formatter(\n        '%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n    handler.setFormatter(formatter)\n    logger.addHandler(handler)\n    logger.setLevel(logging.INFO)\n    if debug:\n        logger.setLevel(logging.DEBUG)\n    return logger\n", "def build_app_logger(name='app', logfile='app.log', debug=True):\n    logger = logging.getLogger(name)\n    logger.setLevel(logging.DEBUG if debug else logging.INFO)\n    handler = logging.FileHandler(logfile)\n    handler.setFormatter(logging.Formatter(\n        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'))\n    logger.addHandler(handler)\n    return logger\n", "def build_app_logger(name='app', logfile='app.log', debug=True):\n\n    logger = logging.getLogger(name)\n    logger.setLevel(logging.DEBUG if debug else logging.INFO)\n    handler = logging.FileHandler(logfile)\n    handler.setFormatter(logging.Formatter(\n        '%(asctime)s %(name)s %(levelname)s %(message)s'))\n    logger.addHandler(handler)\n    return logger", "def build_app_logger(name='app', logfile='app.log', debug=True):\n    logging.basicConfig(filename=logfile, level=logging.DEBUG)\n    logger = logging.getLogger(name)\n    logger.setLevel(logging.DEBUG)\n    if debug:\n        logger.setLevel(logging.INFO)\n    return logger", "def build_app_logger(name='app', logfile='app.log', debug=True):\n    # create logger\n    logger = logging.getLogger(name)\n\n    # set log level\n    logger.setLevel(logging.INFO)\n\n    # create formatter\n    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n\n    # add formatter to logger\n    logger.addHandler(formatter)\n\n    # add debug mode to logger\n    if debug:\n        logger.addHandler(logging.StreamHandler())\n\n    return logger\n"]}
{"_id": "62ece4992e6aefcf4aabbd88", "generate_results": ["def make_array(shape, dtype=np.dtype(\"float32\")):\n    return np.zeros(shape, dtype)", "def make_array(shape, dtype=np.dtype(\"float32\")):\n    return np.zeros(shape, dtype=dtype)\n", "def make_array(shape, dtype=np.dtype(\"float32\")):\n    return np.zeros(shape, dtype=dtype)", "def make_array(shape, dtype=np.dtype(\"float32\")):\n    return np.zeros(shape, dtype=dtype)", "def make_array(shape, dtype=np.dtype(\"float32\")):\n    return np.zeros(shape, dtype=dtype)", "def make_array(shape, dtype=np.dtype(\"float32\")):\n    return np.zeros(shape, dtype=dtype)\n", "def make_array(shape, dtype=np.dtype(\"float32\")):\n    return np.zeros(shape, dtype)\n", "def make_array(shape, dtype=np.dtype(\"float32\")):\n    return np.zeros(shape=shape, dtype=dtype)\n", "def make_array(shape, dtype=np.dtype(\"float32\")):\n    return np.zeros(shape, dtype=dtype)", "def make_array(shape, dtype=np.dtype(\"float32\")):\n    return np.zeros(shape, dtype=dtype)"]}
{"_id": "62ece4992e6aefcf4aabbd89", "generate_results": ["def gaussian(x):\n    return np.exp(-np.power(x - 0.2, 2) / (2 * np.power(0.1, 2)))\n", "def gaussian(x):\n    return np.exp(-(x**2)/(2*0.2**2))\n", "def gaussian(x):\n    return np.exp(-0.5*(x-0.2)**2/(2*0.2**2))", "def gaussian(x):\n    \n    \n    return np.exp(-(x-0.2)**2/(2*0.1**2))", "def gaussian(x):\n    return np.exp(-x**2/2) / (2*np.pi*np.sqrt(2*np.log(2)))\n", "def gaussian(x):\n    return np.exp(-np.power(x - 0.2, 2) / (2 * np.power(0.1, 2)))\n", "def gaussian(x):\n    return np.exp(-(x**2)/2) / (np.sqrt(2*np.pi)*sigma)\n\n# %% Class definition.", "def gaussian(x):\n    \n    \n    return np.exp(-0.5*(x-0.2)**2)*np.exp(-0.5*(x-0.2)**2)*np.exp(-0.5*(x-0.2)**2)\n\n# Create a function that calculates the density of a Gaussian function given the mean and standard deviation of a Gaussian function.", "def gaussian(x):\n    return np.exp(-(x**2)/(2*0.2**2))", "def gaussian(x):\n    \n    \n    return np.exp(-(x**2)/2)/np.sqrt(2*np.pi)"]}
{"_id": "62ece4992e6aefcf4aabbd8a", "generate_results": ["def load_configurations(config_filenames, overrides=None, resolve_env=True):\n    return load_configurations_from_filenames(\n        config_filenames, resolve_env=resolve_env, overrides=overrides)\n", "def load_configurations(config_filenames, overrides=None, resolve_env=True):\n    return _load_configs(config_filenames, parse_config, overrides,\n                         resolve_env=resolve_env)\n", "def load_configurations(config_filenames, overrides=None, resolve_env=True):\n    return _load_configurations(config_filenames, overrides, resolve_env, False)\n", "def load_configurations(config_filenames, overrides=None, resolve_env=True):\n    cfg = load_config_files(config_filenames, resolve_env=resolve_env)\n    return _validate_config_files(cfg, overrides)\n", "def load_configurations(config_filenames, overrides=None, resolve_env=True):\n    configs = load_configs(config_filenames, resolve_env)\n    errors = validate_configs(configs, overrides=overrides)\n    return configs, errors\n", "def load_configurations(config_filenames, overrides=None, resolve_env=True):\n    parser = ConfigurationParser(overrides)\n    return _load_configurations(config_filenames, parser, resolve_env)\n", "def load_configurations(config_filenames, overrides=None, resolve_env=True):\n    configurations = _load_configs(config_filenames, resolve_env)\n    errors = _validate_configurations(configurations, overrides)\n    return configurations, errors\n", "def load_configurations(config_filenames, overrides=None, resolve_env=True):\n    configs = _load_configurations(config_filenames, overrides, resolve_env)\n    return _validate_configurations(configs, config_filenames)\n", "def load_configurations(config_filenames, overrides=None, resolve_env=True):\n    return load_configs(config_filenames, overrides, resolve_env)[0]\n", "def load_configurations(config_filenames, overrides=None, resolve_env=True):\n    return _load_configurations(config_filenames, _load_configs, overrides, resolve_env)\n"]}
{"_id": "62ece4992e6aefcf4aabbd8b", "generate_results": ["def force_string(obj):\n    if isinstance(obj, bytes):\n        return obj.decode('utf-8')\n    return obj\n", "def force_string(obj):\n    if isinstance(obj, np.bytes_) or isinstance(obj, bytes):\n        return obj.decode('utf-8')\n    return obj\n", "def force_string(obj):\n    if isinstance(obj, bytes):\n        return obj.decode('utf-8')\n    return obj\n", "def force_string(obj):\n    return obj if isinstance(obj, str) else str(obj, encoding='utf-8')", "def force_string(obj):\n    if isinstance(obj, bytes):\n        return obj.decode('utf-8')\n    return obj\n", "def force_string(obj):\n    if isinstance(obj, str):\n        return obj\n    if isinstance(obj, bytes):\n        return obj.decode('utf-8')\n    return obj\n", "def force_string(obj):\n    if isinstance(obj, str):\n        return obj\n    elif isinstance(obj, bytes):\n        return obj.decode(\"utf-8\")\n    else:\n        return obj\n", "def force_string(obj):\n    if isinstance(obj, bytes):\n        return obj.decode('utf-8')\n    return obj\n", "def force_string(obj):\n    if isinstance(obj, bytes):\n        return obj.decode(\"utf-8\")\n    return obj\n", "def force_string(obj):\n    if isinstance(obj, np.bytes_) or isinstance(obj, np.bytearray):\n        return obj.decode(\"utf-8\")\n    return obj\n"]}
{"_id": "62e60723d76274f8a4026b76", "generate_results": ["def from_ticks(cls, ticks, tz=None):\n    return cls.from_datetime(\n        datetime.fromtimestamp(ticks, tz),\n        tz)", "def from_ticks(cls, ticks, tz=None):\n    return cls.from_datetime(datetime.fromtimestamp(ticks), tz)", "def from_ticks(cls, ticks, tz=None):\n    return cls(ticks, tz=tz)", "def from_ticks(cls, ticks, tz=None):\n    return cls.from_timestamps(ticks, tz)", "def from_ticks(cls, ticks, tz=None):\n    return cls.from_datetime(\n        dt.datetime.fromtimestamp(ticks, tz),\n        tz=tz)\n", "def from_ticks(cls, ticks, tz=None):\n    return cls(ticks, tz)\n", "def from_ticks(cls, ticks, tz=None):\n    return cls.from_isoticks(isoticks=ticks, tz=tz)\n", "def from_ticks(cls, ticks, tz=None):\n    \n    \n    return cls(ticks, tz)", "def from_ticks(cls, ticks, tz=None):\n    return cls(np.asarray(ticks, dtype='datetime64[s]'), tz=tz)", "def from_ticks(cls, ticks, tz=None):\n    return cls.from_datetime(datetime.datetime.fromtimestamp(ticks, tz))\n"]}
{"_id": "62e60873d76274f8a4026bd8", "generate_results": ["def protocol_handlers(cls, protocol_version=None):\n    return {\n        'foo': __protocol_handler_foo,\n        'bar': __protocol_handler_bar,\n        'baz': __protocol_handler_baz\n    }", "def protocol_handlers(cls, protocol_version=None):\n    \n    \n    return [\n        ('/', ProtocolHandler),\n        ('/api/', ProtocolHandler),\n        ('/api/v1/', ProtocolHandler),\n        ('/api/v2/', ProtocolHandler),\n        ('/api/v2/v1/', ProtocolHandler),\n        ('/api/v2/v2/', ProtocolHandler),\n        ('/api/v2/v2/v2/', ProtocolHandler),\n    ]", "def protocol_handlers(cls, protocol_version=None):\n    if protocol_version is None:\n        protocol_version = _protocol_version\n    return [\n        ('/protocol_handlers', ProtocolHandler, {'protocol_version': protocol_version}),\n    ]\n", "def protocol_handlers(cls, protocol_version=None):\n    return {}\n", "def protocol_handlers(cls, protocol_version=None):\n    return {'protocol_handlers': []}\n", "def protocol_handlers(cls, protocol_version=None):\n    return {\n        'protocol_version': protocol_version,\n        'events': [\n            'node_created',\n            'node_updated',\n            'node_deleted',\n            'node_deleted_by_user',\n        ],\n        'nodes': [\n            'node_created',\n            'node_updated',\n            'node_deleted',\n        ],\n    }\n", "def protocol_handlers(cls, protocol_version=None):\n    return []\n", "def protocol_handlers(cls, protocol_version=None):\n    \n    \n    return {\n        'protocol_version': protocol_version,\n        'protocol_version_major': protocol_version // 100,\n        'protocol_version_minor': (protocol_version % 100) // 10,\n    }\n", "def protocol_handlers(cls, protocol_version=None):\n    return []\n", "def protocol_handlers(cls, protocol_version=None):\n    return []\n"]}
{"_id": "62e60e3bd76274f8a4026d1a", "generate_results": ["def from_raw_values(cls, values):\n    return cls(values)", "def from_raw_values(cls, values):\n    \n    \n    return cls(values=values)", "def from_raw_values(cls, values):\n    return cls(values[0], values[1], values[2], values[3], values[4], values[5], values[6])\n", "def from_raw_values(cls, values):\n    \n    \n    return cls([\n        Bookmark(\n            *[int(value) for value in value.split('.')],\n            bookmark_id=value\n        )\n        for value in values\n    ])", "def from_raw_values(cls, values):\n    return cls(\n        raw_values=[value.strip() for value in values],\n        url=values[0],\n        title=values[1],\n    )\n", "def from_raw_values(cls, values):\n    \n    \n    return cls.from_values(values)", "def from_raw_values(cls, values):\n    \n    \n    return cls(values)", "def from_raw_values(cls, values):\n    return cls(values)\n", "def from_raw_values(cls, values):\n    return cls(values[0], values[1], values[2], values[3], values[4], values[5], values[6], values[7], values[8])\n", "def from_raw_values(cls, values):\n    return cls([Bookmark(value) for value in values])"]}
{"_id": "62b87b199a0c4fa8b80b354c", "generate_results": ["def _get_seq_with_type(seq, bufsize=None):\n    \n    \n    return list(_iter_seq_with_type(seq, bufsize))\n", "def _get_seq_with_type(seq, bufsize=None):\n    \n    \n    return np.array([seq[i].astype(np.float32) for i in range(len(seq))])\n", "def _get_seq_with_type(seq, bufsize=None):\n    return _get_seq(seq, bufsize, type='type')\n", "def _get_seq_with_type(seq, bufsize=None):\n    \n    \n    if bufsize is None:\n        bufsize = 1024\n    return np.frombuffer(seq, dtype=np.uint8).reshape(-1, bufsize)", "def _get_seq_with_type(seq, bufsize=None):\n    \n    \n    return (seq, type(seq))\n", "def _get_seq_with_type(seq, bufsize=None):\n    \n    \n    if isinstance(seq, six.string_types):\n        seq = seq.encode('utf-8')\n    if not bufsize:\n        bufsize = sys.getsizeof(seq)\n    return seq\n", "def _get_seq_with_type(seq, bufsize=None):\n    if bufsize is None:\n        bufsize = _get_buffer_size()\n    return _get_seq_with_type_buffer(seq, bufsize)\n", "def _get_seq_with_type(seq, bufsize=None):\n    if bufsize is None:\n        bufsize = sys.getsizeof(seq)\n    iter = iter(seq)\n    try:\n        for i in range(bufsize):\n            yield next(iter)\n    except StopIteration:\n        pass\n", "def _get_seq_with_type(seq, bufsize=None):\n    \n    \n    if bufsize is None:\n        bufsize = sys.getsizeof(seq)\n\n    return np.frombuffer(seq, dtype=np.int32, offset=bufsize)\n", "def _get_seq_with_type(seq, bufsize=None):\n    \n    \n    if bufsize is None:\n        bufsize = _default_bufsize\n\n    seq = iter(seq)\n    while True:\n        try:\n            yield next(seq)\n        except StopIteration:\n            break\n"]}
{"_id": "62b87b4f9a0c4fa8b80b3581", "generate_results": ["def scale(self, other=None, recompute=False):\n    if other is not None:\n        self.x = self.x * other.x\n        self.y = self.y * other.y\n    return self", "def scale(self, other=None, recompute=False):\n    if other is None:\n        other = self\n    for i in range(3):\n        self._coords[i] *= other._coords[i]\n    if recompute:\n        self.recompute()\n", "def scale(self, other=None, recompute=False):\n    if other is None:\n        other = Vector([1, 0, 0])\n    new_coords = self.coords * other\n    if recompute:\n        self.__init__(new_coords)", "def scale(self, other=None, recompute=False):\n    pass", "def scale(self, other=None, recompute=False):\n    if other is None:\n        return self\n    for s in self.getSections():\n        s.scale(other, recompute=recompute)\n    return self", "def scale(self, other=None, recompute=False):\n    if other is None:\n        return self\n    if not isinstance(other, Vector):\n        raise TypeError(\"Expecting Vector type\")\n    if self.shape!= other.shape:\n        raise ValueError(\"Shapes do not match\")\n    if self.shape == (1, 1):\n        return self.scale(other)\n    return self.scale_scalar(other)", "def scale(self, other=None, recompute=False):\n    if not other:\n        return self.copy()\n    if not isinstance(other, Scale):\n        raise ValueError('other must be a Scale instance')\n    if recompute:\n        other._recompute()\n    self._transform *= other._transform\n    self._invalidate_cache()\n    return self", "def scale(self, other=None, recompute=False):\n    if other is not None:\n        self._transform = self._transform.scale(other._transform)\n        if recompute:\n            self.recompute()", "def scale(self, other=None, recompute=False):\n    if other is None:\n        other = Vector(0, 0, 0)\n    self.x *= other.x\n    self.y *= other.y\n    self.z *= other.z", "def scale(self, other=None, recompute=False):\n    if other is None:\n        other = self\n    for s in other.shapes:\n        self.shapes[s].scale(other.shapes[s], recompute=recompute)\n    return self"]}
{"_id": "62b87b519a0c4fa8b80b3583", "generate_results": ["def scale(self, other=None):\n    pass\n", "def scale(self, other=None):\n    pass\n", "def scale(self, other=None):\n    if other is None:\n        other = Scale(self)\n    for i, s in enumerate(self.scalings):\n        self.scalings[i] = s * other.scalings[i]\n    return self", "def scale(self, other=None):\n    if other is None:\n        other = Vector()\n    return Vector(self.x * other.x, self.y * other.y, self.z * other.z)\n", "def scale(self, other=None):\n    \n    \n    if other is None:\n        return self\n    return self.__class__(self.x * other, self.y * other)", "def scale(self, other=None):\n    pass\n", "def scale(self, other=None):\n    '''\n    '''\n    if other is None:\n        return Point(self.x * self.scaler, self.y * self.scaler)\n    self.x *= other.x\n    self.y *= other.y\n    return self\n", "def scale(self, other=None):\n    return Point(self.x * other, self.y * other)\n", "def scale(self, other=None):\n    if other is None:\n        other = self.scalar\n    return self.scalar * other", "def scale(self, other=None):\n    pass"]}
{"_id": "62b87b869a0c4fa8b80b35e1", "generate_results": ["def hist_to_graph(hist, make_value=None, get_coordinate=\"left\",\n                  field_names=(\"x\", \"y\"), scale=None):\n    if make_value is None:\n        make_value = lambda x: x\n    return hist._replace(\n        _make_value=make_value,\n        _get_coordinate=get_coordinate,\n        _field_names=field_names,\n        _scale=scale)\n", "def hist_to_graph(hist, make_value=None, get_coordinate=\"left\",\n                  field_names=(\"x\", \"y\"), scale=None):\n    \n    \n    if scale is None:\n        scale = get_coordinate(hist.x)\n    x_range = hist.xrange(*scale)\n    y_range = hist.yrange(*scale)\n    graph = graphs.Graph(hist.x, hist.y, x_range, y_range, field_names=field_names,\n                         make_value=make_value)\n    return graph\n", "def hist_to_graph(hist, make_value=None, get_coordinate=\"left\",\n                  field_names=(\"x\", \"y\"), scale=None):\n    \n    \n    return hist_to_graph_impl(hist, make_value=make_value, get_coordinate=get_coordinate,\n                              field_names=field_names, scale=scale)\n", "def hist_to_graph(hist, make_value=None, get_coordinate=\"left\",\n                  field_names=(\"x\", \"y\"), scale=None):\n    g = hist.to_graph(make_value=make_value, get_coordinate=get_coordinate,\n                      field_names=field_names, scale=scale)\n    return g", "def hist_to_graph(hist, make_value=None, get_coordinate=\"left\",\n                  field_names=(\"x\", \"y\"), scale=None):\n    \n    \n    if make_value is None:\n        make_value = lambda x: x\n    if scale is None:\n        scale = lambda x: x\n\n    g = {}\n    for field_name, x in zip(field_names, hist):\n        g[field_name] = make_value(x)\n        g[field_name] = scale(g[field_name])\n\n    return g\n", "def hist_to_graph(hist, make_value=None, get_coordinate=\"left\",\n                  field_names=(\"x\", \"y\"), scale=None):\n    if scale is None:\n        scale = hist.GetScale()\n    if get_coordinate == \"left\":\n        return hist.GetXaxis().GetXaxis().SetScale(scale)\n    elif get_coordinate == \"right\":\n        return hist.GetYaxis().GetYaxis().SetScale(scale)\n    else:\n        raise ValueError(\"get_coordinate must be left or right\")\n", "def hist_to_graph(hist, make_value=None, get_coordinate=\"left\",\n                  field_names=(\"x\", \"y\"), scale=None):\n    if scale is None:\n        scale = hist.max()\n    if make_value is None:\n        make_value = lambda x: x\n    hist = hist / scale\n    graph = {}\n    for field_name in field_names:\n        graph[field_name] = []\n    for i in range(len(hist)):\n        for j in range(len(hist[i])):\n            graph[field_name].append((get_coordinate(hist, i, j), make_value(hist[i][j])))\n    return graph\n", "def hist_to_graph(hist, make_value=None, get_coordinate=\"left\",\n                  field_names=(\"x\", \"y\"), scale=None):\n    \n    \n    return hist_to_graph_iter(hist, make_value=make_value, get_coordinate=get_coordinate, field_names=field_names, scale=scale)\n", "def hist_to_graph(hist, make_value=None, get_coordinate=\"left\",\n                  field_names=(\"x\", \"y\"), scale=None):\n    return hist_to_graph_helper(hist, make_value=make_value,\n                                get_coordinate=get_coordinate,\n                                field_names=field_names, scale=scale)\n", "def hist_to_graph(hist, make_value=None, get_coordinate=\"left\",\n                  field_names=(\"x\", \"y\"), scale=None):\n    \n    \n    return hist2graph(hist, make_value, get_coordinate, field_names, scale)\n"]}
{"_id": "62b8b4baeb7e40a82d2d1136", "generate_results": ["def _verify(iface, candidate, tentative=False, vtype=None):\n    \n    \n    if not _is_valid_interface(iface):\n        return False\n\n    return _verify_dev(iface, candidate, vtype=vtype) \\\n        and _verify_candidate(iface, candidate, vtype=vtype) \\\n        and _verify_tentative(iface, candidate, vtype=vtype)\n", "def _verify(iface, candidate, tentative=False, vtype=None):\n    \n    \n    return candidate == iface.value", "def _verify(iface, candidate, tentative=False, vtype=None):\n    \n    \n    if vtype is None:\n        vtype = iface.vtype()\n    return verify(iface, candidate, vtype, tentative)\n", "def _verify(iface, candidate, tentative=False, vtype=None):\n    \n    \n    if vtype is None:\n        vtype = iface.vtype\n    if vtype!='veth':\n        return True\n    if candidate not in iface.veths:\n        return False\n    if vtype =='veth':\n        return iface.veths[candidate]\n    elif vtype == 'patch':\n        return iface.veths[candidate] == candidate\n    else:\n        return iface.veths[candidate] == candidate and candidate in iface.patch\n", "def _verify(iface, candidate, tentative=False, vtype=None):\n    \n    \n    if not vtype:\n        vtype = iface.vtype\n    if vtype == 'vlan':\n        return _verify_vlan(iface, candidate, tentative)\n    else:\n        return _verify_bridge(iface, candidate, vtype)", "def _verify(iface, candidate, tentative=False, vtype=None):\n    \n    \n    if vtype is None:\n        vtype = _get_vtype(iface)\n    return _verify_address(iface, candidate, vtype, tentative)\n", "def _verify(iface, candidate, tentative=False, vtype=None):\n    \n    \n    if vtype is None:\n        vtype = iface.vtype\n    if iface.name == candidate:\n        if vtype == 'bridge':\n            return True\n        elif vtype == 'vlan':\n            return True\n        elif vtype == 'bonding':\n            return True\n        elif vtype == 'bridge-domain':\n            return True\n        else:\n            return False\n    else:\n        return False\n", "def _verify(iface, candidate, tentative=False, vtype=None):\n    \n    \n    return __salt__['cmd.run']('ip link show dev %s' % iface) == candidate\n", "def _verify(iface, candidate, tentative=False, vtype=None):\n    \n    \n    return _verify_impl(iface, candidate, tentative, vtype)", "def _verify(iface, candidate, tentative=False, vtype=None):\n    \n    \n    return __salt__['network.interface_ip'](iface, candidate, vtype=vtype, tentative=tentative)\n"]}
{"_id": "62b8b4baeb7e40a82d2d1137", "generate_results": ["def verifyObject(iface, candidate, tentative=False):\n    \npass", "def verifyObject(iface, candidate, tentative=False):\n    '''\n    '''\n    return True", "def verifyObject(iface, candidate, tentative=False):\n    \"\"\" \"\"\"\n    \"\"\" \"\"\"\n    return iface.verifyObject(candidate, tentative)\n", "def verifyObject(iface, candidate, tentative=False):\n    \n    \n    if not candidate:\n        return False\n    if not tentative:\n        if iface.providedBy(candidate):\n            return True\n        for provider in iface.provides:\n            if provider.providedBy(candidate):\n                return True\n        return False\n    for provider in iface.provides:\n        if provider.providedBy(candidate):\n            return True\n    return False", "def verifyObject(iface, candidate, tentative=False):\n    ''''''\n    return True\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "def verifyObject(iface, candidate, tentative=False):\n    '''\n    '''\n    return verify(iface, candidate, tentative)\n\n", "def verifyObject(iface, candidate, tentative=False):\n    \n    \n    if tentative:\n        return True\n\n    if iface.name in candidate:\n        return True\n    return False\n", "def verifyObject(iface, candidate, tentative=False):\n    \n    \n    try:\n        return iface.verifyObject(candidate)\n    except Exception as exc:\n        if not tentative:\n            raise exc", "def verifyObject(iface, candidate, tentative=False):\n    \n    \n    return verify(iface, candidate, tentative)", "def verifyObject(iface, candidate, tentative=False):\n    \n    \n    log.debug('verifyObject(%s, %s, %s)', iface, candidate, tentative)\n    return iface.verifyObject(candidate, tentative)"]}
{"_id": "62b8b4c1eb7e40a82d2d1139", "generate_results": ["def verifyClass(iface, candidate, tentative=False):\n    \npass", "def verifyClass(iface, candidate, tentative=False):\n    \n    \n    if not candidate:\n        return False\n    \n    for i in range(len(candidate)):\n        if verify(iface, candidate[i], tentative):\n            return True\n    return False", "def verifyClass(iface, candidate, tentative=False):\n    \n    \n    return True\n\n# ------------------------------------------------------------------------------", "def verifyClass(iface, candidate, tentative=False):\n    if tentative:\n        return False\n    else:\n        return iface.verify(candidate)\n", "def verifyClass(iface, candidate, tentative=False):\n    \n    \n    # iface.logMessage(\"verifyClass() \" + str(candidate))\n    if not tentative and candidate.has_class(iface.get_name()):\n        return True\n    return False\n", "def verifyClass(iface, candidate, tentative=False):\n    \n    \n    if candidate is None:\n        return False\n    return iface.verify(candidate, tentative)", "def verifyClass(iface, candidate, tentative=False):\n    \n    \n    return verify(iface, candidate, None, tentative)", "def verifyClass(iface, candidate, tentative=False):\n    \npass", "def verifyClass(iface, candidate, tentative=False):\n    \npass", "def verifyClass(iface, candidate, tentative=False):\n    '''\n    '''\n    return verify(iface, candidate, tentative)"]}
{"_id": "62b8b559eb7e40a82d2d11f6", "generate_results": ["def determineMetaclass(bases, explicit_mc=None):\n    if explicit_mc is None:\n        explicit_mc = []\n    for b in bases:\n        if issubclass(b, BaseMeta):\n            explicit_mc.append(b)\n            break\n    return explicit_mc\n", "def determineMetaclass(bases, explicit_mc=None):\n    \n    \n    if explicit_mc is None:\n        explicit_mc = []\n\n    for base in bases:\n        if isinstance(base, type):\n            if base not in explicit_mc:\n                explicit_mc.append(base)\n                yield base\n        else:\n            if base not in explicit_mc:\n                explicit_mc.append(base)\n                yield base\n", "def determineMetaclass(bases, explicit_mc=None):\n    \n    \n    if explicit_mc is not None:\n        return explicit_mc\n    else:\n        return bases\n", "def determineMetaclass(bases, explicit_mc=None):\n    \n    \n    if not bases:\n        return type\n    if explicit_mc is None:\n        explicit_mc = []\n    if len(bases)!= 1 or issubclass(bases[0], type):\n        explicit_mc.append(bases[0])\n        return type\n    explicit_mc.append(bases[0])\n    return determineMetaclass(bases[1:], explicit_mc)\n", "def determineMetaclass(bases, explicit_mc=None):\n    if explicit_mc is None:\n        explicit_mc = []\n    if issubclass(bases[0], type):\n        return explicit_mc\n    for base in bases:\n        if issubclass(base, type):\n            return explicit_mc\n        if base is type:\n            return determineMetaclass(bases[1:], explicit_mc)\n    return explicit_mc\n", "def determineMetaclass(bases, explicit_mc=None):\n    return metaclass(\n        'DeclarativeMeta',\n        bases,\n        dict(\n            __doc__=''' Declarative class for the SQLAlchemy ORM class. ''',\n            __new__=__new__,\n            __init__=__init__,\n            __slots__=(),\n            __weakref__=__weakref__,\n            __dict__=__dict__,\n            __getattribute__=lambda self, name: None,\n        )\n    )", "def determineMetaclass(bases, explicit_mc=None):\n    return []\n", "def determineMetaclass(bases, explicit_mc=None):\n    return det_metaclass(bases, explicit_mc)", "def determineMetaclass(bases, explicit_mc=None):\n    return Metaclass(bases, explicit_mc)\n", "def determineMetaclass(bases, explicit_mc=None):\n    return type('Meta', bases, {})"]}
{"_id": "62b8d22a48ba5a41d1c3f47d", "generate_results": ["def pop(self, key, default=__marker):\n    \n    \n    if key in self:\n        if default is self.__marker:\n            return self.pop(key)\n        else:\n            return self[key]\n    else:\n        if default is self.__marker:\n            raise KeyError(key)\n        else:\n            return default", "def pop(self, key, default=__marker):\n    \n    \n    if key in self:\n        value = self[key]\n        del self[key]\n        return value\n    if default is not __marker:\n        return default\n    raise KeyError(key)", "def pop(self, key, default=__marker):\n    \n    \n    try:\n        return self.__getitem__(key)\n    except KeyError:\n        if default is __marker:\n            raise\n        return default\n", "def pop(self, key, default=__marker):\n    \n    \n    return self.__dict__.pop(key, default)\n", "def pop(self, key, default=__marker):\n    \n    \n    if key in self:\n        value = self[key]\n        del self[key]\n        return value\n    if default is self.__marker:\n        raise KeyError(key)\n    return default", "def pop(self, key, default=__marker):\n    \n    \n    return self.__dict__.pop(key, default)", "def pop(self, key, default=__marker):\n    \n    \n    if key in self:\n        self.__delitem__(key)\n    elif default is not __marker:\n        return default\n    else:\n        raise KeyError(key)", "def pop(self, key, default=__marker):\n    \n    \n    return self.__stack.pop(key, default)", "def pop(self, key, default=__marker):\n    \n    \n    if not self:\n        if default is not __marker:\n            return default\n        raise KeyError(key)\n    if key not in self:\n        if default is not __marker:\n            return default\n        raise KeyError(key)\n    value = self[key]\n    del self[key]\n    return value\n", "def pop(self, key, default=__marker):\n    \n    \n    if default is __marker:\n        return self.popitem(key)[1]\n    else:\n        return self.pop(key, default)"]}
{"_id": "62b8d23748ba5a41d1c3f497", "generate_results": ["def popitem(self):\n    \n    \n    pass\n", "def popitem(self):\n    \n    \n    return dict.popitem(self)\n", "def popitem(self):\n    if not self:\n        raise KeyError('popitem(): dictionary is empty')\n    return self.__key, self.__value", "def popitem(self):\n    pass\n", "def popitem(self):\n    return self.pop()", "def popitem(self):\n    '''\n    '''\n    return self.__dict__.popitem()", "def popitem(self):\n    \n    \n    return self.__dict__.popitem()", "def popitem(self):\n    ''' '''\n    pass", "def popitem(self):\n    \n    \n    self.__data.popitem()\n", "def popitem(self):\n    \"\"\"\n    \"\"\"\n    item = self.pop()\n    self.__list.remove(item)\n    return item"]}
{"_id": "62b8d23a48ba5a41d1c3f499", "generate_results": ["def popitem(self):\n    pass", "def popitem(self):\n    \n    \n    return self.__d.popitem()\n", "def popitem(self):\n    '''\n    '''\n    if not self.is_empty():\n        return self._data.popitem()\n    else:\n        raise KeyError(\"Empty heap\")\n    '''", "def popitem(self):\n    \n    \n    pass", "def popitem(self):\n    \n    \n    key = self._keys[-1]\n    del self[key]\n    return (key, self.pop(key))\n", "def popitem(self):\n    return self.db.popitem()\n", "def popitem(self):\n    \n    \n    pass", "def popitem(self):\n    pass\n", "def popitem(self):\n    return self.__d.popitem()\n", "def popitem(self):\n    return dict.popitem(self)"]}
{"_id": "62b8d23c48ba5a41d1c3f49b", "generate_results": ["def popitem(self):\n    if self._count == 0:\n        raise KeyError('dict is empty')\n    key = self._list[self._index]\n    self._remove(key)\n    return key, self.pop(key)\n", "def popitem(self):\n    item = super().popitem()\n    self.__map.pop(item[0], None)\n    return item", "def popitem(self):\n    if self._len == 0:\n        raise KeyError('The dictionary is empty.')\n    key = self._list.head.data\n    self._len -= 1\n    if self._len == 0:\n        self._remove_last()\n    return (key, self[key])\n", "def popitem(self):\n    return self._dict.popitem()\n", "def popitem(self):\n    return self._dict.popitem()", "def popitem(self):\n    return dict.popitem(self)[0]", "def popitem(self):\n    for k, v in self.__data:\n        if v is not REMOVED:\n            del self[k]\n            return (k, v)\n    raise KeyError('popitem(): dictionary is empty')", "def popitem(self):\n    raise NotImplementedError", "def popitem(self):\n    try:\n        return dict.popitem(self)\n    except KeyError:\n        raise KeyError('Key %r not found' % (self.key,))", "def popitem(self):\n    item = self.__getitem__(0)\n    return (item[0], item[1])\n"]}
{"_id": "62b8d23e48ba5a41d1c3f49e", "generate_results": ["def popitem(self):\n    return self.__choice.popitem()", "def popitem(self):\n    try:\n        key = list(self.__choice)[0]\n        self.__remove(key)\n        return key, self[key]\n    except IndexError:\n        raise KeyError('No value selected')\n", "def popitem(self):\n    try:\n        k, v = next(iter(self.__choice))\n    except StopIteration:\n        raise KeyError('No items to pop')\n    del self[k]\n    return k, v\n", "def popitem(self):\n    return self.__choice.popitem()\n", "def popitem(self):\n    return self.__choice.popitem()", "def popitem(self):\n    return self.__choice.popitem()", "def popitem(self):\n    \n    \n    key = random.choice(list(self.keys()))\n    return (key, self.pop(key))", "def popitem(self):\n    return random.choice(list(self.items()))", "def popitem(self):\n    return self.__choice.popitem()", "def popitem(self):\n    try:\n        return next(iter(self))\n    except StopIteration:\n        raise KeyError('popitem(): dictionary is empty')"]}
{"_id": "62b43425903eeb48555d3ea1", "generate_results": ["def _create_in_regex(self) -> Pattern:\n    return re.compile(self._regex)\n", "def _create_in_regex(self) -> Pattern:\n    return re.compile(self.pattern)", "def _create_in_regex(self) -> Pattern:\n    \n    \n    return re.compile(self.pattern)\n", "def _create_in_regex(self) -> Pattern:\n    \n    \n    return re.compile(self._pattern)\n", "def _create_in_regex(self) -> Pattern:\n    \n    \n    return re.compile(self._in_regex, re.MULTILINE)\n", "def _create_in_regex(self) -> Pattern:\n    \n    \n    return re.compile(self.pattern)\n", "def _create_in_regex(self) -> Pattern:\n    \n    \n    return re.compile(self.pattern)\n", "def _create_in_regex(self) -> Pattern:\n    \n    \n    return re.compile(self._pattern)\n", "def _create_in_regex(self) -> Pattern:\n    return re.compile(r'^[\\w-]+$')", "def _create_in_regex(self) -> Pattern:\n    return re.compile(self.pattern)\n"]}
{"_id": "62b43426903eeb48555d3ea2", "generate_results": ["def _create_converter(self) -> _converting._Converter:\n    return _converting._Converter(self._language)\n", "def _create_converter(self) -> _converting._Converter:\n    return _converting._Converter(self)\n", "def _create_converter(self) -> _converting._Converter:\n    \n    \n    raise NotImplementedError('Must be implemented in subclasses')\n", "def _create_converter(self) -> _converting._Converter:\n    return _converting._Converter()", "def _create_converter(self) -> _converting._Converter:\n    return _converting._Converter()\n", "def _create_converter(self) -> _converting._Converter:\n    \n    \n    return _converting._Converter(self)\n", "def _create_converter(self) -> _converting._Converter:\n    return _converting._Converter()\n", "def _create_converter(self) -> _converting._Converter:\n    return _converting._Converter(self._to_value)\n", "def _create_converter(self) -> _converting._Converter:\n    return _converting._Converter(self)\n", "def _create_converter(self) -> _converting._Converter:\n    \n    \n    return _converting._Converter(self)\n"]}
{"_id": "62b8966c755ee91dce50a154", "generate_results": ["def isoparse(self, dt_str):\n    \n    \n    if dt_str is None:\n        return None\n    return datetime.datetime.strptime(dt_str, ISO_FORMAT)", "def isoparse(self, dt_str):\n    \n    \n    return parse(dt_str)\n", "def isoparse(self, dt_str):\n    if dt_str:\n        dt_str = dt_str.split(\"-\")\n        if dt_str[0] == \"\":\n            dt_str[0] = \"00\"\n        if dt_str[1] == \"\":\n            dt_str[1] = \"00\"\n        if dt_str[2] == \"\":\n            dt_str[2] = \"00\"\n        return \"-\".join([dt_str[0], dt_str[1], dt_str[2]])\n    else:\n        return \"\"", "def isoparse(self, dt_str):\n    return datetime.strptime(dt_str, \"%Y-%m-%dT%H:%M:%S.%fZ\")", "def isoparse(self, dt_str):\n    return datetime.strptime(dt_str, \"%Y-%m-%dT%H:%M:%SZ\")\n", "def isoparse(self, dt_str):\n    \n    \n    return datetime.datetime.strptime(dt_str, '%Y-%m-%dT%H:%M:%SZ')", "def isoparse(self, dt_str):\n    \n    \n    if not dt_str:\n        return None\n    try:\n        dt = datetime.datetime.strptime(dt_str, \"%Y-%m-%dT%H:%M:%SZ\")\n    except ValueError:\n        return None\n    return dt\n", "def isoparse(self, dt_str):\n    \n    \n    try:\n        dt_obj = isodate.parse_datetime(dt_str)\n    except:\n        return False\n    return dt_obj", "def isoparse(self, dt_str):\n    if dt_str is None:\n        return None\n    dt_obj = datetime.strptime(dt_str, '%Y-%m-%dT%H:%M:%S.%fZ')\n    return dt_obj.isoformat()\n", "def isoparse(self, dt_str):\n    \n    \n    if isinstance(dt_str, datetime.datetime):\n        return dt_str.isoformat()\n    else:\n        return dt_str"]}
{"_id": "62b896de755ee91dce50a183", "generate_results": ["def parse(self, timestr, default=None,\n              ignoretz=False, tzinfos=None, **kwargs):\n    if ignoretz:\n        if isinstance(timestr, datetime):\n            timestr = timestr.strftime(\"%Y-%m-%d %H:%M:%S\")\n        else:\n            timestr = timestr\n\n    if timestr in self.cache:\n        return self.cache[timestr]\n\n    ret = default\n    for regex, fn in self.patterns:\n        match = regex.match(timestr)\n        if match:\n            ret = fn(match, **kwargs)\n            break\n    if not ret:\n        ret = default\n\n    self.cache[timestr] = ret\n    return ret\n", "def parse(self, timestr, default=None,\n              ignoretz=False, tzinfos=None, **kwargs):\n    return default\n", "def parse(self, timestr, default=None,\n              ignoretz=False, tzinfos=None, **kwargs):\n    return self._parse(timestr, ignoretz, tzinfos, default, **kwargs)", "def parse(self, timestr, default=None,\n              ignoretz=False, tzinfos=None, **kwargs):\n    if ignoretz:\n        timestr += 'Z'\n    return datetime.strptime(timestr, self.format).replace(tzinfo=None)\n", "def parse(self, timestr, default=None,\n              ignoretz=False, tzinfos=None, **kwargs):\n    if timestr in self.time_cache:\n        return self.time_cache[timestr]\n    else:\n        result = self._parse(timestr, default,\n                             ignoretz, tzinfos, **kwargs)\n        self.time_cache[timestr] = result\n        return result", "def parse(self, timestr, default=None,\n              ignoretz=False, tzinfos=None, **kwargs):\n    \"\"\" \"\"\"\n    try:\n        timeobj = timeparser.parse(timestr)\n        if ignoretz and timeobj.tzinfo is None:\n            timeobj = timeobj.replace(tzinfo=pytz.utc)\n        return timeobj\n    except Exception as e:\n        raise ValueError('invalid time: %s' % timestr)", "def parse(self, timestr, default=None,\n              ignoretz=False, tzinfos=None, **kwargs):\n    return default", "def parse(self, timestr, default=None,\n              ignoretz=False, tzinfos=None, **kwargs):\n    return parse_date(timestr, ignoretz=ignoretz, tzinfos=tzinfos, **kwargs)", "def parse(self, timestr, default=None,\n              ignoretz=False, tzinfos=None, **kwargs):\n    \"\"\"\n        Args:\n            timestr: string representing a time in the format '%Y-%m-%dT%H:%M:%SZ'\n            default: default value for the attribute\n    \"\"\"\n    return self.parse_time(timestr, default=default,\n                           ignoretz=ignoretz, tzinfos=tzinfos, **kwargs)\n", "def parse(self, timestr, default=None,\n              ignoretz=False, tzinfos=None, **kwargs):\n    return parse_time(timestr, default, ignoretz, tzinfos, **kwargs)\n"]}
{"_id": "62b8a4a4755ee91dce50a3d3", "generate_results": ["def fromutc(self, dt):\n    \n    \n    if self._time_func:\n        self._time_func(dt)\n    self._x += self._vx * dt\n    self._y += self._vy * dt\n    self._vx += self._ax * dt\n    self._vy += self._ay * dt\n    self._ax += self._ax_dt * dt\n    self._ay += self._ay_dt * dt", "def fromutc(self, dt):\n    '''\n    '''\n    return self.__time()", "def fromutc(self, dt):\n    \n    \n    return self._time_func(dt)", "def fromutc(self, dt):\n    pass\n", "def fromutc(self, dt):\n    \n    \n    self.pos += dt * self.vel\n    self.vel = self.vel.add(dt)", "def fromutc(self, dt):\n    self.dx += dt * self.x\n    self.dy += dt * self.y\n", "def fromutc(self, dt):\n    # Support for dt in seconds\n    if dt > 0:\n        return self.time.time() + dt * self.dt\n    else:\n        return self.time.time()", "def fromutc(self, dt):\n    return datetime.timedelta(seconds=0)\n", "def fromutc(self, dt):\n    \n    \n    return datetime.datetime.now()", "def fromutc(self, dt):\n    \"\"\" \"\"\"\n    return self._fromutc(dt)"]}
{"_id": "62b8a7b2755ee91dce50a4a7", "generate_results": ["def default_tzinfo(dt, tzinfo):\n    return dt.replace(tzinfo=tzinfo)\n", "def default_tzinfo(dt, tzinfo):\n    if dt == None:\n        return None\n    return dt.astimezone(tzinfo)", "def default_tzinfo(dt, tzinfo):\n    return dt\n", "def default_tzinfo(dt, tzinfo):\n    \n    \n    return dt.replace(tzinfo=tzinfo)\n", "def default_tzinfo(dt, tzinfo):\n    return dt\n", "def default_tzinfo(dt, tzinfo):\n    \n    \n    return dt\n", "def default_tzinfo(dt, tzinfo):\n    return dt\n", "def default_tzinfo(dt, tzinfo):\n    return dt\n", "def default_tzinfo(dt, tzinfo):\n    \n    \n    if tzinfo:\n        return dt.replace(tzinfo=tzinfo)\n    return dt\n", "def default_tzinfo(dt, tzinfo):\n    return dt\n"]}
{"_id": "6305f9991d275c6667163c50", "generate_results": ["def set_cut_chars(self, before: str, after: str) -> None:\nself.__cut_chars = before + after", "def set_cut_chars(self, before: str, after: str):\nself.__cut_chars = before +'' + after\n", "def set_cut_chars(self, before: str, after: str):\nself.cut_chars = before + after", "def set_cut_chars(self, before: str, after: str) -> None:\nself._cut_chars = before + \",\" + after", "def set_cut_chars(self, before: str, after: str):\nself.__cut_chars = before + after\nself.__cut_chars_len = len(self.__cut_chars)", "def set_cut_chars(self, before: str, after: str):\nself.cut_chars = before + after", "def set_cut_chars(self, before: str, after: str) -> None:\nif before is not None:\nself.__cut_chars = before\nif after is not None:\nself.__cut_chars += after\n", "def set_cut_chars(self, before: str ='', after: str ='') -> None:\nself.__cut_chars = before + after", "def set_cut_chars(self, before: str, after: str) -> None:\nself.__cut_chars = before + ',' + after\n", "def set_cut_chars(self, before: str, after: str):\nself._cut_chars = before + \",\" + after"]}
{"_id": "6306292052e177c0ba469f09", "generate_results": ["def identify_request(request: str) -> bool:\n    if request.startswith('/'):\n        return False\n\n    if request.startswith('/private'):\n        return True\n\n    return request.startswith('/message')\n", "def identify_request(request: Request):\n    if request.message:\n        return True\n    if request.private_message:\n        return True\n    if request.payload:\n        return True\n    return False\n", "def identify_request(request: Request) -> bool:\n    if request.is_payload_request():\n        return True\n    return request.is_legacy_payload()\n", "def identify_request(request: dict) -> bool:\n    if request[\"content\"].get(\"payload\", {}).get(\"type\") == \"message\":\n        return True\n    if request[\"content\"].get(\"payload\", {}).get(\"type\") == \"legacy_payload\":\n        return request[\"content\"].get(\"payload\", {}).get(\"payload_type\") == \"message\"\n    return False\n", "def identify_request(request: Request) -> bool:\n    if request.is_private:\n        return False\n\n    if not request.message:\n        return False\n\n    return _identify_request(request)\n", "def identify_request(request: dict) -> bool:\n    return request[\"public_message\"] is not None or request[\"private_message\"] is not None\n", "def identify_request(request: Request):\n    if request.is_legacy_payload():\n        return True\n    if request.is_private_payload():\n        return True\n    return False", "def identify_request(request: str) -> bool:\n    if request.startswith(\"/msg\"):\n        return True\n    elif request.startswith(\"/payload\"):\n        return False\n    else:\n        return False", "def identify_request(request: Request) -> bool:\n    return (\n        isinstance(request, Request)\n        and request.method in (\"POST\", \"PUT\", \"PATCH\", \"DELETE\")\n        and request.path.startswith(\"/private/\")\n    )\n", "def identify_request(request: Request) -> bool:\n    return (request.headers.get('content-type') == 'application/json' and\n            not request.headers.get('content-length'))\n"]}
{"_id": "6306292152e177c0ba469f0d", "generate_results": ["def identify_request(request: bytes) -> bool:\n    return (\n        request[:4] == b'\\x00\\x01\\x00\\x00\\x00'\n        and request[4:] == b'\\x00\\x01\\x00\\x00\\x00'\n        and request[8:12] == b'\\x00\\x01\\x00\\x00\\x00'\n        and request[12:14] == b'\\x00\\x00\\x01\\x00\\x00'\n        and request[14:] == b'\\x00\\x00\\x01\\x00\\x00'\n    )\n", "def identify_request(request: Request) -> bool:\n    return isinstance(request, MatrixRequest)\n", "def identify_request(request: Dict) -> bool:\n    return request['request'] =='matrix'", "def identify_request(request: Request) -> bool:\n    return isinstance(request, MatrixRequest)\n", "def identify_request(request: str) -> bool:\n    return request in (\"M\", \"m\", \"s\", \"S\", \"st\", \"T\")", "def identify_request(request: dict) -> bool:\n    \n    \n    if \"method\" in request and request[\"method\"] == \"Matrix\":\n        return True\n    else:\n        return False\n", "def identify_request(request: str) -> bool:\n    return bool(re.match(REQUEST_IDENTIFIER, request))\n", "def identify_request(request: dict):\n    if 'event' in request:\n        return 'event'\n    elif'request' in request:\n        return'request'\n    else:\n        return 'unknown'\n", "def identify_request(request: str) -> bool:\n    return bool(re.match(REQUEST_REGEX, request))\n", "def identify_request(request: str):\n    if request == 'Matrix':\n        return True\n    else:\n        return False\n"]}
{"_id": "6306292252e177c0ba469f11", "generate_results": ["def format_dt(dt):\n    return dt.strftime('%Y-%m-%d %H:%M:%S')\n", "def format_dt(dt):\n    return dt.strftime(\"%d %B %Y %H:%M:%S\")\n", "def format_dt(dt):\n    \n    \n    return dt.strftime(\"%Y-%m-%dT%H:%M:%S\")", "def format_dt(dt):\n    return dt.strftime('%Y-%m-%d %H:%M:%S.%f')", "def format_dt(dt):\n    return dt.strftime('%Y-%m-%d %H:%M:%S')\n", "def format_dt(dt):\n    return dt.strftime('%Y-%m-%dT%H:%M:%SZ')\n", "def format_dt(dt):\n    return dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n", "def format_dt(dt):\n    return dt.isoformat().replace('+00:00', 'Z')", "def format_dt(dt):\n    \n    \n    return dt.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n", "def format_dt(dt):\n    \n    \n    return dt.isoformat()"]}
{"_id": "6306292352e177c0ba469f1d", "generate_results": ["def find_tags(text: str, replacer: Callable[[str], str] = None) -> Tuple[Set[str], str]:\n    if replacer is not None:\n        text = replacer(text)\n    return set(TAG_RE.findall(text)), text", "def find_tags(text: str, replacer=None) -> Tuple[set, str]:\n    return _find_tags(text, replacer, ignore_code=True)\n", "def find_tags(text: str, replacer: Callable[[str], str] = None) -> Set[str]:\n    if not replacer:\n        return set(RE_TAG.findall(text))\n    else:\n        return set(RE_TAG.findall(text, replacer))\n", "def find_tags(text: str, replacer: Callable = None) -> Set[str]:\n    if replacer is None:\n        replacer = lambda t: t\n    return set(\n        tag for tag in findall(\n            r'<\\s*[^>]*?>(?:\\s*(?:\\w+\\s*=\\s*\\w+)|(?:\\s*(?:\\w+\\s*=\\s*)|(?:\\s*(?:\\w+\\s*=\\s*)|(?:\\s*(?:\\w+\\s*=\\s*)|(?:\\s*(?:\\w+\\s*=\\s*)|(?:\\s*(?:\\w+\\s*=\\s*)|(?:\\s*(?:\\w+\\s*=\\s*)))))))\\s*\\))',\n            text)\n", "def find_tags(text: str, replacer: Callable[[str], str] = replacer) -> Set[str]:\n    return {\n        tag\n        for tag in findall(r'(?:<[^>]+>)|(?:<[^>]+>)\\s*<[^>]+>', text)\n        if replacer(tag)\n    }\n", "def find_tags(text: str, replacer: Optional[Callable[[str], str]] = None) -> Set[str]:\n    if replacer is None:\n        replacer = lambda m: m\n\n    return set(\n        tag\n        for tag in re.findall(r\"<([^>]+)>\", text)\n        if tag.lower() not in (\"code\", \"meta\", \"footnotes\", \"code-block\")\n    ) | set(replacer(m) for m in re.findall(r\"<([^>]+)>\", text))\n", "def find_tags(text: str, replacer: Callable[[str], str] = None) -> Tuple[Set[str], str]:\n    if replacer:\n        text = re.sub(r\"<.*?>\", replacer, text)\n    return _find_tags(text)\n", "def find_tags(text: str, replacer: Optional[Callable[[str], str]] = None) -> Tuple[Set[str], str]:\n    if replacer:\n        text = replacer(text)\n\n    # Try to find tags in code blocks\n    tags = set()\n    match = re.search(r'<\\s*(?:[^>]*>)?(.*?)\\s*>', text)\n    while match:\n        tags.add(match.group(1))\n        text = text[match.end(1):]\n        match = re.search(r'<\\s*(?:[^>]*>)?(.*?)\\s*>', text)\n\n    return tags, text\n", "def find_tags(text: str, replacer: Callable = replace) -> Set[str]:\n    # Use regex to match tags inside code blocks\n    return re.findall(r\"<(?:[^>]|(?:[^>]|$))*>(.*?)</\\1>\", text, re.DOTALL | re.UNICODE)\n", "def find_tags(text: str, replacer: Callable = None) -> Set[str]:\n    if replacer is not None:\n        text = replacer(text)\n    text = RE_CODE_TAGS.sub(lambda m: RE_CODE_TAGS_REPLACE_MAP[m.group(0)], text)\n    return {m.group(0) for m in RE_TAGS.finditer(text)}"]}
{"_id": "6306292352e177c0ba469f1e", "generate_results": ["def process_text_links(text):\n    text = linkify_text(text)\n    text = process_links(text)\n    return text\n", "def process_text_links(text):\n    text = re.sub(r'\\[\\[\\[(.*?)\\]\\]\\]', lambda m: m.group(1) +'' + m.group(2), text)\n    text = re.sub(r'\\[\\[(.*?)\\]\\]', lambda m: m.group(1) + m.group(2), text)\n    text = re.sub(r'\\[\\[([^\\]]*)\\]\\]', lambda m: m.group(1) + m.group(2), text)\n    return text\n", "def process_text_links(text):\n    # Ignore links with a scheme and an authority.\n    text = re.sub(r\"(?s)<a\\s+href=['\\\"]?([^\\\"'>]*)['\\\"]?>([^<]*)</a>\",\n                  lambda m: m.group(1) + m.group(2).replace('\"', \"'\"), text)\n    return text", "def process_text_links(text):\n    for regex, replace in LINK_REGEXES:\n        text = regex.sub(replace, text)\n    return text", "def process_text_links(text):\n    return text\n", "def process_text_links(text):\n    \n    \n    text = text.replace('\\n','')\n    for match in re.finditer('https?://[^\\s]+', text):\n        if match.group() not in urls:\n            text = re.sub(match.group(), urls[match.group()], text)\n    for match in re.finditer('https?://[^\\s]+@[^\\s]+', text):\n        if match.group() not in urls:\n            text = re.sub(match.group(), urls[match.group()], text)\n    text = re.sub('https?://[^\\s]+', '', text)\n    return text", "def process_text_links(text):\n    text = linkify_text(text)\n    return text\n", "def process_text_links(text):\n    \n    \n    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+','', text)\n    text = re.sub(r'https?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+','', text)\n    text = re.sub(r'http\\S+', '', text)\n    return text", "def process_text_links(text):\n    text = re.sub(r'https?:\\/\\/(www\\.)?([a-zA-Z0-9]+\\.)*([a-zA-Z]{2,3}\\.[a-zA-Z0-9]+)', '\\g<1> <2>', text)\n    text = re.sub(r'https?://[a-zA-Z0-9\\-\\.]*', '\\g<1> <2>', text)\n    text = re.sub(r'https?://[a-zA-Z0-9\\-\\.]*[\\s\\S]*', '\\g<1> <2>', text)\n    text = re.sub(r'https?://[a-zA-Z0-9\\-\\.]*[\\s\\S]*', '\\g<1> <2>', text)\n    return text", "def process_text_links(text):\n    text = linkify_text(text)\n    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', r'<a href=\"\\1\">\\1</a>', text)\n    text = re.sub(r'https?://[a-zA-Z]+[a-zA-Z0-9_.-]*[a-zA-Z0-9]', r'<a href=\"\\1\">\\1</a>', text)\n    return text"]}
{"_id": "6306292652e177c0ba469f34", "generate_results": ["def fetch_content_type(url: str) -> str:\n    try:\n        return requests.head(url).headers['content-type']\n    except KeyError:\n        return ''\n", "def fetch_content_type(url: str) -> str:\n    try:\n        response = requests.head(url)\n        return response.headers[\"content-type\"]\n    except Exception:\n        return None\n", "def fetch_content_type(url: str) -> str:\n    r = requests.head(url)\n    return r.headers.get(\"content-type\")\n", "def fetch_content_type(url: str) -> str:\n    r = requests.head(url)\n    return r.headers['content-type']\n", "def fetch_content_type(url: str) -> Optional[str]:\n    response = requests.head(url)\n    if response.status_code == 200:\n        return response.headers.get(\"content-type\")\n    return None\n", "def fetch_content_type(url: str) -> str:\n    return requests.head(url).headers[\"content-type\"]\n", "def fetch_content_type(url: str) -> str:\n    return requests.head(url).headers[\"Content-Type\"]", "def fetch_content_type(url: str) -> str:\n    with closing(get(url, stream=True)) as resp:\n        return resp.headers['content-type']\n", "def fetch_content_type(url: str) -> str:\n    \n    \n    return requests.head(url).headers.get(\"content-type\", \"\")\n", "def fetch_content_type(url: str) -> str:\n    return requests.head(url).headers[\"content-type\"]\n"]}
{"_id": "6306292a52e177c0ba469f41", "generate_results": ["def test_tag(tag: str) -> bool:\n    return tag in TAGS", "def test_tag(tag: str, word: str) -> bool:\n    return tag in tag_mapping[word]\n", "def test_tag(tag: str) -> bool:\n    \n    \n    return bool(TAG_RE.match(tag))\n", "def test_tag(tag: str, word: str):\n    \n    \n    if tag in tag_map:\n        return tag_map[tag](word)\n    else:\n        return False", "def test_tag(tag: str) -> bool:\n    return tag in TAGS\n", "def test_tag(tag: str) -> bool:\n    return tag.lower() in TAGS", "def test_tag(tag: str) -> bool:\n    if tag not in TAGS:\n        return False\n    return True\n", "def test_tag(tag: str, word: str) -> bool:\n    if tag in TAGS:\n        return True\n    return False", "def test_tag(tag: str) -> bool:\n    return tag in TAGS\n", "def test_tag(tag: str) -> bool:\n    return tag in TAGS\n"]}
{"_id": "6306298b52e177c0ba469fdc", "generate_results": ["def xml_children_as_dict(node):\n    return {child.tag: child.text for child in node}\n", "def xml_children_as_dict(node):\n    return dict((child.tag, child.text) for child in node)\n", "def xml_children_as_dict(node):\n    return {child.tag: child.text for child in node}", "def xml_children_as_dict(node):\n    return dict([(child.tag, child.text)\n                 for child in node])\n", "def xml_children_as_dict(node):\n    result = {}\n    for child in node.getchildren():\n        tag = child.tag\n        if tag in result:\n            raise ValueError(\"Duplicate tag name %s\" % tag)\n        result[tag] = xml_children_as_dict(child)\n    return result\n", "def xml_children_as_dict(node):\n    return {child.tag: child.text for child in node}\n", "def xml_children_as_dict(node):\n    return {n.tag: n.text for n in node.getchildren()}\n", "def xml_children_as_dict(node):\n    return {child.tag: child.text for child in node}\n", "def xml_children_as_dict(node):\n    return dict((child.tag, child.text) for child in node)\n", "def xml_children_as_dict(node):\n    return {child.tag: child.text for child in node}\n"]}
{"_id": "6306299052e177c0ba469fe8", "generate_results": ["def check_sender_and_entity_handle_match(sender_handle, entity_handle):\n    if sender_handle == entity_handle:\n        return\n\n    if sender_handle == '-' or entity_handle == '-':\n        raise ValueError('The sender and entity may not be the same.')\n\n    if sender_handle == entity_handle.split('@')[0]:\n        raise ValueError('The sender and entity must be different.')\n", "def check_sender_and_entity_handle_match(sender_handle, entity_handle):\n    if sender_handle!= entity_handle:\n        raise ValueError('Sender and entity handle do not match.')\n", "def check_sender_and_entity_handle_match(sender_handle, entity_handle):\n    if sender_handle == entity_handle:\n        return\n    if sender_handle == '-':\n        sender_handle = '__UNKNOWN__'\n    if entity_handle == '-':\n        entity_handle = '__UNKNOWN__'\n    raise ValueError(\"Entity handle mismatch: %s vs %s\" % (sender_handle, entity_handle))\n", "def check_sender_and_entity_handle_match(sender_handle, entity_handle):\n    return sender_handle == entity_handle\n", "def check_sender_and_entity_handle_match(sender_handle, entity_handle):\n    if sender_handle == entity_handle:\n        return True\n    elif sender_handle is None or entity_handle is None:\n        return False\n    else:\n        return sender_handle == entity_handle\n", "def check_sender_and_entity_handle_match(sender_handle, entity_handle):\n    if sender_handle!= entity_handle:\n        raise ValueError(\"Sender and entity handle do not match.\")\n", "def check_sender_and_entity_handle_match(sender_handle, entity_handle):\n    if sender_handle!= entity_handle:\n        raise ValueError(\"Sender and entity handle mismatch.\")\n", "def check_sender_and_entity_handle_match(sender_handle, entity_handle):\n    if sender_handle!= entity_handle:\n        raise ValueError(\"Sender and Entity handle mismatch: %s!= %s\" % (\n            sender_handle, entity_handle))\n", "def check_sender_and_entity_handle_match(sender_handle, entity_handle):\n    if sender_handle == entity_handle:\n        return\n\n    raise Exception(\"Sender and entity handle mismatch\")\n", "def check_sender_and_entity_handle_match(sender_handle, entity_handle):\n    if sender_handle == entity_handle:\n        return\n\n    if sender_handle!= entity_handle:\n        raise ValueError(\"Sender and entity handles do not match\")\n"]}
{"_id": "630629b952e177c0ba46a043", "generate_results": ["def get_nodeinfo_well_known_document(url, document_path=None):\n    nodeinfo = {'protocol': 'https',\n                'url': url,\n                'document_path': document_path}\n    return nodeinfo\n", "def get_nodeinfo_well_known_document(url, document_path=None):\n    return _get_nodeinfo_well_known_document(url, document_path=document_path)", "def get_nodeinfo_well_known_document(url, document_path=None):\n    return {\n        \"nodeinfo\": {\n            \"url\": url,\n            \"document_path\": document_path,\n        }\n    }\n", "def get_nodeinfo_well_known_document(url, document_path=None):\n    if document_path is None:\n        document_path = '/'.join([url.rstrip('/'), 'document.well-known'])\n    return {'document_path': document_path}\n", "def get_nodeinfo_well_known_document(url, document_path=None):\n    document_path = document_path or ''\n    return {'@id': 'http://example.com/%s' % document_path,\n            '@type': 'http://schemas.google.com/g/2005#/definitions/NodeInfo',\n            'label': 'NodeInfo for %s' % url,\n            'properties': {\n                'url': url,\n                'document_path': document_path,\n            }}", "def get_nodeinfo_well_known_document(url, document_path=None):\n    document_path = document_path or get_nodeinfo_document_path(url)\n    return {\n        'type': 'document',\n        'url': url,\n        'document_path': document_path,\n    }\n", "def get_nodeinfo_well_known_document(url, document_path=None):\n    doc = NodeInfo()\n    doc.set_url(url)\n    doc.set_document_path(document_path)\n    return doc.to_dict()", "def get_nodeinfo_well_known_document(url, document_path=None):\n    return get_nodeinfo(url, document_path).well_known_document\n", "def get_nodeinfo_well_known_document(url, document_path=None):\n    return {\n        \"@type\": \"NodeInfo\",\n        \"@context\": \"https://nodeinfo.diaspora.software\",\n        \"@id\": url,\n        \"@type\": \"NodeInfo\",\n        \"@context\": \"https://nodeinfo.diaspora.software\",\n        \"@id\": url,\n    }\n", "def get_nodeinfo_well_known_document(url, document_path=None):\n    node_info = get_nodeinfo(url, document_path)\n    node_info['well_known'] = {\n       'version': '1.0',\n        'type': 'node-info',\n        'description': 'NodeInfo document',\n        'properties': node_info['properties'],\n    }\n    return node_info\n"]}
{"_id": "630629d052e177c0ba46a0a1", "generate_results": ["def verify_relayable_signature(public_key, doc, signature):\n    return verify_signature(public_key, doc.get_signature(signature),\n                            doc.get_signature_hash())\n", "def verify_relayable_signature(public_key, doc, signature):\n    # XXX Remove this line once the legacy client is aware of how signatures\n    # are generated and how to verify them.\n    return verify_signature(public_key, doc, signature)\n", "def verify_relayable_signature(public_key, doc, signature):\n    if signature!= doc.get('signature'):\n        raise ValueError('Signature does not match the claimed author.')\n", "def verify_relayable_signature(public_key, doc, signature):\n    return verify_relayable_elements(public_key, doc, signature, etree.fromstring(doc))\n", "def verify_relayable_signature(public_key, doc, signature):\n    verifier = Verifier(public_key)\n    if verifier.verify(doc, signature):\n        return True\n    return False\n", "def verify_relayable_signature(public_key, doc, signature):\n    return verify_signature(public_key, doc.elements[0].text, signature)\n", "def verify_relayable_signature(public_key, doc, signature):\n    return _verify_signature(public_key, doc, signature, True)\n", "def verify_relayable_signature(public_key, doc, signature):\n    signer = PKCS1_v1_5.new(public_key)\n    return signer.verify(SHA256.new(doc.toxml()).digest(), signature)\n", "def verify_relayable_signature(public_key, doc, signature):\n    element = doc.find('.//signature/relayableSignature')\n    assert element is not None\n    assert element.text == signature\n", "def verify_relayable_signature(public_key, doc, signature):\n    if not signature:\n        return False\n    if public_key is None:\n        return False\n    if doc.get('signature') is None:\n        return False\n    return verify_signature(public_key, doc.get('signature'), signature)\n"]}
{"_id": "630629e052e177c0ba46a0c4", "generate_results": ["def parse_diaspora_webfinger(document: Document) -> dict:\n    if document.get('webfinger'):\n        return parse_webfinger(document)\n    else:\n        return {}\n", "def parse_diaspora_webfinger(document: dict) -> dict:\n    return _parse_webfinger(document)\n", "def parse_diaspora_webfinger(document: Document, filename: str):\n\n    if filename.endswith('.json'):\n        return parse_json_webfinger(document, filename)\n    elif filename.endswith('.xrd'):\n        return parse_xrd_webfinger(document, filename)\n    else:\n        raise ValueError('Unknown webfinger file type: {}'.format(filename))", "def parse_diaspora_webfinger(document: Document) -> Dict[str, Any]:\n    if document.type == DocumentType.WEBFINGER_JSON:\n        return parse_diaspora_webfinger_json(document)\n    elif document.type == DocumentType.WEBFINGER_XRD:\n        return parse_diaspora_webfinger_xrd(document)\n    else:\n        raise ValueError(f\"Unknown document type {document.type}\")\n", "def parse_diaspora_webfinger(document: Document) -> DiasporaWebfinger:\n    if document.header.format == \"json\":\n        return parse_diaspora_webfinger_json(document)\n    elif document.header.format == \"xrd\":\n        return parse_diaspora_webfinger_xrd(document)\n    else:\n        raise ValueError(\"Unknown format: %s\" % document.header.format)\n", "def parse_diaspora_webfinger(document: Document) -> None:\n    if document.get(\"type\") == \"diaspora_webfinger\":\n        webfinger_response = requests.post(\n            \"https://diaspora.github.io/diaspora_federation/discovery/webfinger.json\",\n            data=json.dumps(document),\n            headers={\"Content-Type\": \"application/json\"},\n        )\n        if webfinger_response.status_code!= 200:\n            raise Exception(f\"Failed to parse webfinger {webfinger_response.status_code}\")\n", "def parse_diaspora_webfinger(document: Document) -> Dict[str, Any]:\n    if 'webfinger' not in document:\n        return {}\n    return parse_webfinger(document['webfinger'])\n", "def parse_diaspora_webfinger(document: Document) -> Optional[WebfingerDiaspora]:\n    if not document.text:\n        return None\n    if document.text.startswith(\"{\"):\n        return WebfingerDiaspora(document.text)\n    return None\n", "def parse_diaspora_webfinger(document: Document) -> Optional[Webfinger]:\n    if not document.url.startswith(\"http\"):\n        return None\n    return Webfinger.from_json(document.url)\n", "def parse_diaspora_webfinger(document: Document) -> DiasporaWebfinger:\n    if document.get(\"format\") == \"new\":\n        return parse_webfinger_new(document)\n    else:\n        return parse_webfinger_old(document)\n"]}
{"_id": "630629e152e177c0ba46a0d1", "generate_results": ["def try_retrieve_webfinger_document(handle: str) -> str:\n    try:\n        return requests.get(f\"https://{handle}/webfinger\").text\n    except requests.exceptions.RequestException:\n        return \"\"\n", "def try_retrieve_webfinger_document(handle: str, delay: int = 5) -> str:\n    time.sleep(delay)\n    try:\n        return retrieve_webfinger_document(handle)\n    except Exception:\n        return None\n", "def try_retrieve_webfinger_document(handle: int) -> WebfingerDocument:\n    try:\n        return WebfingerDocument(handle)\n    except WebfingerException:\n        return None\n", "def try_retrieve_webfinger_document(handle: Union[bytes, str], headers: dict) -> bytes:\n    \n    \n    try:\n        return retrieve_webfinger_document_raw(handle, headers)\n    except Exception as e:\n        if isinstance(e, HTTPError) and e.response.status_code == 403:\n            return None\n        raise\n", "def try_retrieve_webfinger_document(handle: int, user_agent: str) -> str:\n    response = requests.get(\n        url=f\"https://api.rfc7033.org/finger/{handle}?user-agent={user_agent}\",\n        timeout=TIMEOUT,\n    )\n\n    if response.status_code == 200:\n        return response.content.decode(\"utf-8\")\n\n    return \"\"\n", "def try_retrieve_webfinger_document(handle: str, suffix: str = '') -> dict:\n    try:\n        return retrieve_webfinger_document(handle, suffix)\n    except Exception as e:\n        logger.error(f\"Failed to retrieve webfinger document with error {e}\")\n        return {}\n", "def try_retrieve_webfinger_document(handle: str, **kwargs) -> bytes:\n    try:\n        return retrieve_webfinger_document(handle, **kwargs)\n    except Exception:\n        return b\"\"\n", "def try_retrieve_webfinger_document(handle: str, **kwargs) -> str:\n    try:\n        return handle.read()\n    except Exception:\n        pass\n", "def try_retrieve_webfinger_document(handle: str, username: str) -> str:\n    try:\n        return retrieve_webfinger_document_from_handle(handle, username)\n    except Exception:\n        # TODO log this\n        return \"\"\n", "def try_retrieve_webfinger_document(handle: Union[str, bytes]) -> str:\n    if isinstance(handle, str):\n        handle = handle.encode(\"ascii\")\n    response = requests.get(webfinger.url(handle), timeout=5)\n    if response.status_code == 200:\n        return response.text\n    return None\n"]}
{"_id": "630629e152e177c0ba46a0d2", "generate_results": ["def retrieve_and_parse_diaspora_webfinger(handle):\n    return retrieve_and_parse_webfinger(handle, \"diaspora\")\n", "def retrieve_and_parse_diaspora_webfinger(handle):\n    r = requests.get(handle)\n    r.raise_for_status()\n    return r.json()\n", "def retrieve_and_parse_diaspora_webfinger(handle):\n    return retrieve_and_parse_remote_doc(handle, 'DiasporaWebfinger')\n", "def retrieve_and_parse_diaspora_webfinger(handle):\n    try:\n        return _retrieve_and_parse_diaspora_webfinger(handle)\n    except Exception as exc:\n        raise exc\n", "def retrieve_and_parse_diaspora_webfinger(handle):\n    response = requests.get(handle)\n    return _parse_diaspora_webfinger(response.text)\n", "def retrieve_and_parse_diaspora_webfinger(handle):\n    r = requests.get(handle)\n    return parse_diaspora_webfinger(r.text)\n", "def retrieve_and_parse_diaspora_webfinger(handle):\n    response = requests.get(handle)\n    return parse_diaspora_webfinger(response.text)\n", "def retrieve_and_parse_diaspora_webfinger(handle):\n    return retrieve_and_parse_diaspora_document(handle, 'webfinger')\n", "def retrieve_and_parse_diaspora_webfinger(handle):\n    return _retrieve_and_parse_remote_doc(\n        handle,\n        \"diaspora.webfinger\",\n        {\"id\": \"http://diaspora.org/webfinger/\"},\n    )\n", "def retrieve_and_parse_diaspora_webfinger(handle):\n    response = requests.get(handle)\n    return parse_diaspora_webfinger(response.content)\n"]}
{"_id": "630629e252e177c0ba46a0d6", "generate_results": ["def retrieve_diaspora_host_meta(host):\n    return XRD(host)\n", "def retrieve_diaspora_host_meta(host):\n    return _retrieve_xrd_from_file(host, '/diaspora/host-meta')", "def retrieve_diaspora_host_meta(host):\n    return host.get_xrd('diaspora')\n", "def retrieve_diaspora_host_meta(host):\n    return XRD(host, \"https://diaspora.org/api/v1/hostMeta\")", "def retrieve_diaspora_host_meta(host):\n    response = requests.get(\n        'https://{}/rest/diaspora/meta'.format(host)\n    )\n    response.raise_for_status()\n    return XRD(response.json())\n", "def retrieve_diaspora_host_meta(host):\n    url = 'https://%s.diaspora.org/remotes/%s/xrd' % (host, host)\n    return XRD(url)", "def retrieve_diaspora_host_meta(host):\n    return get_diaspora_client().hosts.get(host)\n", "def retrieve_diaspora_host_meta(host):\n    url = \"https://api.diaspora.org/host-meta/%s\" % host\n    r = requests.get(url)\n    if r.status_code!= 200:\n        raise ValueError(\"Failed to retrieve diaspora host-meta for %s\" % host)\n    return r.json()\n", "def retrieve_diaspora_host_meta(host):\n    return get_diaspora_host_meta(host, \"XRD\")\n", "def retrieve_diaspora_host_meta(host):\n    return _retrieve_meta(host, 'DiasporaHost')"]}
{"_id": "630629e752e177c0ba46a0fb", "generate_results": ["def send_document(url, data, timeout=10, method=\"post\", *args, **kwargs):\n    return send_request(\n        url, data, timeout=timeout, method=method, *args, **kwargs\n    )\n", "def send_document(url, data, timeout=10, method=\"post\", *args, **kwargs):\n    return _send_document(url, data, timeout, method, *args, **kwargs)\n", "def send_document(url, data, timeout=10, method=\"post\", *args, **kwargs):\n    return send_request(\n        method,\n        url,\n        data=data,\n        timeout=timeout,\n        *args,\n        **kwargs\n    )\n", "def send_document(url, data, timeout=10, method=\"post\", *args, **kwargs):\n    return send_request(\"POST\", url, data, timeout, method, *args, **kwargs)\n", "def send_document(url, data, timeout=10, method=\"post\", *args, **kwargs):\n    return send_request(url, data, timeout, method, *args, **kwargs)\n", "def send_document(url, data, timeout=10, method=\"post\", *args, **kwargs):\n    return send_request(url, data, timeout=timeout, method=method, *args, **kwargs)\n", "def send_document(url, data, timeout=10, method=\"post\", *args, **kwargs):\n    return _send_request(\"POST\", url, data=data, timeout=timeout, *args, **kwargs)", "def send_document(url, data, timeout=10, method=\"post\", *args, **kwargs):\n    response = requests.post(url, data=data, timeout=timeout, **kwargs)\n    return _check_status(response, method), response\n", "def send_document(url, data, timeout=10, method=\"post\", *args, **kwargs):\n    response = requests.post(url, data=data, timeout=timeout, *args, **kwargs)\n    return _get_status_code_and_error(response), response.content\n", "def send_document(url, data, timeout=10, method=\"post\", *args, **kwargs):\n    response = requests.post(\n        url,\n        data=data,\n        timeout=timeout,\n        **kwargs\n    )\n    return response.status_code, response\n"]}
{"_id": "6306091073426c38ae68acac", "generate_results": ["def dict_insert(dic, val, key, *keys):\n    if keys:\n        key = keys[0]\n    dic[key] = val\n    for key in keys[1:]:\n        dic = dic[key]\n", "def dict_insert(dic, val, key, *keys):\n    if not keys:\n        dic[key] = val\n        return\n\n    keys = keys[:-1]\n    dict_insert(dic, val, keys[-1], *keys)\n", "def dict_insert(dic, val, key, *keys):\n    if not keys:\n        dic[key] = val\n        return\n\n    dic = dict_insert(dic, val, key, *keys[:-1])\n    dic[keys[-1]] = dic.get(keys[-1], {})\n    dic[keys[-1]] = dic[keys[-1]].get(key, 0) + 1\n", "def dict_insert(dic, val, key, *keys):\n    if len(keys) == 0:\n        dic[key] = val\n    else:\n        dic[key] = dict_insert(dic[key], val, keys[0], *keys[1:])\n", "def dict_insert(dic, val, key, *keys):\n    if keys:\n        dic[key] = {}\n        for key in keys:\n            dic[key][val] = dic[key].get(val, [])\n            dic[key][val].append(key)\n    else:\n        dic[key] = val\n", "def dict_insert(dic, val, key, *keys):\n    keys = keys[:-1] if keys else [key]\n    for k in keys:\n        dic = dict_insert_deep(dic, val, k)\n    return dic\n", "def dict_insert(dic, val, key, *keys):\n    dic[key] = val\n    for key in keys:\n        if key not in dic:\n            dic[key] = {}\n        dict_insert(dic[key], val, key)\n", "def dict_insert(dic, val, key, *keys):\n    if keys:\n        keys = keys[:-1]\n        dic[key] = dic.get(key, {})\n        for key in keys:\n            dic[key][keys[-1]] = val\n", "def dict_insert(dic, val, key, *keys):\n    if keys:\n        key = '.'.join(keys)\n    dic[key] = val\n", "def dict_insert(dic, val, key, *keys):\n    if keys:\n        key = key + '.' + keys[0]\n    if key not in dic:\n        dic[key] = val\n        return\n    else:\n        dict_insert(dic[key], val, keys[1:])\n"]}
{"_id": "6306091a73426c38ae68acc8", "generate_results": ["def list_of_file_names(settings_dirs, spec_option):\n    return [IniType(settings_dir, spec_option) for settings_dir in settings_dirs]\n", "def list_of_file_names(settings_dirs, spec_option):\n    return list_of_files(settings_dirs, spec_option)\n", "def list_of_file_names(settings_dirs, spec_option):\n    \n    \n    return [IniType(settings_dir, spec_option) for settings_dir in settings_dirs]\n", "def list_of_file_names(settings_dirs, spec_option):\n    \n    \n    if spec_option == 'local':\n        return list_of_file_names_local(settings_dirs)\n    if spec_option =='remote':\n        return list_of_file_names_remote(settings_dirs)\n    raise ValueError('Unknown ini file type specified: {}'.format(spec_option))\n", "def list_of_file_names(settings_dirs, spec_option):\n    \n    \n    return [\"ini_file_{}.ini\".format(i) for i in range(len(settings_dirs))]\n", "def list_of_file_names(settings_dirs, spec_option):\n    return [\n        settings_dir + spec_option + \".\" + ext\n        for settings_dir in settings_dirs\n        for ext in [\"\", \".py\"]\n    ]\n", "def list_of_file_names(settings_dirs, spec_option):\n    \n    \n    return [IniType(settings_dirs, spec_option, f)\n            for f in list_of_files(settings_dirs, spec_option)]\n", "def list_of_file_names(settings_dirs, spec_option):\n    \n    \n    return ['{}.{}'.format(x, spec_option) for x in settings_dirs]\n", "def list_of_file_names(settings_dirs, spec_option):\n    \n    \n    return [IniType(file_name, spec_option) for file_name in settings_dirs]\n", "def list_of_file_names(settings_dirs, spec_option):\n    return [\n        create_ini_type(settings_dirs, 'list_of_file_names.ini', spec_option)\n    ]\n"]}
{"_id": "6306091b73426c38ae68acd7", "generate_results": ["def ansible_config_manager(cls):\n    return cls.get_ansible_config_manager()", "def ansible_config_manager(cls):\n    return cls._ansible_config_manager", "def ansible_config_manager(cls):\n    if cls == AnsibleConfigManager:\n        return AnsibleConfigManager()\n    elif cls == AnsibleConfigManagerRun:\n        return AnsibleConfigManagerRun()\n    else:\n        raise Exception(\"Unknown Ansible Config Manager %s\" % cls)", "def ansible_config_manager(cls):\n    if cls.get_config_manager():\n        return cls.get_config_manager()\n    else:\n        return ConfigManager.get_config_manager()\n", "def ansible_config_manager(cls):\n    return cls.get_options().ansible_config_manager\n", "def ansible_config_manager(cls):\n    \n    \n    return cls._ansible_config_manager\n", "def ansible_config_manager(cls):\n    return cls._ansible_config_manager\n", "def ansible_config_manager(cls):\n    \n    \n    try:\n        config_manager = cls._get_config_manager()\n    except AnsibleConfigException:\n        config_manager = None\n    return config_manager\n", "def ansible_config_manager(cls):\n    return cls._ansible_config_manager\n", "def ansible_config_manager(cls):\n    return cls.__dict__.get(\"_ansible_config_manager\", None)\n"]}
{"_id": "6306091b73426c38ae68acd9", "generate_results": ["def workspace_manager(cls):\n    \n    \n    return cls.__get_workspace_manager__()\n", "def workspace_manager(cls):\n    return WorkspaceManager(cls)\n", "def workspace_manager(cls):\n    return cls._workspace_manager\n", "def workspace_manager(cls):\n    return cls._workspace_manager", "def workspace_manager(cls):\n    return cls._workspace_manager\n", "def workspace_manager(cls):\n    return cls._workspace_manager\n", "def workspace_manager(cls):\n    return cls._workspace_manager", "def workspace_manager(cls):\n    return get_workspace_manager()", "def workspace_manager(cls):\n    return cls._workspace_manager\n", "def workspace_manager(cls):\n    return cls._workspace_manager\n"]}
{"_id": "6306091b73426c38ae68acda", "generate_results": ["def plugins_manager(cls):\n    \n    \n\n    if not cls.plugins:\n        cls.plugins = PluginManager()\n    return cls.plugins", "def plugins_manager(cls):\n    \n    \n    return cls._plugins_manager\n", "def plugins_manager(cls):\n    \n    \n    if cls._plugins_manager is None:\n        cls._plugins_manager = PluginManager(cls)\n    return cls._plugins_manager", "def plugins_manager(cls):\n    return cls._plugins\n", "def plugins_manager(cls):\n    \n    \n    if cls in _plugins_managers:\n        return _plugins_managers[cls]\n\n    _plugins_managers[cls] = _PluginsManager(cls)\n    return _plugins_managers[cls]\n", "def plugins_manager(cls):\n    return cls._plugins\n", "def plugins_manager(cls):\n    return cls._plugins_manager\n", "def plugins_manager(cls):\n    return cls._plugins\n", "def plugins_manager(cls):\n    return cls._plugins_manager\n", "def plugins_manager(cls):\n    return plugins.manager"]}
{"_id": "6306091c73426c38ae68acdc", "generate_results": ["def validate_from_content(cls, spec_content=None):\n    if spec_content is None:\n        raise IRValidatorException('spec content is missing')\n\n    spec_data = yaml.load(spec_content)\n    validate_data(cls, spec_data)\n    return spec_data", "def validate_from_content(cls, spec_content=None):\n    if spec_content is None:\n        raise IRValidatorException(\"Spec file content cannot be None\")\n\n    return cls.validate_from_yaml(spec_content)\n", "def validate_from_content(cls, spec_content=None):\n    data = {}\n    for field in cls.required_fields:\n        data[field] = spec_content.get(field)\n    return data\n", "def validate_from_content(cls, spec_content=None):\n\n    spec_data = yaml.safe_load(spec_content)\n    return cls.validate_from_dict(spec_data)\n", "def validate_from_content(cls, spec_content=None):\n    return cls.validate(yaml.safe_load(spec_content))\n", "def validate_from_content(cls, spec_content=None):\n    data = {}\n    if not spec_content:\n        spec_content = get_spec_content(cls)\n    if not spec_content:\n        raise IRValidatorException('No spec content provided')\n    for name, value in spec_content.items():\n        if name not in cls.__fields__:\n            raise IRValidatorException('Missing field %s' % name)\n        data[name] = cls.__fields__[name].validate(value)\n    return data\n", "def validate_from_content(cls, spec_content=None):\n    spec = {}\n    if spec_content:\n        spec = yaml.safe_load(spec_content)\n    if not spec:\n        raise IRValidatorException(cls.__name__, 'no spec file found')\n    if not all(key in spec for key in cls.__required_fields):\n        raise IRValidatorException(cls.__name__,'missing required fields')\n    return spec\n", "def validate_from_content(cls, spec_content=None):\n    spec = cls._load_spec_from_content(spec_content)\n    cls._validate_spec(spec)\n    return spec\n", "def validate_from_content(cls, spec_content=None):\n    if spec_content is None:\n        raise IRValidatorException(\"Spec content is required\")\n\n    data = yaml.load(spec_content)\n    if not isinstance(data, dict):\n        raise IRValidatorException(\"Spec content is not a dictionary\")\n\n    return data", "def validate_from_content(cls, spec_content=None):\n    if spec_content is None:\n        spec_content = cls.SPEC_CONTENT\n\n    return validate(cls.SPEC_SCHEMA, spec_content)\n"]}
{"_id": "6306091c73426c38ae68acdd", "generate_results": ["def validate_from_file(cls, yaml_file=None):\n    data = load_yaml_file(yaml_file)\n    if data is None:\n        raise IRValidatorException(\"Missing required fields\")\n    validate_keys(data, cls.required_keys())\n    return data\n", "def validate_from_file(cls, yaml_file=None):\n\n    if yaml_file is None:\n        raise IRValidatorException('No file specified')\n\n    try:\n        with open(yaml_file, 'r') as f:\n            data = yaml.load(f)\n            cls.validate(data)\n    except Exception as e:\n        raise IRValidatorException('Failed to load file {}: {}'.format(yaml_file, e))\n\n    return data\n", "def validate_from_file(cls, yaml_file=None):\n    if not yaml_file:\n        raise IRValidatorException(\"Missing yaml file path\")\n    try:\n        with open(yaml_file, 'r') as f:\n            yaml_data = yaml.load(f, Loader=yaml.FullLoader)\n    except yaml.YAMLError as e:\n        raise IRValidatorException(e)\n    return cls.validate(yaml_data)\n", "def validate_from_file(cls, yaml_file=None):\n    cls.validate_fields(yaml_file)\n    return cls.load_from_file(yaml_file)\n", "def validate_from_file(cls, yaml_file=None):\n    if yaml_file is None:\n        raise IRValidatorException(\n            \"You must provide a yaml file to validate with.\")\n\n    with open(yaml_file, 'r') as f:\n        data = yaml.safe_load(f)\n\n    validate_schema(data, cls.schema)\n\n    return data\n", "def validate_from_file(cls, yaml_file=None):\n    if yaml_file is None:\n        raise IRValidatorException('Missing required YAML file path')\n\n    with open(yaml_file, 'r') as f:\n        data = yaml.safe_load(f)\n    return cls.validate(data)\n", "def validate_from_file(cls, yaml_file=None):\n    if not yaml_file:\n        raise IRValidatorException('A file path must be provided to validate a yaml file')\n\n    with open(yaml_file, 'r') as yaml_file:\n        data = yaml.safe_load(yaml_file)\n\n    if not isinstance(data, dict):\n        raise IRValidatorException('YAML file must contain a dict with required fields')\n\n    return data\n", "def validate_from_file(cls, yaml_file=None):\n    if not yaml_file:\n        yaml_file = cls._default_file_path\n\n    if not os.path.exists(yaml_file):\n        raise IRValidatorException('File {} does not exist.'.format(yaml_file))\n\n    with open(yaml_file) as f:\n        yaml_data = yaml.safe_load(f)\n\n    validate_from_dict(cls, yaml_data)\n\n    return yaml_data\n", "def validate_from_file(cls, yaml_file=None):\n    if yaml_file is None:\n        raise IRValidatorException(\"Missing YAML file\")\n\n    if not os.path.isfile(yaml_file):\n        raise IRValidatorException(\"Invalid YAML file path: {}\".format(yaml_file))\n\n    with open(yaml_file, \"r\") as f:\n        try:\n            return cls.load(f)\n        except yaml.YAMLError as exc:\n            raise IRValidatorException(exc)\n", "def validate_from_file(cls, yaml_file=None):\n    if yaml_file is None:\n        raise IRValidatorException('Missing YAML file')\n\n    with open(yaml_file, 'r') as f:\n        data = yaml.load(f, Loader=yaml.FullLoader)\n\n    cls.validate(data)\n\n    return data\n"]}
{"_id": "6306091d73426c38ae68ace5", "generate_results": ["def _include_groups(self, parser_dict):\n    for key, value in parser_dict.items():\n        if isinstance(value, list):\n            for include_group in value:\n                if include_group.get('include'):\n                    yield include_group", "def _include_groups(self, parser_dict):\n    include_groups = []\n    for key, value in parser_dict.items():\n        if isinstance(value, list):\n            include_groups.append(key)\n        else:\n            include_groups.append(value)\n    return include_groups\n", "def _include_groups(self, parser_dict):\n    if \"include_groups\" in parser_dict:\n        parser_dict[\"include_groups\"] = parser_dict[\"include_groups\"].split(\",\")\n        parser_dict[\"include_groups\"] = [i.strip() for i in parser_dict[\"include_groups\"]]\n        parser_dict[\"include_groups\"] = [i for i in parser_dict[\"include_groups\"] if i]\n    return parser_dict\n", "def _include_groups(self, parser_dict):\n    \n    \n    for key, value in parser_dict.items():\n        if isinstance(value, list):\n            for item in value:\n                if isinstance(item, dict):\n                    self._include_groups(item)\n        else:\n            if isinstance(value, dict):\n                self._include_groups(value)", "def _include_groups(self, parser_dict):\n    \n    \n    include_groups = []\n    for group in parser_dict.get(\"include\", []):\n        include_groups.append(self._include_group(group))\n\n    return include_groups\n", "def _include_groups(self, parser_dict):\n    includes = {}\n    for group, values in parser_dict.items():\n        includes[group] = []\n        for value in values:\n            if value[0] == '#':\n                includes[group].append(value[1:])\n            else:\n                includes[group].append(value)\n    return includes", "def _include_groups(self, parser_dict):\n    for include_group in parser_dict.get(\"include_groups\", []):\n        include_group_name = include_group.get(\"name\")\n        if include_group_name in self._spec_file.include_groups:\n            parser_dict[\"include_groups\"] = self._spec_file.include_groups[include_group_name]\n        else:\n            parser_dict[\"include_groups\"] = []\n    return parser_dict\n", "def _include_groups(self, parser_dict):\n    \n    \n    for group in parser_dict:\n        if group.startswith('-'):\n            group = group[1:]\n        if 'include' in parser_dict[group]:\n            parser_dict[group] = parser_dict[group]['include']\n    return parser_dict", "def _include_groups(self, parser_dict):\n    include_groups = parser_dict.get(\"include_groups\")\n    if include_groups:\n        for group in include_groups:\n            if not isinstance(group, str):\n                raise ValueError(\n                    \"Include group %s must be a string but not a %s\" %\n                    (group, type(group)))\n            self._include_groups.append(group)\n", "def _include_groups(self, parser_dict):\n    for include in parser_dict.get('include', []):\n        for line in _get_content(include):\n            self._add_group(line, include)\n"]}
{"_id": "6306092373426c38ae68acfa", "generate_results": ["def get_spec_defaults(self):\n    return {\n        \"build_dir\": self._get_spec_default(\"build_dir\"),\n        \"spec_file\": self._get_spec_default(\"spec_file\"),\n        \"spec_base\": self._get_spec_default(\"spec_base\"),\n    }\n", "def get_spec_defaults(self):\n    if self.name == 'args':\n        return self.args.values()\n    elif self.name == 'kwargs':\n        return self.kwargs.values()\n    else:\n        return self.defaults\n", "def get_spec_defaults(self):\n    defaults = {}\n    for name, value in self.defaults.items():\n        if name in self.spec:\n            defaults[name] = self.spec[name]\n    return defaults", "def get_spec_defaults(self):\n    return self._resolve_defaults(self.spec, self._get_spec_defaults())", "def get_spec_defaults(self):\n    return self.spec.get_defaults()", "def get_spec_defaults(self):\n    return self.spec.get_defaults()\n", "def get_spec_defaults(self):\n    spec = getattr(self.get_spec(),'spec', None)\n    if spec is None:\n        return {}\n    return spec.get_defaults(self.spec, self)\n", "def get_spec_defaults(self):\n    for name, value in self.spec.get('defaults', {}).items():\n        if not isinstance(value, (list, dict)):\n            value = [value]\n        value = self._get_spec_value(name, value)\n        self.spec['defaults'][name] = value\n    for name, value in self.spec.get('defaults_dict', {}).items():\n        if not isinstance(value, (list, dict)):\n            value = [value]\n        value = self._get_spec_value(name, value)\n        self.spec['defaults_dict'][name] = value\n    for name, value in self.spec.get('defaults_tuple', ()):\n        self.spec['defaults_tuple'][name] = self._get_spec_value(name, value)\n", "def get_spec_defaults(self):\n    spec = self.get_spec()\n    return {name: getattr(spec, name) for name in spec._fields}\n", "def get_spec_defaults(self):\n    return {\n        'title': self.spec['title'],\n        'description': self.spec['description'],\n        'tags': self.spec.get('tags', []),\n       'version': self.spec.get('version', ''),\n       'slug': self.spec.get('slug', ''),\n        'license': self.spec.get('license', ''),\n        'author': self.spec.get('author', ''),\n        'author_email': self.spec.get('author_email', ''),\n        'license_url': self.spec.get('license_url', ''),\n        'author_url': self.spec.get('author_url', ''),\n        'url': self.spec.get('url', ''),\n    }\n"]}
{"_id": "6306092973426c38ae68ad01", "generate_results": ["def get_deprecated_args(self):\n    \n    \n    return {}\n", "def get_deprecated_args(self):\n    return {'deprecated_options': self.deprecated_options}\n", "def get_deprecated_args(self):\n    return self.deprecated_args\n", "def get_deprecated_args(self):\n    \n    \n    return self._deprecated_args", "def get_deprecated_args(self):\n    return {'options': self.deprecated_args}\n", "def get_deprecated_args(self):\n    return self._deprecated_args", "def get_deprecated_args(self):\n    return {}\n", "def get_deprecated_args(self):\n    return self.__deprecated_args__\n", "def get_deprecated_args(self):\n    \n    \n    return {}\n", "def get_deprecated_args(self):\n    return self._deprecated_args"]}
{"_id": "6306092c73426c38ae68ad02", "generate_results": ["def validate_arg_deprecation(self, cli_args, answer_file_args):\n    deprecation_args = {}\n    for arg in self._deprecated_args:\n        if arg in cli_args:\n            deprecation_args[arg] = cli_args[arg]\n        else:\n            deprecation_args[arg] = answer_file_args[arg]\n\n    self._logger.debug(\"deprecated args: {}\".format(deprecation_args))\n    return deprecation_args\n", "def validate_arg_deprecation(self, cli_args, answer_file_args):\n    for arg in cli_args:\n        if arg not in answer_file_args:\n            self.log.warning('Argument %s is deprecated. Please use %s' %\n                             (arg, arg))\n", "def validate_arg_deprecation(self, cli_args, answer_file_args):\n    for arg_name, arg_value in cli_args.items():\n        if arg_name in answer_file_args:\n            answer_file_args[arg_name] = self.validate_arg(cli_args[arg_name], arg_value)\n        else:\n            print(f'{arg_name} is deprecated. Please use --{arg_name} or --{arg_name}=new_value')\n", "def validate_arg_deprecation(self, cli_args, answer_file_args):\n    answer_file = answer_file_args[\"file\"]\n    if not answer_file.endswith(\".yaml\"):\n        return\n\n    self._validate_file_arguments(cli_args, answer_file)\n    self._validate_file_arguments(cli_args, answer_file.replace(\".yaml\", \".yml\"))\n    self._validate_file_arguments(cli_args, answer_file.replace(\".yml\", \".yaml\"))\n", "def validate_arg_deprecation(self, cli_args, answer_file_args):\n    print(\"DEPRECATED ARGUMENTS: {}\".format(cli_args))\n    print(\"DEPRECATED ARGUMENTS: {}\".format(answer_file_args))\n", "def validate_arg_deprecation(self, cli_args, answer_file_args):\n    if cli_args is not None:\n        for key in cli_args.keys():\n            if key in answer_file_args.keys():\n                raise ValueError(\n                    \"Argument '{0}' is deprecated and should be used instead \"\n                    \"of '{1}'\".format(key, cli_args[key]))\n            else:\n                print(\"Argument '{0}' is deprecated\".format(key))\n", "def validate_arg_deprecation(self, cli_args, answer_file_args):\n    if cli_args.deprecated_args:\n        deprecated_args = cli_args.deprecated_args\n        for arg in deprecated_args:\n            if arg not in answer_file_args:\n                self.logger.error('[DEPRECATED] Argument {} is not present in file'.format(arg))\n                return False\n        return True\n    else:\n        return True", "def validate_arg_deprecation(self, cli_args, answer_file_args):\n    if cli_args is not None:\n        self.validate_args(cli_args)\n    if answer_file_args is not None:\n        self.validate_args(answer_file_args)", "def validate_arg_deprecation(self, cli_args, answer_file_args):\n    if cli_args['deprecated']:\n        return\n    deprecated = cli_args['deprecated']\n    if deprecated and deprecated in answer_file_args:\n        answer_file_args[deprecated] = answer_file_args.pop(deprecated)\n        if not answer_file_args:\n            print('')\n        else:\n            print('\\n'.join(\n                ['    {}: {}'.format(k, v) for k, v in answer_file_args.items()]\n            ))\n", "def validate_arg_deprecation(self, cli_args, answer_file_args):\n    if cli_args is None or cli_args.get('deprecated') is None:\n        return\n\n    if cli_args['deprecated'] is True:\n        self.deprecation_warning(answer_file_args)\n"]}
{"_id": "6306092d73426c38ae68ad04", "generate_results": ["def get_parser_option_specs(self, command_name):\n    if command_name in self.commands:\n        return self.commands[command_name].get_parser_option_specs()\n    else:\n        return []\n", "def get_parser_option_specs(self, command_name):\n    if command_name not in self.__commands:\n        raise KeyError(\"Command '%s' is not defined\" % command_name)\n    return self.__commands[command_name].get_parser_option_specs()", "def get_parser_option_specs(self, command_name):\n    option_spec = {}\n    for option in self._parser.option_list:\n        if option.dest == command_name:\n            option_spec[option.opts[0]] = option.opts[1]\n    return option_spec\n", "def get_parser_option_specs(self, command_name):\n    parser = self.get_parser(command_name)\n    return parser.option_list", "def get_parser_option_specs(self, command_name):\n    if command_name == \"main\":\n        return self.main_parser.parse_args()\n    elif command_name == \"virsh\":\n        return self.virsh_parser.parse_args()\n    elif command_name == \"ospd\":\n        return self.ospd_parser.parse_args()\n    elif command_name == \"ospd-config\":\n        return self.ospd_parser.parse_args()\n    else:\n        return []\n", "def get_parser_option_specs(self, command_name):\n    return self.get_parser_options(command_name)[1]", "def get_parser_option_specs(self, command_name):\n    return self._parser_options.get(command_name, [])", "def get_parser_option_specs(self, command_name):\n    return self._parser.get_option_specs(command_name)", "def get_parser_option_specs(self, command_name):\n    return self.command_parser_map[command_name]", "def get_parser_option_specs(self, command_name):\n    if command_name == \"main\":\n        return self.__main_parser.option_list\n    elif command_name == \"virsh\":\n        return self.__virsh_parser.option_list\n    elif command_name == \"ospd\":\n        return self.__ospd_parser.option_list\n    elif command_name == \"libvirtd\":\n        return self.__libvirtd_parser.option_list\n    else:\n        return self.__parser.option_list\n"]}
{"_id": "6306092d73426c38ae68ad05", "generate_results": ["def get_option_spec(self, command_name, argument_name):\n\n\nreturn self.__get_option_spec(command_name, argument_name, True)\n", "def get_option_spec(self, command_name, argument_name):\n\n\nreturn self.__get_command_spec(command_name).get_option_spec(argument_name)", "def get_option_spec(self, command_name, argument_name):\n    return self.__option_specs[command_name][argument_name]", "def get_option_spec(self, command_name, argument_name):\n    \n    \n    try:\n        return self.__getattribute__(command_name)[argument_name]\n    except KeyError:\n        raise OptionNotFound(command_name, argument_name)", "def get_option_spec(self, command_name, argument_name):\n    \n    \n    return self.__commands[command_name]['options'][argument_name]\n", "def get_option_spec(self, command_name, argument_name):\n    \n    \n\n    if command_name not in self.commands:\n        return None\n\n    command = self.commands[command_name]\n    if argument_name not in command.options:\n        return None\n\n    return command.options[argument_name]\n", "def get_option_spec(self, command_name, argument_name):\n    return self.__command_table[command_name]['options'][argument_name]", "def get_option_spec(self, command_name, argument_name):\n    \n    \n    command = self.__get_command(command_name)\n    return command.get_option_spec(argument_name)", "def get_option_spec(self, command_name, argument_name):\n    \n    \n    command = self._get_command(command_name)\n    return command.get_option_spec(argument_name)", "def get_option_spec(self, command_name, argument_name):\n    \n    \n    if command_name not in self._commands:\n        raise ValueError('Unknown command name {!r}'.format(command_name))\n    command = self._commands[command_name]\n    return command.get_option_spec(argument_name)\n"]}
{"_id": "6306092d73426c38ae68ad06", "generate_results": ["def get_silent_args(self, args):\nreturn [arg for arg in self.silent_args if arg in args]", "def get_silent_args(self, args):\nargs_silent = []\nfor arg in args:\nif not arg.startswith('-'):\nargs_silent.append(arg)\nreturn args_silent", "def get_silent_args(self, args):\nreturn []", "def get_silent_args(self, args):\nreturn [arg for arg in args if arg!='self']", "def get_silent_args(self, args):\nreturn [arg for arg in args if not self.__is_silent(arg)]\n", "def get_silent_args(self, args):\nreturn [arg for arg in args if arg not in self.silent_args]", "def get_silent_args(self, args):\n    return [arg for arg in self.__args if not arg.silent]", "def get_silent_args(self, args):\nreturn []", "def get_silent_args(self, args):\nreturn [arg for arg in args if arg not in self.silent_args]\n", "def get_silent_args(self, args):\nreturn [arg for arg in args if not self.__silent_args.has_key(arg)]\n\n"]}
{"_id": "6306092d73426c38ae68ad07", "generate_results": ["def validate_requires_args(self, args):\n    for arg in args:\n        if arg not in self.required_args:\n            raise ValueError(\n                f\"The argument {arg} is required for {self.name}\"\n            )\n", "def validate_requires_args(self, args):\n    return all(required in args for required in REQUIRED_ARGS)\n", "def validate_requires_args(self, args):\n    if not args.username and not args.password:\n        raise ValueError('You need to specify either a username or a password.')", "def validate_requires_args(self, args):\n\n    required_args = [\"file\", \"record\", \"out_dir\", \"out_file\"]\n\n    for arg in required_args:\n        if arg not in args:\n            return False\n\n    return True\n", "def validate_requires_args(self, args):\n    for arg in self.required_args:\n        if arg not in args:\n            return False\n    return True", "def validate_requires_args(self, args):\n    for arg in self.required_args:\n        if arg not in args:\n            raise ValueError(\"Required argument {0} not provided.\".format(arg))\n", "def validate_requires_args(self, args):\n    return all(arg is not None for arg in self.required_args)", "def validate_requires_args(self, args):\n    for arg in args:\n        if arg not in self.required_args:\n            return False\n    return True\n", "def validate_requires_args(self, args):\n    \n    \n    required_args = ['title', 'url', 'description', 'is_enabled']\n    for arg in required_args:\n        if arg not in args:\n            raise Exception('Missing required argument: {}'.format(arg))\n", "def validate_requires_args(self, args):\n    missing_args = []\n    for arg in REQUIRED_ARGS:\n        if arg not in args:\n            missing_args.append(arg)\n    if missing_args:\n        raise ValueError('Missing required arguments: %s' % ', '.join(missing_args))\n"]}
{"_id": "6306092d73426c38ae68ad08", "generate_results": ["def _get_conditionally_required_args(self, command_name, options_spec,\n                                         args):\n    return [arg for arg in args if self._conditionally_required(\n        command_name, options_spec, arg)]\n", "def _get_conditionally_required_args(self, command_name, options_spec,\n                                         args):\n    args_with_required_when = []\n    for name, value in args:\n        if value is None and name in options_spec:\n            args_with_required_when.append(name)\n        elif value is not None and name not in options_spec:\n            args_with_required_when.append(name)\n    return args_with_required_when\n", "def _get_conditionally_required_args(self, command_name, options_spec,\n                                         args):\n    return self._get_conditionally_required_args_helper(\n        command_name, options_spec, args, False)\n", "def _get_conditionally_required_args(self, command_name, options_spec,\n                                         args):\n    conditionally_required_args = []\n    for arg in args:\n        if self._is_required_when(command_name, options_spec, arg):\n            conditionally_required_args.append(arg)\n    return conditionally_required_args", "def _get_conditionally_required_args(self, command_name, options_spec,\n                                         args):\n    required_when = self._get_conditionally_required_arguments(command_name,\n                                                               options_spec,\n                                                               args)\n    return [arg for arg in args if arg in required_when]\n", "def _get_conditionally_required_args(self, command_name, options_spec,\n                                         args):\n    return _get_conditionally_required_args(\n        command_name, options_spec, args, required_when=True)\n", "def _get_conditionally_required_args(self, command_name, options_spec,\n                                         args):\n    if not self._conditional_required_args:\n        return []\n    conditional_required_args = self._conditional_required_args\n    for arg in args:\n        conditional_required_args.append(arg)\n    return self._get_conditionally_required_args_helper(\n        command_name, options_spec, conditional_required_args)\n", "def _get_conditionally_required_args(self, command_name, options_spec,\n                                         args):\n    conditional_args = []\n    for arg in args:\n        if self._conditional_arg_matches(command_name, options_spec, arg):\n            conditional_args.append(arg)\n    return conditional_args\n", "def _get_conditionally_required_args(self, command_name, options_spec,\n                                         args):\n    conditions = [condition for condition in options_spec\n                  if condition['required_when'](command_name, args)]\n\n    if conditions:\n        return conditions\n    return []\n", "def _get_conditionally_required_args(self, command_name, options_spec,\n                                         args):\n    arg_names = set()\n    for arg in args:\n        if not self._conditionally_required_arg(command_name, arg):\n            continue\n\n        if self._arg_matches_required_when(command_name, arg):\n            arg_names.add(arg)\n\n    return arg_names\n"]}
{"_id": "6306092e73426c38ae68ad09", "generate_results": ["def validate_length_args(self, args):\n    if len(args) < self.length:\n        raise ValidationError(\n            self.error_messages['too_few_arguments'],\n            code='too_few_arguments',\n        )\n", "def validate_length_args(self, args):\n    if len(args) > self.max_length:\n        raise ArgumentError('Too many arguments (%d)' % len(args))\n", "def validate_length_args(self, args):\n    return len(args) > self.length\n", "def validate_length_args(self, args):\n    if args['length'] > len(args['value']):\n        raise ValueError('Length specified is greater than value specified')", "def validate_length_args(self, args):\n    if len(args) > self.length:\n        raise ValueError('Argument is longer than length')\n", "def validate_length_args(self, args):\n    return len(args) > self.args_length", "def validate_length_args(self, args):\n    if len(args) > self.length:\n        self.__error(\"Length of {} is greater than {}\".format(args[0], self.length))\n", "def validate_length_args(self, args):\n    length = args.get('length', 0)\n    if length > len(args['items']):\n        raise ArgumentError('Value of length must be less than length of items.')", "def validate_length_args(self, args):\n    if len(args) > self.arg_max:\n        raise argparse.ArgumentTypeError(\n            f\"{self.arg_name} exceeds maximum length of {self.arg_max}\"\n        )\n", "def validate_length_args(self, args):\n    if len(args) > self.args_length:\n        self.error(\"Value of argument '{0}' exceeds length limit of {1}\".format(args[0], self.args_length))\n"]}
{"_id": "6306092e73426c38ae68ad0a", "generate_results": ["def validate_choices_args(self, args):\n    if args not in self.choices:\n        raise ValueError('Invalid choice: {}'.format(args))\n", "def validate_choices_args(self, args):\n    for choice in self.choices:\n        if choice[0] in args:\n            return True\n    return False\n", "def validate_choices_args(self, args):\n    if args['choices'] in self.get_choices_list():\n        return True\n    return False\n", "def validate_choices_args(self, args):\n    if args.choices is not None:\n        choices = args.choices\n        choices = set(choices)\n        available_choices = set(self._available_choices)\n        available_choices.difference_update(choices)\n        if len(choices)!= len(available_choices):\n            raise ValueError(\n                'Not all choices are available in the arguments for the choices argument.'\n            )\n", "def validate_choices_args(self, args):\n    if args.choices and not args.choices in self.choices:\n        raise ValueError(\n            \"Expected one of {} choices, got {}\".format(\n                self.choices, args.choices))\n", "def validate_choices_args(self, args):\n    choices = args.get('choices')\n    if not choices:\n        return\n    for choice in choices:\n        if choice not in self.choices:\n            raise ValueError('Invalid choice %s.' % choice)", "def validate_choices_args(self, args):\n    if args['choices'] not in self._choices:\n        raise ValueError(\"Invalid choice: '{}'\".format(args['choices']))\n", "def validate_choices_args(self, args):\n    if args[\"choices\"] not in self.choices:\n        raise ArgumentError(\"'%s' is not a valid choice for the choices argument\" % args[\"choices\"])", "def validate_choices_args(self, args):\n    if args not in self.choices:\n        raise ValueError(\"Invalid choice: %s\" % args)", "def validate_choices_args(self, args):\n    choices = []\n    for arg in args:\n        if arg in self.__choices:\n            choices.append(arg)\n    if len(choices) == 0:\n        self.__choices.append('all')\n    return choices"]}
{"_id": "6306092e73426c38ae68ad0b", "generate_results": ["def validate_min_max_args(self, args):\n    if args.min is not None and args.max is not None:\n        if args.min > args.max:\n            self.error(\"%s must be at least %s\" % (args.min, args.max))\n", "def validate_min_max_args(self, args):\n    try:\n        min_value = self._validate_args(args, self.MIN_VALUE, self.MAX_VALUE)\n    except ValueError:\n        self._print_args_error(args)\n        return False\n    return min_value is not None\n", "def validate_min_max_args(self, args):\n    if args is None:\n        raise ValueError(\"Arguments are required.\")\n\n    min_arg, max_arg = self.get_min_max_args()\n    if min_arg <= args <= max_arg:\n        return\n    raise ValueError(\"Arguments are not between {} and {}\".format(min_arg, max_arg))", "def validate_min_max_args(self, args):\n    if not isinstance(args, list):\n        raise ValueError(\"Arguments must be a list.\")\n    if not all(isinstance(arg, str) for arg in args):\n        raise ValueError(\"Arguments must be strings.\")\n\n    if not all(isinstance(arg, int) for arg in args):\n        raise ValueError(\"Arguments must be integers.\")\n\n    if not all(isinstance(arg, float) for arg in args):\n        raise ValueError(\"Arguments must be floats.\")", "def validate_min_max_args(self, args):\n    return self.validate_args(args, self.min_arg, self.max_arg)\n", "def validate_min_max_args(self, args):\n    if not args:\n        raise ValueError('Missing argument \"%s\"' % self.__class__.__name__)\n\n    for arg in args:\n        if arg < self.__min_value or arg > self.__max_value:\n            raise ValueError('Argument \"%s\" is not between %s and %s' % (arg, self.__min_value, self.__max_value))", "def validate_min_max_args(self, args):\n    if len(args)!= 2:\n        self.__parser.error('A range must be specified.')\n\n    try:\n        min_value = int(args[0])\n        max_value = int(args[1])\n    except ValueError:\n        self.__parser.error('A range must be specified.')\n\n    if min_value > max_value:\n        self.__parser.error('A range must be specified.')\n", "def validate_min_max_args(self, args):\n    return (args.min is not None and args.max is not None and\n            args.min >= args.max)\n", "def validate_min_max_args(self, args):\n    if not isinstance(args, list):\n        raise InvalidArgument(\"Argument must be a list.\")\n\n    if len(args) < 2:\n        raise InvalidArgument(\"Arguments must be at least two values.\")\n\n    if args[0] < args[1]:\n        raise InvalidArgument(\"Value of first argument must be less than value of second argument.\")", "def validate_min_max_args(self, args):\n    min_arg = args.get(self._arg_name, None)\n    max_arg = args.get(self._arg_name + '_max', None)\n    if min_arg is None or max_arg is None:\n        return True\n    return min_arg <= args[self._arg_name] <= max_arg\n"]}
{"_id": "6306092e73426c38ae68ad0d", "generate_results": ["def create_complex_argumet_type(self, subcommand, type_name, option_name,\n                                    spec_option):\n    return self._create_argumet_type(subcommand, type_name, option_name,\n                                      spec_option, self.complex_argument_types)", "def create_complex_argumet_type(self, subcommand, type_name, option_name,\n                                    spec_option):\n    return self.__create_argumet_type(subcommand, type_name, option_name,\n                                       spec_option, complex)\n", "def create_complex_argumet_type(self, subcommand, type_name, option_name,\n                                    spec_option):\n    return self.__create_argument_type(subcommand, type_name, option_name,\n                                       spec_option, complex)\n", "def create_complex_argumet_type(self, subcommand, type_name, option_name,\n                                    spec_option):\n    return self.__create_argument_type(subcommand, type_name, option_name,\n                                       spec_option, True)\n", "def create_complex_argumet_type(self, subcommand, type_name, option_name,\n                                    spec_option):\n    return self.__create_argument_type(subcommand, type_name, option_name,\n                                        spec_option, complex)", "def create_complex_argumet_type(self, subcommand, type_name, option_name,\n                                    spec_option):\n    return ComplexArgumentType(\n        subcommand, type_name, option_name, spec_option)\n", "def create_complex_argumet_type(self, subcommand, type_name, option_name,\n                                    spec_option):\n    return complex(subcommand, type_name, option_name, spec_option)\n", "def create_complex_argumet_type(self, subcommand, type_name, option_name,\n                                    spec_option):\n    return ComplexType(subcommand, type_name, option_name, spec_option)\n", "def create_complex_argumet_type(self, subcommand, type_name, option_name,\n                                    spec_option):\n    if not isinstance(spec_option, ComplexTypeSpecification):\n        raise ValueError(\"The'spec_option' parameter must be a ComplexTypeSpecification\")\n    return ComplexType(subcommand, type_name, option_name, spec_option)\n", "def create_complex_argumet_type(self, subcommand, type_name, option_name,\n                                    spec_option):\n    if not self.__has_complex_type(subcommand, type_name, option_name,\n                                   spec_option):\n        raise SchemaError(\"No complex type found for {}.{}.{}\".format(\n            subcommand, type_name, option_name))\n    return self.__create_complex_argument_type(subcommand, type_name, option_name,\n                                               spec_option)"]}
{"_id": "6306092e73426c38ae68ad0f", "generate_results": ["def get_nested_custom_and_control_args(self, args):\n    control_args = {}\n    nested_args = {}\n    if args.control:\n        control_args = self._get_nested_custom_args(args)\n    if args.nested:\n        nested_args = self._get_nested_custom_args(args.nested)\n    return control_args, nested_args\n", "def get_nested_custom_and_control_args(self, args):\n    control_args = {}\n    nested_args = {}\n    for arg in args:\n        if '=' in arg:\n            key, value = arg.split('=')\n            control_args[key] = value\n        else:\n            nested_args[arg] = args[arg]\n    return control_args, nested_args\n", "def get_nested_custom_and_control_args(self, args):\n\n    control_args = {}\n    nested_args = {}\n    if args.control:\n        control_args = self._get_nested_custom_args(args)\n    if args.nested:\n        nested_args = self._get_nested_custom_args(args.nested)\n\n    return control_args, nested_args\n", "def get_nested_custom_and_control_args(self, args):\n    control_args = {}\n    nested_args = {}\n\n    for arg in args:\n        if arg.startswith(\"--control\"):\n            control_args.update(arg)\n        elif arg.startswith(\"--nested\"):\n            nested_args.update(arg)\n\n    return control_args, nested_args\n", "def get_nested_custom_and_control_args(self, args):\n    return {}, {}", "def get_nested_custom_and_control_args(self, args):\n    control_args = {}\n    nested_args = {}\n    for key, value in args.iteritems():\n        if key.startswith('-') and key.endswith('_'):\n            nested_args[key[1:-1]] = value\n        else:\n            control_args[key] = value\n    return control_args, nested_args\n", "def get_nested_custom_and_control_args(self, args):\n    control_args = {}\n    nested_args = {}\n    for arg in args:\n        if arg.startswith('--'):\n            nested_args[arg[2:]] = args[arg]\n        else:\n            control_args[arg] = args[arg]\n    return control_args, nested_args\n", "def get_nested_custom_and_control_args(self, args):\n    control_args = {}\n    nested_args = {}\n    if args.control:\n        control_args = self._get_nested_custom_args(args.control)\n    if args.nested:\n        nested_args = self._get_nested_custom_args(args.nested)\n    return control_args, nested_args\n", "def get_nested_custom_and_control_args(self, args):\n\n    control_args = {}\n    nested_args = {}\n\n    for arg in args:\n        if arg == \"--control\":\n            control_args = True\n        elif arg == \"--nested\":\n            nested_args = True\n        else:\n            return None, None\n\n    return control_args, nested_args\n", "def get_nested_custom_and_control_args(self, args):\n    control_args = {}\n    nested_args = {}\n    if args.control:\n        control_args = args.control\n    if args.nested:\n        nested_args = args.nested\n    return control_args, nested_args\n"]}
{"_id": "6306092e73426c38ae68ad11", "generate_results": ["def merge_extra_vars(vars_dict, extra_vars=None):\n    if extra_vars is None:\n        extra_vars = []\n    vars_dict.update(extra_vars)\n    return vars_dict\n", "def merge_extra_vars(vars_dict, extra_vars=None):\n    if extra_vars is None:\n        extra_vars = []\n\n    for var in extra_vars:\n        if var not in vars_dict:\n            vars_dict[var] = {}\n\n        vars_dict[var] = vars_dict[var].copy()\n    return vars_dict\n", "def merge_extra_vars(vars_dict, extra_vars=None):\n    if extra_vars is None:\n        extra_vars = []\n    return vars_dict.update(extra_vars)\n", "def merge_extra_vars(vars_dict, extra_vars=None):\n    if extra_vars is None:\n        extra_vars = []\n\n    extra_vars = [var.strip() for var in extra_vars]\n    vars_dict.update({\"extra-vars\": extra_vars})\n    return vars_dict", "def merge_extra_vars(vars_dict, extra_vars=None):\n    if extra_vars is None:\n        extra_vars = []\n\n    vars_dict.update(extra_vars)\n    return vars_dict\n", "def merge_extra_vars(vars_dict, extra_vars=None):\n    if extra_vars is None:\n        extra_vars = []\n\n    if not isinstance(extra_vars, list):\n        raise TypeError(\"extra-vars must be a list\")\n\n    vars_dict.update({'extra-vars': extra_vars})\n", "def merge_extra_vars(vars_dict, extra_vars=None):\n    if extra_vars is None:\n        extra_vars = []\n\n    if isinstance(vars_dict, dict):\n        vars_dict = vars_dict.copy()\n        for extra_var in extra_vars:\n            if extra_var in vars_dict:\n                vars_dict[extra_var] = vars_dict.pop(extra_var)\n\n    return vars_dict\n", "def merge_extra_vars(vars_dict, extra_vars=None):\n    if extra_vars is None:\n        extra_vars = []\n\n    if isinstance(extra_vars, basestring):\n        extra_vars = [extra_vars]\n\n    vars_dict.update(extra_vars)\n\n    return vars_dict\n", "def merge_extra_vars(vars_dict, extra_vars=None):\n    if extra_vars is None:\n        extra_vars = []\n\n    for extra_var in extra_vars:\n        if extra_var in vars_dict:\n            vars_dict[extra_var] = vars_dict[extra_var] + vars_dict[extra_var]\n        else:\n            vars_dict[extra_var] = vars_dict[extra_var]\n\n    return vars_dict\n", "def merge_extra_vars(vars_dict, extra_vars=None):\n    if extra_vars is None:\n        extra_vars = []\n\n    for var in extra_vars:\n        if var not in vars_dict:\n            vars_dict[var] = dict()\n\n        vars_dict[var].update(vars_dict[var])\n"]}
{"_id": "6306092f73426c38ae68ad13", "generate_results": ["def ansible_playbook(ir_workspace, ir_plugin, playbook_path, verbose=None,\n                     extra_vars=None, ansible_args=None):\n    return _ansible_playbook(\n        ir_workspace, ir_plugin, playbook_path, verbose=verbose,\n        extra_vars=extra_vars, ansible_args=ansible_args)\n", "def ansible_playbook(ir_workspace, ir_plugin, playbook_path, verbose=None,\n                     extra_vars=None, ansible_args=None):\n    return ansible_main(\n        ir_workspace, ir_plugin, playbook_path, verbose=verbose,\n        extra_vars=extra_vars, ansible_args=ansible_args)", "def ansible_playbook(ir_workspace, ir_plugin, playbook_path, verbose=None,\n                     extra_vars=None, ansible_args=None):\n    command = 'ansible-playbook {} {}'.format(\n        playbook_path, ir_workspace.name)\n    return _ansible_run(command, verbose, extra_vars, ansible_args)\n", "def ansible_playbook(ir_workspace, ir_plugin, playbook_path, verbose=None,\n                     extra_vars=None, ansible_args=None):\n    # TODO: Implement this function\n    return None", "def ansible_playbook(ir_workspace, ir_plugin, playbook_path, verbose=None,\n                     extra_vars=None, ansible_args=None):\n    return _ansible_wrapper(\n        ir_workspace, ir_plugin, playbook_path, verbose, extra_vars, ansible_args)\n", "def ansible_playbook(ir_workspace, ir_plugin, playbook_path, verbose=None,\n                     extra_vars=None, ansible_args=None):\n    ansible_args = dict(ansible_args or {})\n    ansible_args.update({'ir_workspace': ir_workspace,\n                        'ir_plugin': ir_plugin,\n                        'playbook_path': playbook_path})\n    return playbook(**ansible_args)\n", "def ansible_playbook(ir_workspace, ir_plugin, playbook_path, verbose=None,\n                     extra_vars=None, ansible_args=None):\n\n    ir_workspace.ansible_playbook(\n        playbook_path, verbose=verbose, extra_vars=extra_vars, ansible_args=ansible_args\n    )\n", "def ansible_playbook(ir_workspace, ir_plugin, playbook_path, verbose=None,\n                     extra_vars=None, ansible_args=None):\n    return ansible_wrapper(\n        ir_workspace, ir_plugin, playbook_path, verbose=verbose,\n        extra_vars=extra_vars, ansible_args=ansible_args,\n        ansible_wrapper=ansible_playbook_wrapper)\n", "def ansible_playbook(ir_workspace, ir_plugin, playbook_path, verbose=None,\n                     extra_vars=None, ansible_args=None):\n\n    return _ansible_playbook_helper(\n        ir_workspace, ir_plugin, playbook_path, verbose, extra_vars, ansible_args\n    )\n", "def ansible_playbook(ir_workspace, ir_plugin, playbook_path, verbose=None,\n                     extra_vars=None, ansible_args=None):\n    return playbook(\n        ir_workspace, ir_plugin, playbook_path, verbose=verbose,\n        extra_vars=extra_vars, ansible_args=ansible_args)"]}
{"_id": "6306093273426c38ae68ad15", "generate_results": ["def _run_playbook(cli_args, vars_dict, ir_workspace, ir_plugin):\n    return _run_ansible_cli(cli_args, vars_dict, ir_workspace, ir_plugin)\n", "def _run_playbook(cli_args, vars_dict, ir_workspace, ir_plugin):\n    # TODO: Add support for setting variables in the vars dict\n    return _run_ansible_cli(cli_args, vars_dict, ir_workspace, ir_plugin, ir_workspace.playbook_dir)\n", "def _run_playbook(cli_args, vars_dict, ir_workspace, ir_plugin):\n    return cli_args[0](cli_args[1:], vars_dict, ir_workspace, ir_plugin)\n", "def _run_playbook(cli_args, vars_dict, ir_workspace, ir_plugin):\n    vars_dict.update(ir_plugin.vars)\n    return cli_args, vars_dict\n", "def _run_playbook(cli_args, vars_dict, ir_workspace, ir_plugin):\n    return _run_cli(cli_args, vars_dict, ir_workspace, ir_plugin, playbook_name='playbook.yml')\n", "def _run_playbook(cli_args, vars_dict, ir_workspace, ir_plugin):\n    ansible_vars = vars_dict.copy()\n    ansible_vars.update(ir_workspace.ansible_vars)\n    return cli_runner.invoke(cli_args, ansible_vars, catch_exceptions=False)\n", "def _run_playbook(cli_args, vars_dict, ir_workspace, ir_plugin):\n    if ir_workspace:\n        ir_workspace.load_vars(vars_dict)\n        ir_workspace.load_plugins(ir_plugin)\n    results = cli_args.run(cli_args, ir_workspace, ir_plugin)\n    return results\n", "def _run_playbook(cli_args, vars_dict, ir_workspace, ir_plugin):\n    cli_args = cli_args + ['--extra-vars']\n    cli_args += vars_dict.get('extra_vars', [])\n    return _run_ansible_cli(cli_args, ir_workspace, ir_plugin)\n", "def _run_playbook(cli_args, vars_dict, ir_workspace, ir_plugin):\n    with ir_workspace.create_temp_playbook(cli_args=cli_args, vars_dict=vars_dict, plugin=ir_plugin) as playbook:\n        return playbook.run()\n", "def _run_playbook(cli_args, vars_dict, ir_workspace, ir_plugin):\n    return _run_cli(cli_args, vars_dict, ir_workspace, ir_plugin)\n"]}
{"_id": "63060ada73426c38ae68ad31", "generate_results": ["def _convert_non_cli_args(self, parser_name, values_dict):\n    for key in values_dict:\n        values_dict[key] = str(values_dict[key])\n    return values_dict\n", "def _convert_non_cli_args(self, parser_name, values_dict):\n    for arg, value in values_dict.items():\n        if type(value) == type([]):\n            values_dict[arg] = value[0]\n        elif type(value) == type(''):\n            values_dict[arg] = value\n        else:\n            values_dict[arg] = str(value)", "def _convert_non_cli_args(self, parser_name, values_dict):\n    for key, value in values_dict.items():\n        if not isinstance(value, str):\n            values_dict[key] = str(value)\n", "def _convert_non_cli_args(self, parser_name, values_dict):\n    for key in values_dict:\n        if key.endswith('values'):\n            values_dict[key] = values_dict[key].split()\n        else:\n            values_dict[key] = self._get_cli_value(values_dict[key])\n", "def _convert_non_cli_args(self, parser_name, values_dict):\n    for key in values_dict:\n        if isinstance(values_dict[key], str):\n            values_dict[key] = values_dict[key].encode(\"utf-8\")\n", "def _convert_non_cli_args(self, parser_name, values_dict):\n    for key, value in values_dict.items():\n        if isinstance(value, str):\n            values_dict[key] = value.strip()\n        elif isinstance(value, bool):\n            values_dict[key] = value == \"True\"\n        elif isinstance(value, int):\n            values_dict[key] = value == \"1\"\n", "def _convert_non_cli_args(self, parser_name, values_dict):\n    for arg in values_dict[parser_name]:\n        if isinstance(values_dict[parser_name][arg], six.string_types):\n            values_dict[parser_name][arg] = str(values_dict[parser_name][arg])\n", "def _convert_non_cli_args(self, parser_name, values_dict):\n    if parser_name in values_dict:\n        for arg in values_dict[parser_name]:\n            if isinstance(arg, str):\n                values_dict[parser_name][arg] = values_dict[parser_name][arg].strip()\n", "def _convert_non_cli_args(self, parser_name, values_dict):\n    for arg_name, arg_val in values_dict.items():\n        if isinstance(arg_val, str):\n            values_dict[arg_name] = arg_val.encode(\"utf-8\")\n", "def _convert_non_cli_args(self, parser_name, values_dict):\n    for key in values_dict.keys():\n        if key.startswith(parser_name):\n            values_dict[key] = self._arg_type_map.get(key, str)(values_dict[key])\n"]}
{"_id": "63060b1a73426c38ae68ad3e", "generate_results": ["def get_plugin_spec_flatten_dict(plugin_dir):\n    flat_dict = {}\n    for plugin_path in get_plugin_spec_paths(plugin_dir):\n        plugin_name = os.path.basename(plugin_path)\n        flat_dict[plugin_name] = get_plugin_spec_flatten_dict(plugin_path)\n    return flat_dict\n", "def get_plugin_spec_flatten_dict(plugin_dir):\n    plugin_dict = {}\n    for plugin in get_plugin_dir_flatten_dict(plugin_dir):\n        plugin_dict.update(plugin)\n\n    return plugin_dict\n", "def get_plugin_spec_flatten_dict(plugin_dir):\n    return dict((k, get_plugin_spec_flatten_dict(os.path.join(plugin_dir, k))) for k in os.listdir(plugin_dir))\n", "def get_plugin_spec_flatten_dict(plugin_dir):\n    return flatten_dict(get_plugin_spec_dict(plugin_dir))\n", "def get_plugin_spec_flatten_dict(plugin_dir):\n    return {\n        'name': plugin_dir,\n        'plugin': {\n            'name': os.path.basename(plugin_dir),\n            'plugin_spec': {\n                'plugin_dir': plugin_dir,\n                'plugin_id': os.path.basename(plugin_dir)\n            }\n        }\n    }\n", "def get_plugin_spec_flatten_dict(plugin_dir):\n    return {\n        \"plugin_name\": get_plugin_name(plugin_dir),\n        \"short_description\": get_plugin_description(plugin_dir),\n        \"author\": get_plugin_author(plugin_dir),\n        \"version\": get_plugin_version(plugin_dir),\n        \"license\": get_plugin_license(plugin_dir),\n        \"version_info\": get_plugin_version_info(plugin_dir),\n        \"author_info\": get_plugin_author_info(plugin_dir),\n        \"path\": get_plugin_path(plugin_dir)\n    }\n", "def get_plugin_spec_flatten_dict(plugin_dir):\n    spec_dict = {}\n    for dirname, dirnames, filenames in os.walk(plugin_dir):\n        for filename in filenames:\n            if filename.endswith('.py'):\n                spec_dict[os.path.splitext(filename)[0]] = dirname\n\n    return spec_dict\n", "def get_plugin_spec_flatten_dict(plugin_dir):\n    plugin_spec_flatten_dict = {}\n    for file_name in os.listdir(plugin_dir):\n        if file_name.endswith(\".py\"):\n            plugin_spec_flatten_dict[file_name[:-3]] = get_plugin_spec_flatten_dict(os.path.join(plugin_dir, file_name))\n    return plugin_spec_flatten_dict\n", "def get_plugin_spec_flatten_dict(plugin_dir):\n    return {key: value for key, value in get_plugin_spec_dict(plugin_dir).items() if isinstance(value, dict)}\n", "def get_plugin_spec_flatten_dict(plugin_dir):\n    plugin_spec_dict = get_plugin_spec_dict(plugin_dir)\n    plugin_spec_dict = flatten_dict(plugin_spec_dict)\n    return plugin_spec_dict\n"]}
{"_id": "63060b1b73426c38ae68ad42", "generate_results": ["def inject_config(self):\n    \n    \n    if not self.config_path:\n        return\n    os.environ[self.config_path] = self.config_value", "def inject_config(self):\n    \n    \n    if self.config_path:\n        os.environ['CONFIG_PATH'] = self.config_path\n", "def inject_config(self):\n    if 'CONFIG_PATH' not in os.environ:\n        os.environ['CONFIG_PATH'] = os.path.join(\n            os.path.dirname(__file__), '../../config')\n", "def inject_config(self):\n    if self.config_path is None:\n        return\n    self.config_path = os.path.expanduser(self.config_path)", "def inject_config(self):\n    if self._config_path is None:\n        return\n    os.environ['PYTHONUNBUFFERED'] = 'yes'\n    os.environ['PYTHONUNBUFFERED_LOGGING'] = 'yes'\n    os.environ['PYTHONUNBUFFERED_LOGGING_LEVEL'] = 'DEBUG'\n    os.environ['PYTHONUNBUFFERED_LOGGING_FILE'] = self._config_path", "def inject_config(self):\n    \n    \n    if not self._config_path:\n        self._config_path = os.path.join(os.getenv('HOME'), '.config/scripts/config.json')\n", "def inject_config(self):\n    \n    \n    if not self.config_path:\n        self.config_path = '/etc/'\n", "def inject_config(self):\n    \n    \n    if not self.config_path:\n        return\n    os.environ['CONFIG_PATH'] = self.config_path\n", "def inject_config(self):\n    \n    \n    if self.config_path is None:\n        return\n\n    os.environ['CONFIG_PATH'] = self.config_path\n", "def inject_config(self):\n    if 'CONFIG' not in os.environ:\n        os.environ['CONFIG'] = os.path.join(self.get_config_dir(), 'config.yaml')"]}
{"_id": "63060b1b73426c38ae68ad43", "generate_results": ["def extend_cli(self, root_subparsers):\n    cli_options = self._get_cli_options()\n    cli_parser = root_subparsers.add_parser('cli', help='cli options')\n    cli_parser.set_defaults(func=self._cli_func)\n    for option in cli_options:\n        cli_parser.add_argument('--' + option.name, **option.opts)\n        if option.name in self._cli_specs:\n            self._cli_specs[option.name].update(option.opts)\n        else:\n            self._cli_specs[option.name] = option.opts\n", "def extend_cli(self, root_subparsers):\n    parser = root_subparsers.add_parser('repo', help='repo information')\n    self.add_repo_args(parser)\n    parser.add_argument('--token', '-t', required=True, help='API token')\n    parser.add_argument('--username', '-u', required=True, help='API username')\n    parser.add_argument('--password', '-p', required=True, help='API password')", "def extend_cli(self, root_subparsers):\n    parser = root_subparsers.add_parser(\n        self.cli_name,\n        help=self.__doc__,\n        formatter_class=HelpFormatter,\n        description=self.description\n    )\n    self.extend_cli_parser(parser)\n", "def extend_cli(self, root_subparsers):\n    self.cli_parser = self.cli_parser.add_parser(self.command,\n                                                 help=self.help,\n                                                 description=self.description)\n\n    self.cli_parser.set_defaults(func=self.run)\n    self.cli_parser.add_argument(\"--version\", action=\"version\", version=self.version)\n    root_subparsers.add_parser(self.cli_parser)\n", "def extend_cli(self, root_subparsers):\n    self._cli = self._add_subparsers(root_subparsers, 'cli')\n    self._add_common_options(self._cli)", "def extend_cli(self, root_subparsers):\n    pass\n", "def extend_cli(self, root_subparsers):\n    extend_cli_base(self, root_subparsers, self.cli_parser)\n", "def extend_cli(self, root_subparsers):\n    cli_opts = self.__get_cli_opts()\n    for opt in cli_opts:\n        root_subparsers.add_parser(opt.name, help=opt.help, **opt.kwargs)\n", "def extend_cli(self, root_subparsers):\n    root_subparser = root_subparsers.add_parser(\n       'spec', help='List spec information',\n        description='Lists the spec information for a given package.')\n    root_subparser.set_defaults(func=self.run)\n", "def extend_cli(self, root_subparsers):\n    self._cli_parser = root_subparsers.add_parser(\n        self.cli_name,\n        help=self.__doc__)\n    self._cli_parser.set_defaults(func=self._run)\n"]}
